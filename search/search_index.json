{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#welcome-to-jarvais","title":"Welcome to jarvAIs","text":"<p>Official Github here.</p>"},{"location":"#overview","title":"Overview","text":"<p><code>jarvAIs</code> is a Python package designed to automate and enhance machine learning workflows. The primary goal of this project is to reduce redundancy in repetitive tasks, improve consistency, and elevate the quality of standardized processes in oncology research.</p> <p>Follow pixi installation process found here</p> <pre><code># Clone Repo\ngit clone https://github.com/pmcdi/jarvais.git\n\n# Navigate to project\ncd jarvais\n\n# Install dependencies\npixi install\n</code></pre>"},{"location":"#modules","title":"Modules","text":"<p>This package consists of 3 different modules:</p> <ul> <li>Analyzer: A module that analyzes and processes data, providing valuable insights for downstream tasks.</li> <li>Trainer: A module for training machine learning models, designed to be flexible and efficient.</li> <li>Explainer: A module that explains model predictions, offering interpretability and transparency in decision-making.</li> </ul>"},{"location":"api/analyzer/","title":"Analyzer","text":""},{"location":"api/analyzer/#analyzer","title":"Analyzer","text":"<p>The <code>Analyzer</code> class is part of the <code>jarvais.analyzer</code> module. It provides tools for exploring datasets and identifying issues.</p>"},{"location":"api/analyzer/#jarvais.analyzer.Analyzer","title":"<code>jarvais.analyzer.Analyzer</code>","text":"<p>A data analysis and cleaning tool for preprocessing datasets, generating reports, and visualizations.</p> Features <ul> <li>Handles missing values and outliers.</li> <li>Infers column types (categorical, continuous, date).</li> <li>Supports one-hot encoding and survival analysis.</li> <li>Generates summary statistics and correlation plots.</li> <li>Produces a comprehensive PDF analysis report.</li> </ul> <p>Attributes:</p> Name Type Description <code>data</code> <code>DataFrame</code> <p>Input dataset.</p> <code>target_variable</code> <code>str</code> <p>Target variable in the dataset.</p> <code>task</code> <code>str</code> <p>Type of analysis task.</p> <code>one_hot_encode</code> <code>bool</code> <p>Whether to one-hot encode categorical columns.</p> <code>config</code> <code>str | Path</code> <p>Path to a YAML configuration file.</p> <code>output_dir</code> <code>str | Path</code> <p>Directory to save outputs. Default is the current directory.</p> Example <pre><code>from jarvais.analyzer import Analyzer\nimport pandas as pd\n\ndata = pd.DataFrame({\n    \"age\": [25, 32, 40],\n    \"income\": [50000, 60000, 75000],\n    \"category\": [\"A\", \"B\", \"A\"]\n})\n\nanalyzer = Analyzer(data, target_variable=\"income\", task=\"regression\")\nanalyzer.run()\n</code></pre> Source code in <code>src/jarvais/analyzer/analyzer.py</code> <pre><code>class Analyzer:\n    \"\"\"\n    A data analysis and cleaning tool for preprocessing datasets, generating reports, and visualizations.\n\n    Features:\n        - Handles missing values and outliers.\n        - Infers column types (categorical, continuous, date).\n        - Supports one-hot encoding and survival analysis.\n        - Generates summary statistics and correlation plots.\n        - Produces a comprehensive PDF analysis report.\n\n    Attributes:\n        data (pd.DataFrame): Input dataset.\n        target_variable (str, optional): Target variable in the dataset.\n        task (str, optional): Type of analysis task.\n        one_hot_encode (bool, optional): Whether to one-hot encode categorical columns.\n        config (str | Path, optional): Path to a YAML configuration file.\n        output_dir (str | Path, optional): Directory to save outputs. Default is the current directory.\n\n    Example:\n        ```python\n        from jarvais.analyzer import Analyzer\n        import pandas as pd\n\n        data = pd.DataFrame({\n            \"age\": [25, 32, 40],\n            \"income\": [50000, 60000, 75000],\n            \"category\": [\"A\", \"B\", \"A\"]\n        })\n\n        analyzer = Analyzer(data, target_variable=\"income\", task=\"regression\")\n        analyzer.run()\n        ```\n    \"\"\"\n    def __init__(\n            self,\n            data: pd.DataFrame,\n            target_variable: str | None = None,\n            task: str | None = None,\n            one_hot_encode: bool = False,\n            config: str | Path = None,\n            output_dir: str | Path = None\n        ) -&gt; None:\n\n        self.data = data\n        self.target_variable = target_variable\n        self.task = task\n        self.one_hot_encode = one_hot_encode\n\n        assert_message = \"When setting task to 'survival', target_variable must be 'event' and 'time' must be in data\"\n        if self.task == 'survival':\n            assert target_variable == 'event' and 'time' in data.columns, assert_message\n\n        self.output_dir = Path.cwd() if output_dir is None else Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n\n        if config is not None:\n            config = Path(config)\n            if config.is_file():\n                with config.open('r') as file:\n                    self.config = yaml.safe_load(file)\n            else:\n                raise ValueError(f'Config file does not exist at {config}')\n        else:\n            self.config = config\n\n        self.outlier_analysis = '' # Used later when writing to PDF\n\n    def _create_config(self) -&gt; None:\n        \"\"\"\n        Create and save a configuration file for column types, outlier handling, and missing value strategies.\n\n        Steps:\n        1. **Infer Column Types**: Identifies categorical, continuous, and date columns using `infer_types`.\n        2. **Handle NaN Columns**: Drops columns entirely filled with NaN and updates the continuous column list.\n        3. **Outlier Detection**: Identifies outliers in categorical columns and stores the mappings.\n        4. **Missing Value Strategy**: Sets default imputation strategies for categorical and continuous variables.\n        \"\"\"\n        print('Config file not found. Creating custom...')\n\n        self.config = {}\n        columns = {}\n\n        self.categorical_columns, self.continuous_columns, self.date_columns = infer_types(self.data)\n        # Replace all non numerical values with NaN\n        self.data[self.continuous_columns] = self.data[self.continuous_columns].apply(pd.to_numeric, errors='coerce')\n\n        nan_ = self.data.apply(lambda col: col.isna().all())\n        nan_columns = nan_[nan_].index.tolist()\n        if len(nan_columns) &gt; 0:\n            print(\"Columns that are all NaN(probably ID columns) dropping...: \", nan_columns)\n            self.continuous_columns = list(set(self.continuous_columns) - set(nan_columns))\n\n        print(\"Used a heuristic to define categorical and continuous columns. Please review!\")\n\n        columns['categorical'] = self.categorical_columns\n        columns['continuous'] = self.continuous_columns\n        columns['date'] = self.date_columns\n        columns['other'] = nan_columns\n\n        self.config['columns'] = columns\n\n        outlier_analysis, mapping = get_outliers(self.data, self.categorical_columns)\n\n        self.outlier_analysis += outlier_analysis\n        self.config['mapping'] = mapping\n\n        self.config['missingness_strategy'] = {}\n        # Defining default replacement for each missing categorical variable\n        self.config['missingness_strategy']['categorical'] = {cat :'Unknown' for cat in self.categorical_columns}\n        # Defining default replacement for each missing continuous variable\n        self.config['missingness_strategy']['continuous'] = {cont :'median' for cont in self.continuous_columns}\n\n    def _apply_config(self) -&gt; None:\n\n        print('Applying changes from config...\\n')\n\n        for key in self.config['mapping'].keys():\n            assert key in self.data.columns, f\"{key} in mapping file not found data\"\n            self.data.loc[:, [key]] = self.data.loc[:, key].replace(self.config['mapping'][key])\n\n        self.data = replace_missing(self.data, self.categorical_columns, self.continuous_columns, self.config)\n\n    def _create_multiplots(self, figures_dir: Path) -&gt; None:\n        \"\"\"Generate and save multiplots for each categorical variable against all continuous variables.\"\"\"\n        self.multiplots = [] # Used to save in PDF later\n\n        (figures_dir / 'multiplots').mkdir(parents=True, exist_ok=True)\n\n        self.multiplots = Parallel(n_jobs=-1)(\n            delayed(plot_one_multiplot)(\n                self.data,\n                self.umap_data,\n                var,\n                self.continuous_columns,\n                figures_dir\n            ) for var in self.categorical_columns\n        )\n\n    def run(self) -&gt; None:\n        \"\"\"Run the data cleaning and visualization process.\"\"\"\n        if self.config is None:\n            self._create_config()\n        else:\n            self.continuous_columns = self.config['columns']['continuous']\n            self.categorical_columns = self.config['columns']['categorical']\n            # Replace all non numerical values with NaN\n            self.data[self.continuous_columns] = self.data[self.continuous_columns].apply(pd.to_numeric, errors='coerce')\n            self.outlier_analysis, _ = get_outliers(self.data, self.categorical_columns)\n\n        print(f\"Feature Types:\\n  - Categorical: {self.categorical_columns}\\n  - Continuous: {self.continuous_columns}\")\n        print(f\"\\n\\nOutlier Analysis:\\n{self.outlier_analysis}\")\n\n        with open(self.output_dir / 'config.yaml', 'w') as f:\n            yaml.dump(self.config, f)\n\n        self._apply_config()\n\n        # Create Table One\n        df_keep = self.data[self.continuous_columns + self.categorical_columns]\n\n        self.mytable = TableOne(df_keep, categorical=self.categorical_columns, pval=False)\n        print(self.mytable.tabulate(tablefmt = \"fancy_grid\"))\n        self.mytable.to_csv(self.output_dir / 'tableone.csv')\n\n        # PLOTS\n        figures_dir = self.output_dir / 'figures'\n        figures_dir.mkdir(exist_ok=True, parents=True)\n\n        if self.task == 'survival':\n            data_x = self.data.drop(columns=['time', 'event'])\n            data_y = self.data[['time', 'event']]\n            categorical_columns  = [cat for cat in self.categorical_columns if cat != 'event']\n            plot_kaplan_meier_by_category(\n                data_x, data_y,\n                categorical_columns,\n                figures_dir / 'kaplan_meier'\n            )\n\n        # Correlation Plots\n        p_corr = self.data[self.continuous_columns].corr(method=\"pearson\")\n        s_corr = self.data[self.continuous_columns].corr(method=\"spearman\")\n        size = len(self.continuous_columns)*1.5\n        plot_corr(p_corr, size, file_name='pearson_correlation.png', output_dir=figures_dir)\n        plot_corr(s_corr, size, file_name='spearman_correlation.png', output_dir=figures_dir)\n\n        # Categorical cross frequency table\n        plot_frequency_table(self.data, self.categorical_columns, figures_dir)\n\n        # UMAP reduced data + Plots\n        self.umap_data = plot_umap(self.data, self.continuous_columns, figures_dir)\n\n        # Plot pairplot: keeping only the top ten correlated pairs in the pair plot\n        if self.target_variable in self.categorical_columns:\n            plot_pairplot(self.data, self.continuous_columns, output_dir=figures_dir, target_variable=self.target_variable)\n        else:\n            plot_pairplot(self.data, self.continuous_columns, output_dir=figures_dir)\n\n        # Create Multiplots\n        self._create_multiplots(figures_dir)\n\n        if self.one_hot_encode:\n            self.data = pd.get_dummies(\n                self.data,\n                columns=[cat for cat in self.categorical_columns if cat != self.target_variable],\n                dtype=float,\n                prefix_sep='|' # Using this to make it obvious OHE features\n            )\n\n        self.data.to_csv(self.output_dir / 'updated_data.csv')\n\n        # Create Output PDF\n        generate_analysis_report_pdf(\n            self.outlier_analysis,\n            self.multiplots,\n            self.categorical_columns,\n            self.output_dir\n        )\n\n    @classmethod\n    def dry_run(cls, data: pd.DataFrame) -&gt; dict:\n        \"\"\"Simply returns generated config and displays TableOne.\"\"\"\n        analyzer = cls(data)\n        analyzer._create_config()\n\n        df_keep = analyzer.data[analyzer.continuous_columns + analyzer.categorical_columns]\n\n        print(f\"\\n\\nFeature Types:\\n  - Categorical: {analyzer.categorical_columns}\\n  - Continuous: {analyzer.continuous_columns}\")\n        print(f\"\\n\\nOutlier Analysis:\\n{analyzer.outlier_analysis}\")\n\n        mytable = TableOne(df_keep, categorical=analyzer.categorical_columns, pval=False)\n        print(mytable.tabulate(tablefmt = \"fancy_grid\"))\n\n        return analyzer.config\n</code></pre>"},{"location":"api/analyzer/#jarvais.analyzer.Analyzer.run","title":"<code>run()</code>","text":"<p>Run the data cleaning and visualization process.</p> Source code in <code>src/jarvais/analyzer/analyzer.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Run the data cleaning and visualization process.\"\"\"\n    if self.config is None:\n        self._create_config()\n    else:\n        self.continuous_columns = self.config['columns']['continuous']\n        self.categorical_columns = self.config['columns']['categorical']\n        # Replace all non numerical values with NaN\n        self.data[self.continuous_columns] = self.data[self.continuous_columns].apply(pd.to_numeric, errors='coerce')\n        self.outlier_analysis, _ = get_outliers(self.data, self.categorical_columns)\n\n    print(f\"Feature Types:\\n  - Categorical: {self.categorical_columns}\\n  - Continuous: {self.continuous_columns}\")\n    print(f\"\\n\\nOutlier Analysis:\\n{self.outlier_analysis}\")\n\n    with open(self.output_dir / 'config.yaml', 'w') as f:\n        yaml.dump(self.config, f)\n\n    self._apply_config()\n\n    # Create Table One\n    df_keep = self.data[self.continuous_columns + self.categorical_columns]\n\n    self.mytable = TableOne(df_keep, categorical=self.categorical_columns, pval=False)\n    print(self.mytable.tabulate(tablefmt = \"fancy_grid\"))\n    self.mytable.to_csv(self.output_dir / 'tableone.csv')\n\n    # PLOTS\n    figures_dir = self.output_dir / 'figures'\n    figures_dir.mkdir(exist_ok=True, parents=True)\n\n    if self.task == 'survival':\n        data_x = self.data.drop(columns=['time', 'event'])\n        data_y = self.data[['time', 'event']]\n        categorical_columns  = [cat for cat in self.categorical_columns if cat != 'event']\n        plot_kaplan_meier_by_category(\n            data_x, data_y,\n            categorical_columns,\n            figures_dir / 'kaplan_meier'\n        )\n\n    # Correlation Plots\n    p_corr = self.data[self.continuous_columns].corr(method=\"pearson\")\n    s_corr = self.data[self.continuous_columns].corr(method=\"spearman\")\n    size = len(self.continuous_columns)*1.5\n    plot_corr(p_corr, size, file_name='pearson_correlation.png', output_dir=figures_dir)\n    plot_corr(s_corr, size, file_name='spearman_correlation.png', output_dir=figures_dir)\n\n    # Categorical cross frequency table\n    plot_frequency_table(self.data, self.categorical_columns, figures_dir)\n\n    # UMAP reduced data + Plots\n    self.umap_data = plot_umap(self.data, self.continuous_columns, figures_dir)\n\n    # Plot pairplot: keeping only the top ten correlated pairs in the pair plot\n    if self.target_variable in self.categorical_columns:\n        plot_pairplot(self.data, self.continuous_columns, output_dir=figures_dir, target_variable=self.target_variable)\n    else:\n        plot_pairplot(self.data, self.continuous_columns, output_dir=figures_dir)\n\n    # Create Multiplots\n    self._create_multiplots(figures_dir)\n\n    if self.one_hot_encode:\n        self.data = pd.get_dummies(\n            self.data,\n            columns=[cat for cat in self.categorical_columns if cat != self.target_variable],\n            dtype=float,\n            prefix_sep='|' # Using this to make it obvious OHE features\n        )\n\n    self.data.to_csv(self.output_dir / 'updated_data.csv')\n\n    # Create Output PDF\n    generate_analysis_report_pdf(\n        self.outlier_analysis,\n        self.multiplots,\n        self.categorical_columns,\n        self.output_dir\n    )\n</code></pre>"},{"location":"api/analyzer/#jarvais.analyzer.Analyzer.dry_run","title":"<code>dry_run(data)</code>  <code>classmethod</code>","text":"<p>Simply returns generated config and displays TableOne.</p> Source code in <code>src/jarvais/analyzer/analyzer.py</code> <pre><code>@classmethod\ndef dry_run(cls, data: pd.DataFrame) -&gt; dict:\n    \"\"\"Simply returns generated config and displays TableOne.\"\"\"\n    analyzer = cls(data)\n    analyzer._create_config()\n\n    df_keep = analyzer.data[analyzer.continuous_columns + analyzer.categorical_columns]\n\n    print(f\"\\n\\nFeature Types:\\n  - Categorical: {analyzer.categorical_columns}\\n  - Continuous: {analyzer.continuous_columns}\")\n    print(f\"\\n\\nOutlier Analysis:\\n{analyzer.outlier_analysis}\")\n\n    mytable = TableOne(df_keep, categorical=analyzer.categorical_columns, pval=False)\n    print(mytable.tabulate(tablefmt = \"fancy_grid\"))\n\n    return analyzer.config\n</code></pre>"},{"location":"api/explainer/","title":"Explainer","text":""},{"location":"api/explainer/#explainer","title":"Explainer","text":"<p>The <code>Explainer</code> class is part of the <code>jarvais.explainer</code> module. It generates explainability reports for trained models.</p> <p>The <code>BiasExplainer</code> class is used by the <code>Explainer</code> class to run a bias audit.</p>"},{"location":"api/explainer/#jarvais.explainer.Explainer","title":"<code>jarvais.explainer.Explainer</code>","text":"<p>A class to generate diagnostic plots and reports for models trained using TrainerSupervised.</p> <p>Attributes:</p> Name Type Description <code>trainer</code> <code>TrainerSupervised</code> <p>The TrainerSupervised object containing the trained model.</p> <code>predictor</code> <code>object</code> <p>The AutoGluon predictor object used for inference.</p> <code>X_train</code> <code>DataFrame</code> <p>The training dataset used to train the model.</p> <code>X_test</code> <code>DataFrame</code> <p>The test dataset for evaluating the model.</p> <code>y_test</code> <code>DataFrame</code> <p>The true target values for the test dataset.</p> <code>output_dir</code> <code>Path</code> <p>The directory where plots, reports, and outputs are saved.</p> <code>sensitive_features</code> <code>list</code> <p>List of features considered sensitive for bias auditing.</p> Source code in <code>src/jarvais/explainer/explainer.py</code> <pre><code>class Explainer():\n    \"\"\"\n    A class to generate diagnostic plots and reports for models trained using TrainerSupervised.\n\n    Attributes:\n        trainer (TrainerSupervised): The TrainerSupervised object containing the trained model.\n        predictor (object): The AutoGluon predictor object used for inference.\n        X_train (pd.DataFrame): The training dataset used to train the model.\n        X_test (pd.DataFrame): The test dataset for evaluating the model.\n        y_test (pd.DataFrame): The true target values for the test dataset.\n        output_dir (Path): The directory where plots, reports, and outputs are saved.\n        sensitive_features (list, optional): List of features considered sensitive for bias auditing.\n    \"\"\"\n    def __init__(\n            self,\n            trainer,\n            X_train: pd.DataFrame,\n            X_test: pd.DataFrame,\n            y_test: pd.DataFrame,\n            output_dir: str | Path | None = None,\n            sensitive_features: list | None = None,\n        ) -&gt; None:\n\n        self.trainer = trainer\n        self.predictor = trainer.predictor\n        self.X_train = X_train\n        self.X_test = X_test\n        self.y_test = y_test\n        self.sensitive_features = sensitive_features\n\n        self.output_dir = Path.cwd() if output_dir is None else Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        (self.output_dir / 'figures').mkdir(parents=True, exist_ok=True)\n\n    def run(self) -&gt; None:\n        \"\"\"Generate diagnostic plots and reports for the trained model.\"\"\"\n\n        self._run_bias_audit()\n\n        plot_violin_of_bootstrapped_metrics(\n            self.trainer,\n            self.X_test,\n            self.y_test,\n            self.trainer.X_val,\n            self.trainer.y_val,\n            self.X_train,\n            self.trainer.y_train,\n            output_dir=self.output_dir / 'figures'\n        )            \n\n        if self.trainer.task in ['binary', 'multiclass']:\n            plot_classification_diagnostics(\n                self.y_test,\n                self.predictor.predict_proba(self.X_test).iloc[:, 1],\n                self.trainer.y_val,\n                self.predictor.predict_proba(self.trainer.X_val).iloc[:, 1],\n                self.trainer.y_train,\n                self.predictor.predict_proba(self.X_train).iloc[:, 1],\n                output_dir=self.output_dir / 'figures'\n            )\n            plot_shap_values(\n                self.predictor,\n                self.X_train,\n                self.X_test,\n                output_dir=self.output_dir / 'figures'\n            )\n\n        elif self.trainer.task == 'regression':\n            plot_regression_diagnostics(\n                self.y_test,\n                self.predictor.predict(self.X_test, as_pandas=False),\n                output_dir=self.output_dir / 'figures'\n            )\n\n        # Plot feature importance\n        if self.trainer.task == 'survival': # NEEDS TO BE UPDATED\n            model = self.trainer.predictors['CoxPH']\n            result = permutation_importance(model, self.X_test,\n                                            Surv.from_dataframe('event', 'time', self.y_test),\n                                            n_repeats=15)\n\n            importance_df = pd.DataFrame(\n                {\n                    \"importance\": result[\"importances_mean\"],\n                    \"stddev\": result[\"importances_std\"],\n                },\n                index=self.X_test.columns,\n            ).sort_values(by=\"importance\", ascending=False)\n            model_name = 'CoxPH'\n        else:\n            importance_df = self.predictor.feature_importance(\n                pd.concat([self.X_test, self.y_test], axis=1))\n            model_name = self.predictor.model_best\n\n        plot_feature_importance(importance_df, self.output_dir / 'figures', model_name)\n        generate_explainer_report_pdf(self.trainer.task, self.output_dir)\n\n    def _run_bias_audit(self) -&gt; List[pd.DataFrame]:\n\n        bias_output_dir = self.output_dir / 'bias'\n        bias_output_dir.mkdir(parents=True, exist_ok=True)\n\n        if self.sensitive_features is None:\n            if self.trainer.task == 'survival': # Data needs to be not be one hot encoded\n                self.sensitive_features = infer_sensitive_features(undummify(self.X_test, prefix_sep='|'))\n            else:\n                self.sensitive_features = infer_sensitive_features(self.X_test)\n\n        y_pred = None if self.trainer.task == 'survival' else pd.Series(self.trainer.infer(self.X_test) )\n        metrics = ['mean_prediction'] if self.trainer.task == 'regression' else ['mean_prediction', 'false_positive_rate'] \n\n        bias = BiasExplainer(\n            self.y_test, \n            y_pred, \n            self.sensitive_features,\n            self.trainer.task, \n            bias_output_dir,\n            metrics\n        )\n        bias.run(relative=True)\n\n    @classmethod\n    def from_trainer(cls, trainer, **kwargs):\n        \"\"\"Create Explainer object from TrainerSupervised object.\"\"\"\n        return cls(trainer, trainer.X_train, trainer.X_test, trainer.y_test, trainer.output_dir, **kwargs)\n</code></pre>"},{"location":"api/explainer/#jarvais.explainer.Explainer.run","title":"<code>run()</code>","text":"<p>Generate diagnostic plots and reports for the trained model.</p> Source code in <code>src/jarvais/explainer/explainer.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Generate diagnostic plots and reports for the trained model.\"\"\"\n\n    self._run_bias_audit()\n\n    plot_violin_of_bootstrapped_metrics(\n        self.trainer,\n        self.X_test,\n        self.y_test,\n        self.trainer.X_val,\n        self.trainer.y_val,\n        self.X_train,\n        self.trainer.y_train,\n        output_dir=self.output_dir / 'figures'\n    )            \n\n    if self.trainer.task in ['binary', 'multiclass']:\n        plot_classification_diagnostics(\n            self.y_test,\n            self.predictor.predict_proba(self.X_test).iloc[:, 1],\n            self.trainer.y_val,\n            self.predictor.predict_proba(self.trainer.X_val).iloc[:, 1],\n            self.trainer.y_train,\n            self.predictor.predict_proba(self.X_train).iloc[:, 1],\n            output_dir=self.output_dir / 'figures'\n        )\n        plot_shap_values(\n            self.predictor,\n            self.X_train,\n            self.X_test,\n            output_dir=self.output_dir / 'figures'\n        )\n\n    elif self.trainer.task == 'regression':\n        plot_regression_diagnostics(\n            self.y_test,\n            self.predictor.predict(self.X_test, as_pandas=False),\n            output_dir=self.output_dir / 'figures'\n        )\n\n    # Plot feature importance\n    if self.trainer.task == 'survival': # NEEDS TO BE UPDATED\n        model = self.trainer.predictors['CoxPH']\n        result = permutation_importance(model, self.X_test,\n                                        Surv.from_dataframe('event', 'time', self.y_test),\n                                        n_repeats=15)\n\n        importance_df = pd.DataFrame(\n            {\n                \"importance\": result[\"importances_mean\"],\n                \"stddev\": result[\"importances_std\"],\n            },\n            index=self.X_test.columns,\n        ).sort_values(by=\"importance\", ascending=False)\n        model_name = 'CoxPH'\n    else:\n        importance_df = self.predictor.feature_importance(\n            pd.concat([self.X_test, self.y_test], axis=1))\n        model_name = self.predictor.model_best\n\n    plot_feature_importance(importance_df, self.output_dir / 'figures', model_name)\n    generate_explainer_report_pdf(self.trainer.task, self.output_dir)\n</code></pre>"},{"location":"api/explainer/#jarvais.explainer.Explainer.from_trainer","title":"<code>from_trainer(trainer, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create Explainer object from TrainerSupervised object.</p> Source code in <code>src/jarvais/explainer/explainer.py</code> <pre><code>@classmethod\ndef from_trainer(cls, trainer, **kwargs):\n    \"\"\"Create Explainer object from TrainerSupervised object.\"\"\"\n    return cls(trainer, trainer.X_train, trainer.X_test, trainer.y_test, trainer.output_dir, **kwargs)\n</code></pre>"},{"location":"api/explainer/#jarvais.explainer.BiasExplainer","title":"<code>jarvais.explainer.BiasExplainer</code>","text":"<p>A class for explaining and analyzing bias in a predictive model's outcomes based on sensitive features.</p> <p>This class performs various fairness audits by evaluating predictive outcomes with respect to sensitive features such as gender, age, race, and more. It first runs statistical analyses using the OLS regression F-statistic p-value to assess any possibility  of bias in the model's predictions based on sensitive features. If the p-value is less than 0.05, indicating potential bias,  the class generates visualizations (such as violin plots) and calculates fairness metrics (e.g., demographic parity, equalized odds).  The results are presented for each sensitive feature, with optional relative fairness comparisons.</p> <p>Attributes:</p> Name Type Description <code>y_true</code> <code>DataFrame</code> <p>The true target values for the model.</p> <code>y_pred</code> <code>DataFrame</code> <p>The predicted values from the model.</p> <code>sensitive_features</code> <code>dict or DataFrame</code> <p>A dictionary or DataFrame containing sensitive features used for fairness analysis.</p> <code>metrics</code> <code>list</code> <p>A list of metrics to calculate for fairness analysis. Defaults to ['mean_prediction', 'false_positive_rate', 'true_positive_rate'].</p> <code>mapper</code> <code>dict</code> <p>A dictionary mapping internal metric names to user-friendly descriptions.</p> <code>kwargs</code> <code>dict</code> <p>Additional parameters passed to various methods, such as metric calculation and plot generation.</p> Source code in <code>src/jarvais/explainer/bias.py</code> <pre><code>class BiasExplainer():\n    \"\"\"\n    A class for explaining and analyzing bias in a predictive model's outcomes based on sensitive features.\n\n    This class performs various fairness audits by evaluating predictive outcomes with respect to sensitive features such as\n    gender, age, race, and more. It first runs statistical analyses using the OLS regression F-statistic p-value to assess any possibility \n    of bias in the model's predictions based on sensitive features. If the p-value is less than 0.05, indicating potential bias, \n    the class generates visualizations (such as violin plots) and calculates fairness metrics (e.g., demographic parity, equalized odds). \n    The results are presented for each sensitive feature, with optional relative fairness comparisons.\n\n    Attributes:\n        y_true (pd.DataFrame):\n            The true target values for the model.\n        y_pred (pd.DataFrame):\n            The predicted values from the model.\n        sensitive_features (dict or pd.DataFrame):\n            A dictionary or DataFrame containing sensitive features used for fairness analysis.\n        metrics (list):\n            A list of metrics to calculate for fairness analysis. Defaults to ['mean_prediction', 'false_positive_rate', 'true_positive_rate'].\n        mapper (dict):\n            A dictionary mapping internal metric names to user-friendly descriptions.\n        kwargs (dict):\n            Additional parameters passed to various methods, such as metric calculation and plot generation.\n    \"\"\"\n    def __init__(\n            self, \n            y_true: pd.Series, \n            y_pred: np.ndarray, \n            sensitive_features: dict, \n            task: str,\n            output_dir: Path,\n            metrics: list = ['mean_prediction', 'false_positive_rate', 'true_positive_rate'], \n            **kwargs: dict\n        ) -&gt; None:\n        self.y_true = y_true\n        self.y_pred = y_pred\n        self.task = task\n        self.output_dir = output_dir\n        self.mapper = {\"mean_prediction\": \"Demographic Parity\",\n                       \"false_positive_rate\": \"(FPR) Equalized Odds\",\n                       \"true_positive_rate\": \"(TPR) Equalized Odds or Equal Opportunity\"}\n        self.metrics = metrics\n        self.kwargs = kwargs\n\n        # Convert sensitive_features to DataFrame or leave as Series\n        if isinstance(sensitive_features, pd.DataFrame) or isinstance(sensitive_features, pd.Series):\n            self.sensitive_features = sensitive_features\n        elif isinstance(sensitive_features, dict):\n            self.sensitive_features = pd.DataFrame.from_dict(sensitive_features)\n        elif isinstance(sensitive_features, list):\n            if any(isinstance(item, list) for item in sensitive_features):\n                self.sensitive_features = pd.DataFrame(sensitive_features, columns=[f'sensitive_feature_{i}' for i in range(len(sensitive_features))])\n            else:\n                self.sensitive_features = pd.DataFrame(sensitive_features, columns=['sensitive_feature'])\n        else:\n            raise ValueError(\"sensitive_features must be a pandas DataFrame, Series, dictionary or list\")\n\n    def _generate_violin(self, sensitive_feature: str, bias_metric:np.ndarray) -&gt; None:\n        \"\"\"Generate a violin plot for the bias metric.\"\"\"\n        plt.figure(figsize=(8, 6)) \n        sns.set_theme(style=\"whitegrid\")  \n\n        sns.violinplot(\n            x=self.sensitive_features[sensitive_feature], \n            y=bias_metric, \n            palette=\"muted\",  \n            inner=\"quart\", \n            linewidth=1.25 \n        )\n\n        bias_metric_name = 'log_loss' if self.task == 'binary' else 'root_mean_squared_error'\n\n        plt.title(f'{bias_metric_name.title()} Distribution by {sensitive_feature}', fontsize=16, weight='bold')  \n        plt.xlabel(f'{sensitive_feature}', fontsize=14)  \n        plt.ylabel(f'{bias_metric_name.title()} per Patient', fontsize=14) \n        plt.xticks(rotation=45, ha='right')\n\n        plt.tight_layout()  \n        plt.savefig(self.output_dir / f'{sensitive_feature}_{bias_metric_name}.png') \n        plt.show()\n\n    def _subgroup_analysis_OLS(self, sensitive_feature: str, bias_metric:np.ndarray) -&gt; float:\n        \"\"\"Fit a statsmodels OLS model to the bias metric data, using the sensitive feature and print summary based on p_val.\"\"\"\n        one_hot_encoded = pd.get_dummies(self.sensitive_features[sensitive_feature], prefix=sensitive_feature)\n        X_columns = one_hot_encoded.columns\n\n        X = one_hot_encoded.values  \n        y = bias_metric  \n\n        X = sm.add_constant(X.astype(float), has_constant='add')\n        model = sm.OLS(y, X).fit()\n\n        if model.f_pvalue &lt; 0.05:\n            output = []\n\n            print(f\"\u26a0\ufe0f  **Possible Bias Detected in {sensitive_feature.title()}** \u26a0\ufe0f\\n\")\n            output.append(f\"=== Subgroup Analysis for '{sensitive_feature.title()}' Using OLS Regression ===\\n\")\n\n            output.append(\"Model Statistics:\")\n            output.append(f\"    R-squared:                  {model.rsquared:.3f}\")\n            output.append(f\"    F-statistic:                {model.fvalue:.3f}\")\n            output.append(f\"    F-statistic p-value:        {model.f_pvalue:.4f}\")\n            output.append(f\"    AIC:                        {model.aic:.2f}\")\n            output.append(f\"    Log-Likelihood:             {model.llf:.2f}\")\n\n            summary_df = pd.DataFrame({\n                'Feature': ['const'] + X_columns.tolist(),     # Predictor names (includes 'const' if added)\n                'Coefficient': model.params,    # Coefficients\n                'Standard Error': model.bse     # Standard Errors\n            })\n            table_output = tabulate(summary_df, headers='keys', tablefmt='simple_grid', showindex=False, floatfmt=\".3f\")\n            output.append(\"Model Coefficients:\")\n            output.append('\\n'.join(['    ' + line for line in table_output.split('\\n')]))\n\n            output_text = '\\n'.join(output)\n            print(output_text)\n\n            with open(self.output_dir / f'{sensitive_feature}_Cox_model_summary.txt', 'w') as f:\n                f.write(output_text)\n\n        return model.f_pvalue\n\n    def _subgroup_analysis_CoxPH(self, sensitive_feature: str) -&gt; None:\n        \"\"\"Fit a CoxPH model using the sensitive feature and print summary based on p_val.\"\"\"\n        one_hot_encoded = pd.get_dummies(self.sensitive_features[sensitive_feature], prefix=sensitive_feature)\n        df_encoded = self.y_true.join(one_hot_encoded)\n\n        cph = CoxPHFitter(penalizer=0.0001)\n        cph.fit(df_encoded, duration_col='time', event_col='event')            \n\n        if cph.log_likelihood_ratio_test().p_value &lt; 0.05:\n            output = []\n\n            print(f\"\u26a0\ufe0f  **Possible Bias Detected in {sensitive_feature.title()}** \u26a0\ufe0f\")\n            output.append(f\"=== Subgroup Analysis for '{sensitive_feature.title()}' Using Cox Proportional Hazards Model ===\\n\")\n\n            output.append(\"Model Statistics:\")\n            output.append(f\"    AIC (Partial):               {cph.AIC_partial_:.2f}\")\n            output.append(f\"    Log-Likelihood:              {cph.log_likelihood_:.2f}\")\n            output.append(f\"    Log-Likelihood Ratio p-value: {cph.log_likelihood_ratio_test().p_value:.4f}\")\n            output.append(f\"    Concordance Index (C-index):   {cph.concordance_index_:.2f}\")\n\n            summary_df = pd.DataFrame({\n                'Feature': cph.summary.index.to_list(),\n                'Coefficient': cph.summary['coef'].to_list(),\n                'Standard Error': cph.summary['se(coef)'].to_list()\n            })\n            table_output = tabulate(summary_df, headers='keys', tablefmt='grid', showindex=False, floatfmt=\".3f\")\n            output.append(\"Model Coefficients:\")\n            output.append('\\n'.join(['    ' + line for line in table_output.split('\\n')]))\n\n            output_text = '\\n'.join(output)\n            print(output_text)\n\n            with open(self.output_dir / f'{sensitive_feature}_OLS_model_summary.txt', 'w') as f:\n                f.write(output_text)\n\n    def _calculate_fair_metrics(\n            self, \n            sensitive_feature: str, \n            fairness_threshold: float, \n            relative: bool\n        ) -&gt; pd.DataFrame:\n        \"\"\"Calculate the Fairlearn metrics and return the results in a DataFrame.\"\"\"\n        _metrics = {metric: get_metric(metric, sensitive_features=self.sensitive_features[sensitive_feature]) for metric in self.metrics}\n        metric_frame = fm.MetricFrame(\n            metrics=_metrics, \n            y_true=self.y_true, \n            y_pred=self.y_pred, \n            sensitive_features=self.sensitive_features[sensitive_feature], \n            **self.kwargs\n        )\n        result = pd.DataFrame(metric_frame.by_group.T, index=_metrics.keys())\n        result = result.rename(columns=self.mapper)\n\n        if relative:\n            largest_feature = self.sensitive_features[sensitive_feature].mode().iloc[0]\n            results_relative = result.T / result[largest_feature]\n            results_relative = results_relative.applymap(\n                lambda x: f\"{x:.3f} \u2705\" if x &lt;= fairness_threshold or 1/x &lt;= fairness_threshold \n                else f\"{x:.3f} \u274c\")\n            result = pd.concat([result, results_relative.T.rename(index=lambda x: f\"Relative {x}\")])\n\n        return result\n\n    def run(\n            self, \n            relative: bool = False, \n            fairness_threshold: float = 1.2\n        ) -&gt; None:\n        \"\"\"\n        Runs the bias explainer analysis on the provided data. It first evaluates the potential bias in the model's predictions\n        using the OLS regression F-statistic p-value. If the p-value is below the threshold of 0.05, indicating \n        potential bias in the sensitive feature, the method proceeds to generate visualizations and calculate fairness metrics.\n\n        Args:\n            relative (bool): \n                If True, the metrics will be presented relative to the most frequent value of each sensitive feature.\n            fairness_threshold (float): \n                A threshold for determining fairness based on relative metrics. If the relative metric exceeds this threshold, \n                a warning flag will be applied.\n        \"\"\"\n        if self.task == 'binary':\n            y_true_array = self.y_true.to_numpy()\n            bias_metric = np.array([\n                log_loss([y_true_array[idx]], [self.y_pred[idx]], labels=np.unique(y_true_array))\n                for idx in range(len(y_true_array))\n            ])\n            self.y_pred = (self.y_pred &gt;= .5).astype(int)\n        elif self.task == 'regression':\n            bias_metric = np.sqrt((self.y_true.to_numpy() - self.y_pred) ** 2)\n\n        self.results = []\n        for sensitive_feature in self.sensitive_features.columns:\n            if self.task == 'survival':\n                self._subgroup_analysis_CoxPH(sensitive_feature)\n            else:\n                f_pvalue = self._subgroup_analysis_OLS(sensitive_feature, bias_metric)\n                if f_pvalue &lt; 0.05:\n                    self._generate_violin(sensitive_feature, bias_metric)\n                    result = self._calculate_fair_metrics(sensitive_feature, fairness_threshold, relative)\n\n                    print(f\"\\n=== Subgroup Analysis for '{sensitive_feature.title()}' using FairLearn ===\\n\")\n                    table_output = tabulate(result.iloc[:, :4], headers='keys', tablefmt='fancy_grid')\n                    print('\\n'.join(['    ' + line for line in table_output.split('\\n')]), '\\n')\n\n                    result.to_csv(self.output_dir / f'{sensitive_feature}_fm_metrics.csv')\n</code></pre>"},{"location":"api/explainer/#jarvais.explainer.BiasExplainer.run","title":"<code>run(relative=False, fairness_threshold=1.2)</code>","text":"<p>Runs the bias explainer analysis on the provided data. It first evaluates the potential bias in the model's predictions using the OLS regression F-statistic p-value. If the p-value is below the threshold of 0.05, indicating  potential bias in the sensitive feature, the method proceeds to generate visualizations and calculate fairness metrics.</p> <p>Parameters:</p> Name Type Description Default <code>relative</code> <code>bool</code> <p>If True, the metrics will be presented relative to the most frequent value of each sensitive feature.</p> <code>False</code> <code>fairness_threshold</code> <code>float</code> <p>A threshold for determining fairness based on relative metrics. If the relative metric exceeds this threshold,  a warning flag will be applied.</p> <code>1.2</code> Source code in <code>src/jarvais/explainer/bias.py</code> <pre><code>def run(\n        self, \n        relative: bool = False, \n        fairness_threshold: float = 1.2\n    ) -&gt; None:\n    \"\"\"\n    Runs the bias explainer analysis on the provided data. It first evaluates the potential bias in the model's predictions\n    using the OLS regression F-statistic p-value. If the p-value is below the threshold of 0.05, indicating \n    potential bias in the sensitive feature, the method proceeds to generate visualizations and calculate fairness metrics.\n\n    Args:\n        relative (bool): \n            If True, the metrics will be presented relative to the most frequent value of each sensitive feature.\n        fairness_threshold (float): \n            A threshold for determining fairness based on relative metrics. If the relative metric exceeds this threshold, \n            a warning flag will be applied.\n    \"\"\"\n    if self.task == 'binary':\n        y_true_array = self.y_true.to_numpy()\n        bias_metric = np.array([\n            log_loss([y_true_array[idx]], [self.y_pred[idx]], labels=np.unique(y_true_array))\n            for idx in range(len(y_true_array))\n        ])\n        self.y_pred = (self.y_pred &gt;= .5).astype(int)\n    elif self.task == 'regression':\n        bias_metric = np.sqrt((self.y_true.to_numpy() - self.y_pred) ** 2)\n\n    self.results = []\n    for sensitive_feature in self.sensitive_features.columns:\n        if self.task == 'survival':\n            self._subgroup_analysis_CoxPH(sensitive_feature)\n        else:\n            f_pvalue = self._subgroup_analysis_OLS(sensitive_feature, bias_metric)\n            if f_pvalue &lt; 0.05:\n                self._generate_violin(sensitive_feature, bias_metric)\n                result = self._calculate_fair_metrics(sensitive_feature, fairness_threshold, relative)\n\n                print(f\"\\n=== Subgroup Analysis for '{sensitive_feature.title()}' using FairLearn ===\\n\")\n                table_output = tabulate(result.iloc[:, :4], headers='keys', tablefmt='fancy_grid')\n                print('\\n'.join(['    ' + line for line in table_output.split('\\n')]), '\\n')\n\n                result.to_csv(self.output_dir / f'{sensitive_feature}_fm_metrics.csv')\n</code></pre>"},{"location":"api/functional/","title":"Functional","text":""},{"location":"api/functional/#functional","title":"Functional","text":""},{"location":"api/functional/#jarvais.utils.functional","title":"<code>jarvais.utils.functional</code>","text":""},{"location":"api/functional/#jarvais.utils.functional.auprc","title":"<code>auprc(y_true, y_scores)</code>","text":"<p>Calculate the Area Under the Precision-Recall Curve (AUPRC).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>True binary labels. Shape (n_samples,).</p> required <code>y_scores</code> <code>ndarray</code> <p>Predicted scores or probabilities. Shape (n_samples,).</p> required <p>Returns:</p> Name Type Description <code>auprc_score</code> <code>float</code> <p>The AUPRC value.</p> Source code in <code>src/jarvais/utils/functional.py</code> <pre><code>def auprc(y_true: np.ndarray, y_scores: np.ndarray) -&gt; float:\n    \"\"\"\n    Calculate the Area Under the Precision-Recall Curve (AUPRC).\n\n    Args:\n        y_true (np.ndarray): True binary labels. Shape (n_samples,).\n        y_scores (np.ndarray): Predicted scores or probabilities. Shape (n_samples,).\n\n    Returns:\n        auprc_score (float): The AUPRC value.\n    \"\"\"\n    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n    return auc(recall, precision)\n</code></pre>"},{"location":"api/functional/#jarvais.utils.functional.ci_wrapper","title":"<code>ci_wrapper(y_true, y_pred)</code>","text":"<p>Wrapper for <code>sksurv.metrics.concordance_index_censored</code> to ensure compatibility  with <code>bootstrap_metric</code>.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>A 2D NumPy array of shape (n_samples, 2), where: - <code>y_true[:, 0]</code> represents the observed survival times. - <code>y_true[:, 1]</code> represents the event indicator    (1 if the event occurred, 0 if censored).</p> required <code>y_pred</code> <code>ndarray</code> <p>A 1D NumPy array of predicted risk scores or  survival times. Higher scores typically indicate higher risk.</p> required <p>Returns:</p> Name Type Description <code>concordance_index</code> <code>float</code> <p>The concordance index.</p> Source code in <code>src/jarvais/utils/functional.py</code> <pre><code>def ci_wrapper(y_true: np.ndarray, y_pred: np.ndarray) -&gt; float:\n    \"\"\"\n    Wrapper for `sksurv.metrics.concordance_index_censored` to ensure compatibility \n    with `bootstrap_metric`.\n\n    Args:\n        y_true (np.ndarray): A 2D NumPy array of shape (n_samples, 2), where:\n            - `y_true[:, 0]` represents the observed survival times.\n            - `y_true[:, 1]` represents the event indicator \n              (1 if the event occurred, 0 if censored).\n        y_pred (np.ndarray): A 1D NumPy array of predicted risk scores or \n            survival times. Higher scores typically indicate higher risk.\n\n    Returns:\n        concordance_index (float): The concordance index.\n    \"\"\"\n    time = y_true[:, 0]\n    event = y_true[:, 1]\n\n    return concordance_index_censored(event.astype(bool), time, y_pred)[0]\n</code></pre>"},{"location":"api/functional/#jarvais.utils.functional.bootstrap_metric","title":"<code>bootstrap_metric(y_true, y_pred, metric_func, nsamples=100)</code>","text":"<p>Compute a metric using bootstrapping to estimate its variability.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>True labels. Shape (n_samples,).</p> required <code>y_pred</code> <code>ndarray</code> <p>Predicted values. Shape (n_samples,).</p> required <code>metric_func</code> <code>Callable[[ndarray, ndarray], float]</code> <p>A function that calculates the metric.</p> required <code>nsamples</code> <code>int</code> <p>The number of bootstrap samples. Defaults to 100.</p> <code>100</code> <p>Returns:</p> Name Type Description <code>bootstrapped_values</code> <code>List[float]</code> <p>A list of metric values computed on each bootstrap sample.</p> Source code in <code>src/jarvais/utils/functional.py</code> <pre><code>def bootstrap_metric(\n        y_true: np.ndarray,\n        y_pred: np.ndarray,\n        metric_func: Callable[[np.ndarray, np.ndarray], float],\n        nsamples: int = 100\n    ) -&gt; List[float]:\n    \"\"\"\n    Compute a metric using bootstrapping to estimate its variability.\n\n    Args:\n        y_true (np.ndarray): True labels. Shape (n_samples,).\n        y_pred (np.ndarray): Predicted values. Shape (n_samples,).\n        metric_func (Callable[[np.ndarray, np.ndarray], float]): A function that calculates the metric.\n        nsamples (int, optional): The number of bootstrap samples. Defaults to 100.\n\n    Returns:\n        bootstrapped_values (List[float]): A list of metric values computed on each bootstrap sample.\n    \"\"\"\n    np.random.seed(0)\n    values = []\n\n    for _ in range(nsamples):\n        idx = np.random.randint(len(y_true), size=len(y_true))\n        pred_sample = y_pred[idx]\n        y_true_sample = y_true[idx]\n        val = metric_func(y_true_sample, pred_sample)\n        values.append(val)\n\n    return values\n</code></pre>"},{"location":"api/functional/#jarvais.utils.functional.undummify","title":"<code>undummify(df, prefix_sep='_')</code>","text":"<p>Undummifies a DataFrame by collapsing dummy/one-hot encoded columns back into their original categorical column.</p> <p>Found here: https://stackoverflow.com/a/62085741</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input DataFrame containing dummy/one-hot encoded columns.</p> required <code>prefix_sep</code> <code>str</code> <p>The separator used to distinguish between the prefix (category) and the column name in the dummy columns.  Defaults to \"_\".</p> <code>'_'</code> <p>Returns:</p> Name Type Description <code>undummified_df</code> <code>DataFrame</code> <p>A new DataFrame with the undummified (reconstructed) categorical columns.</p> Source code in <code>src/jarvais/utils/functional.py</code> <pre><code>def undummify(df, prefix_sep=\"_\"):\n    \"\"\"\n    Undummifies a DataFrame by collapsing dummy/one-hot encoded columns back into their original categorical column.\n\n    Found here: https://stackoverflow.com/a/62085741\n\n    Args:\n        df (pandas.DataFrame): The input DataFrame containing dummy/one-hot encoded columns.\n        prefix_sep (str, optional): The separator used to distinguish between the prefix (category) and the column name in the dummy columns. \n            Defaults to \"_\".\n\n    Returns:\n        undummified_df (pandas.DataFrame): A new DataFrame with the undummified (reconstructed) categorical columns.\n    \"\"\"\n    dummy_cols = {\n        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n    }\n    series_list = []\n    for col, needs_to_collapse in dummy_cols.items():\n        if needs_to_collapse:\n            undummified = (\n                df.filter(like=col)\n                .idxmax(axis=1)\n                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n                .rename(col)\n            )\n            series_list.append(undummified)\n        else:\n            series_list.append(df[col])\n    undummified_df = pd.concat(series_list, axis=1)\n    return undummified_df\n</code></pre>"},{"location":"api/pdf/","title":"PDF","text":""},{"location":"api/pdf/#pdf","title":"PDF","text":""},{"location":"api/pdf/#jarvais.utils.pdf","title":"<code>jarvais.utils.pdf</code>","text":""},{"location":"api/pdf/#jarvais.utils.pdf.generate_analysis_report_pdf","title":"<code>generate_analysis_report_pdf(outlier_analysis, multiplots, categorical_columns, output_dir)</code>","text":"<p>Generate a PDF report for the analysis, including plots, tables, and outlier analysis.</p> <p>Parameters:</p> Name Type Description Default <code>outlier_analysis</code> <code>str</code> <p>Text summary of outlier analysis to include in the report.</p> required <code>multiplots</code> <code>list</code> <p>A list of paths to plots to include in the multiplots section.</p> required <code>categorical_columns</code> <code>list</code> <p>A list of categorical columns to use for multiplots.</p> required <code>output_dir</code> <code>str | Path</code> <p>The directory where the generated PDF report will be saved.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>The function saves the generated PDF to the specified output directory.</p> Source code in <code>src/jarvais/utils/pdf.py</code> <pre><code>def generate_analysis_report_pdf(\n        outlier_analysis: str,\n        multiplots: list,\n        categorical_columns: list,\n        output_dir: str | Path\n    ) -&gt; None:\n    \"\"\"\n    Generate a PDF report for the analysis, including plots, tables, and outlier analysis.\n\n    Args:\n        outlier_analysis (str): Text summary of outlier analysis to include in the report.\n        multiplots (list): A list of paths to plots to include in the multiplots section.\n        categorical_columns (list): A list of categorical columns to use for multiplots.\n        output_dir (str | Path): The directory where the generated PDF report will be saved.\n\n    Returns:\n        None: The function saves the generated PDF to the specified output directory.\n    \"\"\"\n    output_dir = Path(output_dir)\n    figures_dir = output_dir / 'figures'\n\n    # Instantiate PDF\n    pdf = FPDF()\n    pdf.add_page()\n    script_dir = Path(__file__).resolve().parent\n\n    # Adding unicode fonts\n    font_path = (script_dir / 'fonts/Inter_28pt-Regular.ttf')\n    pdf.add_font(\"inter\", style=\"\", fname=font_path)\n    font_path = (script_dir / 'fonts/Inter_28pt-Bold.ttf')\n    pdf.add_font(\"inter\", style=\"b\", fname=font_path)\n    pdf.set_font('inter', '', 24)\n\n    # Title\n    pdf.write(5, \"Analysis Report\\n\\n\")\n\n    # Add outlier analysis\n    if outlier_analysis != '':\n        pdf.set_font('inter', '', 12)\n        pdf.write(5, \"Outlier Analysis:\\n\")\n        pdf.set_font('inter', '', 10)\n        pdf.write(5, outlier_analysis)\n\n    # Add page-wide pairplots\n    pdf.image((figures_dir / 'pairplot.png'), Align.C, w=pdf.epw-20)\n    pdf.add_page()\n\n    # Add correlation plots\n    pdf.image((figures_dir / 'pearson_correlation.png'), Align.C, h=pdf.eph/2)\n    pdf.image((figures_dir / 'spearman_correlation.png'), Align.C, h=pdf.eph/2)\n\n    # Add multiplots\n    if multiplots and categorical_columns:\n        pdf = _add_multiplots(pdf, multiplots, categorical_columns)\n\n    # Add demographic breakdown \"table one\"\n    path_tableone = output_dir / 'tableone.csv'\n    if path_tableone.exists():\n        csv_df = pd.read_csv(path_tableone, na_filter=False).astype(str)\n        pdf = _add_table(pdf, csv_df)\n\n    # Save PDF\n    pdf.output(output_dir / 'analysis_report.pdf')\n</code></pre>"},{"location":"api/pdf/#jarvais.utils.pdf.generate_explainer_report_pdf","title":"<code>generate_explainer_report_pdf(problem_type, output_dir)</code>","text":"<p>Generate a PDF report for the explainer with visualizations and metrics.</p> <p>This function creates a PDF report that includes plots and metrics  relevant to the specified problem type. The report is saved in the  specified output directory.</p> <p>Parameters:</p> Name Type Description Default <code>problem_type</code> <code>str</code> <p>The type of machine learning problem.  Supported values are 'binary', 'multiclass', 'regression',  and 'survival'.</p> required <code>output_dir</code> <code>str | Path</code> <p>The directory where the generated PDF  report will be saved.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>The function saves the generated PDF to the specified output directory.</p> Source code in <code>src/jarvais/utils/pdf.py</code> <pre><code>def generate_explainer_report_pdf(\n        problem_type: str,\n        output_dir: str | Path\n    ) -&gt; None:\n    \"\"\"\n    Generate a PDF report for the explainer with visualizations and metrics.\n\n    This function creates a PDF report that includes plots and metrics \n    relevant to the specified problem type. The report is saved in the \n    specified output directory.\n\n    Args:\n        problem_type (str): The type of machine learning problem. \n            Supported values are 'binary', 'multiclass', 'regression', \n            and 'survival'.\n        output_dir (str | Path): The directory where the generated PDF \n            report will be saved.\n\n    Returns:\n        None: The function saves the generated PDF to the specified output directory.\n    \"\"\"\n    output_dir = Path(output_dir)\n    figures_dir = output_dir / 'figures'\n\n    # Instantiate PDF\n    pdf = FPDF()\n    pdf.add_page()\n    script_dir = Path(__file__).resolve().parent\n\n    # Adding unicode fonts\n    font_path = (script_dir / 'fonts/Inter_28pt-Regular.ttf')\n    pdf.add_font(\"inter\", style=\"\", fname=font_path)\n    font_path = (script_dir / 'fonts/Inter_28pt-Bold.ttf')\n    pdf.add_font(\"inter\", style=\"b\", fname=font_path)\n    pdf.set_font('inter', '', 24)\n\n    # Title\n    pdf.write(5, \"Explainer Report\\n\\n\")\n\n    pdf.image((figures_dir / 'test_metrics_bootstrap.png'), Align.C, h=pdf.eph//3.5, w=pdf.epw-20)\n    pdf.image((figures_dir / 'validation_metrics_bootstrap.png'), Align.C, h=pdf.eph//3.5, w=pdf.epw-20)\n    pdf.image((figures_dir /  'train_metrics_bootstrap.png'), Align.C, h=pdf.eph//3.5, w=pdf.epw-20)\n    pdf.add_page()\n\n    pdf.image((figures_dir / 'feature_importance.png'), Align.C, w=pdf.epw-20)\n    pdf.add_page()\n\n    if problem_type in ['binary', 'multiclass']:\n        pdf.image((figures_dir / 'model_evaluation.png'), Align.C, w=pdf.epw-20)\n        pdf.image((figures_dir / 'confusion_matrix.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n        pdf.add_page()\n\n        pdf.image((figures_dir / 'shap_barplot.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n        pdf.image((output_dir /  'figures' / 'shap_heatmap.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n    elif problem_type == 'regression':\n        pdf.image((figures_dir / 'residual_plot.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n        pdf.image((output_dir /  'figures' / 'true_vs_predicted.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n\n    # Save PDF\n    pdf.output((output_dir / 'explainer_report.pdf'))\n</code></pre>"},{"location":"api/plot/","title":"Plotting","text":""},{"location":"api/plot/#plot","title":"Plot","text":""},{"location":"api/plot/#jarvais.utils.plot","title":"<code>jarvais.utils.plot</code>","text":""},{"location":"api/plot/#jarvais.utils.plot.plot_corr","title":"<code>plot_corr(corr, size, output_dir, file_name='correlation_matrix.png')</code>","text":"<p>Plots a lower-triangle heatmap of the correlation matrix and saves it as an image file.</p> <p>Parameters:</p> Name Type Description Default <code>corr</code> <code>DataFrame</code> <p>Correlation matrix to visualize.</p> required <code>size</code> <code>float</code> <p>Size of the heatmap figure.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the output image.</p> required <code>file_name</code> <code>str</code> <p>Name of the saved image file. Defaults to 'correlation_matrix.png'.</p> <code>'correlation_matrix.png'</code> Example <pre><code>import pandas as pd\nfrom pathlib import Path\n\n# Sample data\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [5, 4, 3, 2, 1],\n    'C': [2, 3, 4, 5, 6]\n})\n\n# Compute Spearman correlation\ncorr_matrix = df.corr(method='spearman')\n\n# Plot and save the heatmap\nplot_corr(corr=corr_matrix, size=6, output_dir=Path('./output'))\n</code></pre> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_corr(\n        corr: pd.DataFrame,\n        size: float,\n        output_dir: Path,\n        file_name: str = 'correlation_matrix.png'\n    ) -&gt; None:\n    \"\"\"\n    Plots a lower-triangle heatmap of the correlation matrix and saves it as an image file.\n\n    Args:\n        corr (pd.DataFrame): Correlation matrix to visualize.\n        size (float): Size of the heatmap figure.\n        output_dir (Path): Directory to save the output image.\n        file_name (str): Name of the saved image file. Defaults to 'correlation_matrix.png'.\n\n    Example:\n        ```python\n        import pandas as pd\n        from pathlib import Path\n\n        # Sample data\n        df = pd.DataFrame({\n            'A': [1, 2, 3, 4, 5],\n            'B': [5, 4, 3, 2, 1],\n            'C': [2, 3, 4, 5, 6]\n        })\n\n        # Compute Spearman correlation\n        corr_matrix = df.corr(method='spearman')\n\n        # Plot and save the heatmap\n        plot_corr(corr=corr_matrix, size=6, output_dir=Path('./output'))\n        ```\n    \"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(size, size))\n    mask = np.triu(np.ones_like(corr, dtype=bool)) # Keep only lower triangle\n    np.fill_diagonal(mask, False)\n    sns.heatmap(corr, mask=mask, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidth=.5, fmt=\"1.2f\", ax=ax)\n    plt.title('Correlation Matrix')\n    plt.tight_layout()\n\n    figure_path = output_dir / file_name\n    fig.savefig(figure_path)\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_frequency_table","title":"<code>plot_frequency_table(data, columns, output_dir)</code>","text":"<p>Generates and saves heatmap visualizations for frequency tables of all column pair combinations.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input dataset containing the columns to analyze.</p> required <code>columns</code> <code>list</code> <p>List of column names to create frequency tables for.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the generated heatmaps.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_frequency_table(\n        data: pd.DataFrame,\n        columns: list,\n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Generates and saves heatmap visualizations for frequency tables of all column pair combinations.\n\n    Args:\n        data (pd.DataFrame): Input dataset containing the columns to analyze.\n        columns (list): List of column names to create frequency tables for.\n        output_dir (Path): Directory to save the generated heatmaps.\n    \"\"\"\n    frequency_dir = Path(output_dir) / 'frequency_tables'\n    frequency_dir.mkdir(parents=True, exist_ok=True)\n\n    for column_1, column_2 in combinations(columns, 2):\n        heatmap_data = pd.crosstab(data[column_1], data[column_2])\n        plt.figure(figsize=(8, 6))\n        sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt='d', linewidth=.5)\n        plt.title(f'Frequency Table for {column_1} and {column_2}')\n        plt.xlabel(column_2)\n        plt.ylabel(column_1)\n        plt.savefig(frequency_dir / f'{column_1}_vs_{column_2}.png')\n        plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_pairplot","title":"<code>plot_pairplot(data, continuous_columns, output_dir, target_variable=None, n_keep=10)</code>","text":"<p>Generates a pair plot of the specified continuous columns in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The input DataFrame containing the data to be visualized.</p> required <code>continuous_columns</code> <code>list</code> <p>A list of column names corresponding to continuous variables.</p> required <code>output_dir</code> <code>Path</code> <p>Directory where the resulting plot will be saved.</p> required <code>target_variable</code> <code>str</code> <p>The target variable to use as a hue for coloring the pair plot. Defaults to None.</p> <code>None</code> <code>n_keep</code> <code>int</code> <p>The maximum number of continuous columns to include in the plot.  If exceeded, the most correlated columns are selected. Defaults to 10.</p> <code>10</code> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_pairplot(\n        data: pd.DataFrame,\n        continuous_columns: list,\n        output_dir: Path,\n        target_variable: str = None,\n        n_keep: int = 10\n    ) -&gt; None:\n    \"\"\"\n    Generates a pair plot of the specified continuous columns in the dataset.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame containing the data to be visualized.\n        continuous_columns (list): A list of column names corresponding to continuous variables.\n        output_dir (Path): Directory where the resulting plot will be saved.\n        target_variable (str, optional): The target variable to use as a hue for coloring the pair plot. Defaults to None.\n        n_keep (int, optional): The maximum number of continuous columns to include in the plot. \n            If exceeded, the most correlated columns are selected. Defaults to 10.\n    \"\"\"\n    if len(continuous_columns) &gt; n_keep:\n        spearman_corr = data[continuous_columns].corr(method=\"spearman\") \n        corr_pairs = spearman_corr.abs().unstack().sort_values(\n            kind=\"quicksort\",\n            ascending=False\n        ).drop_duplicates()\n        top_10_pairs = corr_pairs[corr_pairs &lt; 1].nlargest(5)\n        columns_to_plot = list({index for pair in top_10_pairs.index for index in pair})\n    else:\n        columns_to_plot = continuous_columns\n\n    hue = target_variable\n    if target_variable is not None:\n        columns_to_plot += [target_variable]\n\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    g = sns.pairplot(data[columns_to_plot], hue=hue)\n    g.figure.suptitle(\"Pair Plot\", y=1.08)\n\n    figure_path = output_dir / 'pairplot.png'\n    plt.savefig(figure_path)\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_umap","title":"<code>plot_umap(data, continuous_columns, output_dir)</code>","text":"<p>Generates a 2D UMAP projection of the specified continuous columns and saves the resulting scatter plot.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The input DataFrame containing the data to be visualized.</p> required <code>continuous_columns</code> <code>list</code> <p>A list of column names corresponding to continuous variables  to be included in the UMAP projection.</p> required <code>output_dir</code> <code>Path</code> <p>Directory where the resulting plot will be saved.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A 2D NumPy array of the UMAP-transformed data.</p> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_umap(\n        data: pd.DataFrame,\n        continuous_columns: list,\n        output_dir: Path\n    ) -&gt; np.ndarray:\n    \"\"\"\n    Generates a 2D UMAP projection of the specified continuous columns and saves the resulting scatter plot.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame containing the data to be visualized.\n        continuous_columns (list): A list of column names corresponding to continuous variables \n            to be included in the UMAP projection.\n        output_dir (Path): Directory where the resulting plot will be saved.\n\n    Returns:\n        np.ndarray: A 2D NumPy array of the UMAP-transformed data.\n    \"\"\"\n    umap_data = UMAP(n_components=2).fit_transform(data[continuous_columns])\n\n    fig, ax = plt.subplots(figsize=(8, 8), dpi=72)\n    sns.scatterplot(x=umap_data[:,0], y=umap_data[:,1], alpha=.7, ax=ax)\n    plt.title('UMAP of Continuous Variables')\n\n    figure_path = output_dir / 'umap_continuous_data.png'\n    fig.savefig(figure_path)\n    plt.close()\n\n    return umap_data\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_kaplan_meier_by_category","title":"<code>plot_kaplan_meier_by_category(data_x, data_y, categorical_columns, output_dir)</code>","text":"<p>Plots Kaplan-Meier survival curves for each category in the specified categorical columns.</p> <p>Parameters:</p> Name Type Description Default <code>data_x</code> <code>DataFrame</code> <p>Dataset containing the categorical columns to group by.</p> required <code>data_y</code> <code>DataFrame</code> <p>Dataset containing 'time' and 'event' columns for survival analysis.</p> required <code>categorical_columns</code> <code>list</code> <p>List of categorical column names to generate survival curves for.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the Kaplan-Meier survival curve plots.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_kaplan_meier_by_category(\n        data_x: pd.DataFrame,\n        data_y: pd.DataFrame,\n        categorical_columns: list,\n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Plots Kaplan-Meier survival curves for each category in the specified categorical columns.\n\n    Args:\n        data_x (pd.DataFrame): Dataset containing the categorical columns to group by.\n        data_y (pd.DataFrame): Dataset containing 'time' and 'event' columns for survival analysis.\n        categorical_columns (list): List of categorical column names to generate survival curves for.\n        output_dir (Path): Directory to save the Kaplan-Meier survival curve plots.\n    \"\"\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    for cat_col in categorical_columns:\n        plt.figure(figsize=(10, 6))\n        plt.title(f\"Kaplan-Meier Survival Curve by {cat_col}\")\n\n        unique_categories = data_x[cat_col].unique()\n\n        # Plot survival curves for each category\n        for category in unique_categories:\n            mask_category = data_x[cat_col] == category\n            try: # To catch when there are not enough samples for category\n                time_category, survival_prob_category, conf_int = kaplan_meier_estimator(\n                    data_y[\"event\"][mask_category].astype(bool),\n                    data_y[\"time\"][mask_category],\n                    conf_type=\"log-log\",\n                )\n\n                plt.step(\n                    time_category,\n                    survival_prob_category,\n                    where=\"post\",\n                    label=f\"{cat_col} = {category}\"\n                )\n                plt.fill_between(\n                    time_category,\n                    conf_int[0],\n                    conf_int[1],\n                    alpha=0.25,\n                    step=\"post\"\n                )\n            except Exception as _:\n                pass\n\n        results_multivariate = multivariate_logrank_test(\n            data_y['time'], \n            data_x[cat_col], \n            data_y['event']\n        )\n        multivariate_p_value = results_multivariate.p_value\n\n        plt.text(0.6, 0.1, f\"Multivariate log-rank p-value: {multivariate_p_value:.4e}\",\n                 fontsize=10, transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.8))\n        plt.ylim(0, 1)\n        plt.ylabel(r\"Estimated Probability of Survival $\\hat{S}(t)$\")\n        plt.xlabel(\"Time $t$\")\n        plt.legend(loc=\"best\")\n        plt.grid(alpha=0.3)\n        plt.savefig(output_dir / f'kaplan_meier_{cat_col}.png')\n        plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_feature_importance","title":"<code>plot_feature_importance(df, output_dir, model_name='')</code>","text":"<p>Plots feature importance with standard deviation and p-value significance.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing the feature importance data.  Look at example for required format.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the feature importance plot.</p> required <code>model_name</code> <code>str</code> <p>Optional name of the model, included in the plot title.</p> <code>''</code> Example <pre><code>import pandas as pd\nfrom pathlib import Path\n\ndf = pd.DataFrame({\n    'importance': [0.25, 0.18, 0.12, 0.10],\n    'stddev': [0.03, 0.02, 0.01, 0.015],\n    'p_value': [0.03, 0.07, 0.01, 0.2]\n}, index=['Feature A', 'Feature B', 'Feature C', 'Feature D'])\n\nplot_feature_importance(df, Path('./output'))\n</code></pre> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_feature_importance(df: pd.DataFrame, output_dir: Path, model_name: str=''):\n    \"\"\"\n    Plots feature importance with standard deviation and p-value significance.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing the feature importance data. \n            Look at example for required format.\n        output_dir (Path): Directory to save the feature importance plot.\n        model_name (str): Optional name of the model, included in the plot title.\n\n    Example:\n        ```python\n        import pandas as pd\n        from pathlib import Path\n\n        df = pd.DataFrame({\n            'importance': [0.25, 0.18, 0.12, 0.10],\n            'stddev': [0.03, 0.02, 0.01, 0.015],\n            'p_value': [0.03, 0.07, 0.01, 0.2]\n        }, index=['Feature A', 'Feature B', 'Feature C', 'Feature D'])\n\n        plot_feature_importance(df, Path('./output'))\n        ```\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(20, 12), dpi=72)\n\n    bars = ax.bar(df.index, df['importance'], yerr=df['stddev'], capsize=5, color='skyblue', edgecolor='black')\n\n    if 'p_value' in df.columns:\n        for bar, p_value in zip(bars, df['p_value']):\n            height = bar.get_height()\n            significance = '*' if p_value &lt; 0.05 else ''\n            ax.text(bar.get_x() + bar.get_width() / 2.0, height + 0.002, significance,\n                    ha='center', va='bottom', fontsize=10, color='red')\n\n    ax.set_xlabel('Feature', fontsize=14)\n    ax.set_ylabel('Importance', fontsize=14)\n    ax.set_title(f'Feature Importance with Standard Deviation and p-value Significance ({model_name})', fontsize=16)\n    ax.axhline(0, color='grey', linewidth=0.8)\n\n    ax.set_xticks(np.arange(len(df.index.values)))\n    ax.set_xticklabels(df.index.values, rotation=60, ha='right', fontsize=10)\n\n    ax.grid(axis='y', linestyle='--', alpha=0.7)\n\n    significance_patch = plt.Line2D([0], [0], color='red', marker='*', linestyle='None', markersize=10, label='p &lt; 0.05')\n    ax.legend(handles=[significance_patch], loc='upper right', fontsize=12)\n\n    plt.tight_layout()\n    fig.savefig(output_dir / 'feature_importance.png')\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_shap_values","title":"<code>plot_shap_values(predictor, X_train, X_test, output_dir, max_display=10)</code>","text":"<p>Generates and saves SHAP value visualizations, including a heatmap and a bar plot, for a autogluon tabular model.</p> <p>Parameters:</p> Name Type Description Default <code>predictor</code> <code>TabularPredictor</code> <p>The trained tabular predictor model for which SHAP values are calculated.</p> required <code>X_train</code> <code>DataFrame</code> <p>Training dataset used to create the SHAP background data.</p> required <code>X_test</code> <code>DataFrame</code> <p>Test dataset used to evaluate and compute SHAP values.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the SHAP value visualizations.</p> required <code>max_display</code> <code>int</code> <p>Maximum number of features to display in the visualizations. Defaults to 10.</p> <code>10</code> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_shap_values(\n        predictor: TabularPredictor,\n        X_train: pd.DataFrame,\n        X_test: pd.DataFrame,\n        output_dir: Path,\n        max_display: int = 10,\n    ) -&gt; None:\n    \"\"\"\n    Generates and saves SHAP value visualizations, including a heatmap and a bar plot, for a autogluon tabular model.\n\n    Args:\n        predictor (TabularPredictor): The trained tabular predictor model for which SHAP values are calculated.\n        X_train (pd.DataFrame): Training dataset used to create the SHAP background data.\n        X_test (pd.DataFrame): Test dataset used to evaluate and compute SHAP values.\n        output_dir (Path): Directory to save the SHAP value visualizations.\n        max_display (int): Maximum number of features to display in the visualizations. Defaults to 10.\n    \"\"\"\n    predictor = ModelWrapper(predictor, X_train.columns)\n    background_data = shap.sample(X_train, 100)\n    shap_exp = shap.KernelExplainer(predictor.predict_proba, background_data)\n\n    # sample 100 samples from test set to evaluate with shap values\n    test_data = shap.sample(X_test, 100)\n\n    # Compute SHAP values for the test set\n    shap_values = shap_exp(test_data)\n\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    fig, ax = plt.subplots(figsize=(20, 12), dpi=72)\n    shap.plots.heatmap(shap_values[...,1], max_display=max_display, show=False, ax=ax)\n    fig.savefig(output_dir / 'shap_heatmap.png')\n    plt.close()\n\n    fig, ax = plt.subplots(figsize=(20, 12), dpi=72)\n    shap.plots.bar(shap_values[...,1], max_display=max_display, show=False, ax=ax)\n    fig.savefig(output_dir / 'shap_barplot.png')\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_violin_of_bootstrapped_metrics","title":"<code>plot_violin_of_bootstrapped_metrics(trainer, X_test, y_test, X_val, y_val, X_train, y_train, output_dir)</code>","text":"<p>Generates violin plots for bootstrapped model performance metrics across train, validation, and test datasets.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>TrainerSupervised</code> <p>The trained model predictor for evaluating performance metrics.</p> required <code>X_test</code> <code>Series</code> <p>Test features dataset.</p> required <code>y_test</code> <code>Series</code> <p>Test target values.</p> required <code>X_val</code> <code>Series</code> <p>Validation features dataset.</p> required <code>y_val</code> <code>Series</code> <p>Validation target values.</p> required <code>X_train</code> <code>Series</code> <p>Training features dataset.</p> required <code>y_train</code> <code>Series</code> <p>Training target values.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the generated violin plots.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_violin_of_bootstrapped_metrics(\n        trainer,\n        X_test: pd.Series,\n        y_test: pd.Series,\n        X_val: pd.Series,\n        y_val: pd.Series,\n        X_train: pd.Series,\n        y_train: pd.Series,\n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Generates violin plots for bootstrapped model performance metrics across train, validation, and test datasets.\n\n    Args:\n        trainer (TrainerSupervised): The trained model predictor for evaluating performance metrics.\n        X_test (pd.Series): Test features dataset.\n        y_test (pd.Series): Test target values.\n        X_val (pd.Series): Validation features dataset.\n        y_val (pd.Series): Validation target values.\n        X_train (pd.Series): Training features dataset.\n        y_train (pd.Series): Training target values.\n        output_dir (Path): Directory to save the generated violin plots.\n    \"\"\"\n    # Define metrics based on the problem type\n    if trainer.task == 'regression':\n        metrics = [('R Squared', r2_score), ('Root Mean Squared Error', root_mean_squared_error)]\n    elif trainer.task == 'binary':\n        metrics = [('AUROC', roc_auc_score), ('AUPRC', auprc)]\n    elif trainer.task == 'survival':\n        metrics = [('Concordance Index', ci_wrapper)]\n\n    # Prepare lists for DataFrame\n    results = []\n\n    # Loop through models and metrics to compute bootstrapped values\n    for model_name in trainer.model_names():\n        y_pred_test = trainer.infer(X_test, model=model_name)\n        y_pred_val = trainer.infer(X_val, model=model_name)\n        y_pred_train = trainer.infer(X_train, model=model_name)\n\n        for metric_name, metric_func in metrics:\n            test_values = bootstrap_metric(y_test.to_numpy(), y_pred_test, metric_func)\n            results.extend([(model_name, metric_name, 'Test', value) for value in test_values])\n\n            val_values = bootstrap_metric(y_val.to_numpy(), y_pred_val, metric_func)\n            results.extend([(model_name, metric_name, 'Validation', value) for value in val_values])\n\n            train_values = bootstrap_metric(y_train.to_numpy(), y_pred_train, metric_func)\n            results.extend([(model_name, metric_name, 'Train', value) for value in train_values])\n\n    # Create a results DataFrame\n    result_df = pd.DataFrame(results, columns=['model', 'metric', 'data_split', 'value'])\n\n     # Sort models by median metric value within each combination of metric and data_split\n    model_order_per_split = {}\n    for split in ['Test', 'Validation', 'Train']:\n        split_order = (\n            result_df[result_df['data_split'] == split]\n            .groupby(['metric', 'model'])['value']\n            .median()\n            .reset_index()\n            .sort_values(by=['metric', 'value'], ascending=[True, False])\n            .groupby('metric')['model']\n            .apply(list)\n            .to_dict()\n        )\n        model_order_per_split[split] = split_order\n\n    # Function to create violin plots for a specific data split\n    def create_violin_plot(data_split, save_path):\n        sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n        subset = result_df[result_df['data_split'] == data_split]\n        g = sns.FacetGrid(\n            subset,\n            col=\"metric\",\n            margin_titles=True,\n            height=4,\n            aspect=1.5,\n            sharex=False,\n        )\n\n        # Create violin plots with sorted models\n        def violin_plot(data, **kwargs):\n            metric = data.iloc[0]['metric']\n            order = model_order_per_split[data_split].get(metric, None)\n            sns.violinplot(data=data, x=\"value\", y=\"model\", linewidth=1, order=order, **kwargs)\n\n        g.map_dataframe(violin_plot)\n\n        # Adjust the titles and axis labels\n        g.set_titles(col_template=\"{col_name}\")\n        g.set_axis_labels(\"\", \"Model\")\n\n        # Add overall title and adjust layout\n        g.figure.suptitle(f\"Model Performance of {data_split} Data (Bootstrapped)\", fontsize=16)\n        g.tight_layout(w_pad=0.5, h_pad=1)\n\n        # Save the plot\n        g.savefig(save_path, dpi=500)\n        plt.close()\n\n    # Generate and save plots for each data split\n    create_violin_plot('Test', output_dir / 'test_metrics_bootstrap.png')\n    create_violin_plot('Validation', output_dir / 'validation_metrics_bootstrap.png')\n    create_violin_plot('Train', output_dir / 'train_metrics_bootstrap.png')\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_regression_diagnostics","title":"<code>plot_regression_diagnostics(y_true, y_pred, output_dir)</code>","text":"<p>Generates diagnostic plots for evaluating a regression model.</p> Plots <ul> <li>True vs. Predicted values plot.</li> <li>Residuals plot.</li> <li>Histogram of residuals.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>Array of true target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>Array of predicted values from the regression model.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the diagnostic plots.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_regression_diagnostics(\n        y_true: np.ndarray, \n        y_pred: np.ndarray, \n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Generates diagnostic plots for evaluating a regression model.\n\n    Plots:\n        - True vs. Predicted values plot.\n        - Residuals plot.\n        - Histogram of residuals.\n\n    Args:\n        y_true (np.ndarray): Array of true target values.\n        y_pred (np.ndarray): Array of predicted values from the regression model.\n        output_dir (Path): Directory to save the diagnostic plots.\n    \"\"\"\n    residuals = y_true - y_pred\n\n    # Regression Line\n    plt.figure(figsize=(10, 6))\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    sns.scatterplot(x=y_true, y=y_pred, alpha=0.5)\n    sns.lineplot(x=y_true, y=y_true, color='red')  # Perfect prediction line\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs Predicted Values')\n    plt.savefig(output_dir / 'true_vs_predicted.png')\n    plt.close()\n\n    # Residuals\n    plt.figure(figsize=(10, 6))\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    sns.scatterplot(x=y_pred, y=residuals, alpha=0.5)\n    plt.axhline(0, color='red', linestyle='--')\n    plt.xlabel('Fitted Values')\n    plt.ylabel('Residuals')\n    plt.title('Residual Plot')\n    plt.savefig(output_dir / 'residual_plot.png')\n    plt.close()\n\n    # Residual Histogram\n    plt.figure(figsize=(10, 6))\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    sns.histplot(residuals, kde=True, bins=30)\n    plt.xlabel('Residuals')\n    plt.title('Histogram of Residuals')\n    plt.savefig(output_dir / 'residual_hist.png')\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_classification_diagnostics","title":"<code>plot_classification_diagnostics(y_test, y_test_pred, y_val, y_val_pred, y_train, y_train_pred, output_dir)</code>","text":"<p>Generates diagnostic plots for evaluating a classification model.</p> Plots <ul> <li>Epic model evaluation plots (ROC Curve, Precision-Recall Curve, Calibration Curve, Sensitivity/Flag Curve).</li> <li>Confusion Matrix.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_test</code> <code>DataFrame</code> <p>True labels for the test dataset.</p> required <code>y_test_pred</code> <code>DataFrame</code> <p>Predicted probabilities for the test dataset.</p> required <code>y_val</code> <code>DataFrame</code> <p>True labels for the validation dataset.</p> required <code>y_val_pred</code> <code>DataFrame</code> <p>Predicted probabilities for the validation dataset.</p> required <code>y_train</code> <code>DataFrame</code> <p>True labels for the training dataset.</p> required <code>y_train_pred</code> <code>DataFrame</code> <p>Predicted probabilities for the training dataset.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the diagnostic plots.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_classification_diagnostics(\n        y_test: pd.DataFrame,\n        y_test_pred: pd.DataFrame,\n        y_val: pd.DataFrame,\n        y_val_pred: pd.DataFrame,\n        y_train: pd.DataFrame,\n        y_train_pred: pd.DataFrame,\n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Generates diagnostic plots for evaluating a classification model.\n\n    Plots:\n        - Epic model evaluation plots (ROC Curve, Precision-Recall Curve, Calibration Curve, Sensitivity/Flag Curve).\n        - Confusion Matrix.\n\n    Args:\n        y_test (pd.DataFrame): True labels for the test dataset.\n        y_test_pred (pd.DataFrame): Predicted probabilities for the test dataset.\n        y_val (pd.DataFrame): True labels for the validation dataset.\n        y_val_pred (pd.DataFrame): Predicted probabilities for the validation dataset.\n        y_train (pd.DataFrame): True labels for the training dataset.\n        y_train_pred (pd.DataFrame): Predicted probabilities for the training dataset.\n        output_dir (Path): Directory to save the diagnostic plots.\n    \"\"\"\n    plot_epic_copy(\n        y_test.to_numpy(),\n        y_test_pred.to_numpy(),\n        y_val.to_numpy(),\n        y_val_pred.to_numpy(),\n        y_train.to_numpy(),\n        y_train_pred.to_numpy() ,\n        output_dir\n    )\n\n    conf_matrix = confusion_matrix(y_test, y_test_pred.apply(lambda x: 1 if x &gt;= 0.5 else 0))\n\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.savefig(output_dir / 'confusion_matrix.png')\n    plt.close()\n</code></pre>"},{"location":"api/trainer/","title":"Trainer","text":""},{"location":"api/trainer/#trainersupervised","title":"TrainerSupervised","text":"<p>The <code>TrainerSupervised</code> class is part of the <code>jarvais.trainer</code> module.</p>"},{"location":"api/trainer/#jarvais.trainer.TrainerSupervised","title":"<code>jarvais.trainer.TrainerSupervised</code>","text":"<p>TrainerSupervised class for supervised jarvAIs workflows.</p> <p>This class provides functionality for feature reduction, training models (e.g., AutoGluon, survival models),  and performing inference. It supports various tasks such as binary/multiclass classification, regression,  and survival analysis.</p> <p>Attributes:</p> Name Type Description <code>task</code> <code>str</code> <p>Type of task. Must be one of {'binary', 'multiclass', 'regression', 'survival'}. </p> <code>reduction_method</code> <code>str | None</code> <p>Feature reduction method. Supported methods include  {'mrmr', 'variance_threshold', 'corr', 'chi2'}.</p> <code>keep_k</code> <code>int</code> <p>Number of features to retain during reduction.</p> <code>output_dir</code> <code>str | Path</code> <p>Directory for saving outputs. Defaults to the current working directory.</p> Example <pre><code>from jarvais.trainer import TrainerSupervised\n\ntrainer = TrainerSupervised(\n    task=\"binary\",\n    reduction_method=\"mrmr\",\n    keep_k=10,\n    output_dir=\"./results\"\n)\ntrainer.run(data=my_data, target_variable=\"target\")\n\npredictions = trainer.infer(new_data)\n</code></pre> Source code in <code>src/jarvais/trainer/trainer.py</code> <pre><code>class TrainerSupervised:\n    \"\"\"\n    TrainerSupervised class for supervised jarvAIs workflows.\n\n    This class provides functionality for feature reduction, training models (e.g., AutoGluon, survival models), \n    and performing inference. It supports various tasks such as binary/multiclass classification, regression, \n    and survival analysis.\n\n    Attributes:\n        task (str, optional): Type of task. Must be one of {'binary', 'multiclass', 'regression', 'survival'}. \n        reduction_method (str | None, optional): Feature reduction method. Supported methods include \n            {'mrmr', 'variance_threshold', 'corr', 'chi2'}.\n        keep_k (int, optional): Number of features to retain during reduction.\n        output_dir (str | Path, optional): Directory for saving outputs. Defaults to the current working directory.\n\n    Example:\n        ```python\n        from jarvais.trainer import TrainerSupervised\n\n        trainer = TrainerSupervised(\n            task=\"binary\",\n            reduction_method=\"mrmr\",\n            keep_k=10,\n            output_dir=\"./results\"\n        )\n        trainer.run(data=my_data, target_variable=\"target\")\n\n        predictions = trainer.infer(new_data)\n        ```\n    \"\"\"\n    def __init__(\n            self,\n            task: str=None,\n            reduction_method: str | None = None,\n            keep_k: int = 2,\n            output_dir: str | Path = None\n        ) -&gt; None:\n\n        self.task = task\n        self.reduction_method = reduction_method\n        self.keep_k = keep_k\n\n        if task not in ['binary', 'multiclass', 'regression', 'survival', None]:\n            raise ValueError(\"Invalid task parameter. Choose one of: 'binary', 'multiclass', 'regression', 'survival'. Providing None defaults to Autogluon infering.\")\n\n        self.output_dir = Path.cwd() if output_dir is None else Path(output_dir)\n        self.output_dir.mkdir(exist_ok=True, parents=True)\n\n    def _feature_reduction(self, X: pd.DataFrame, y: pd.DataFrame | pd.Series) -&gt; pd.DataFrame:\n        \"\"\"\n        Reduce features based on the specified reduction method. \n\n        One-hot encoding applied before reduction and reverted afterward.\n        \"\"\"\n        # Step 1: Identify categorical columns\n        categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n\n        mappin = {}\n\n        def find_category_mappings(df, variable):\n            return {k: i for i, k in enumerate(df[variable].dropna().unique(), 0)}\n\n        def integer_encode(df, variable, ordinal_mapping):\n            df[variable] = df[variable].map(ordinal_mapping)\n\n        for variable in categorical_columns:\n            mappings = find_category_mappings(X, variable)\n            mappin[variable] = mappings\n\n        for variable in categorical_columns:\n            integer_encode(X, variable, mappin[variable])\n\n        # Step 3: Perform feature reduction\n        if self.reduction_method == 'mrmr':\n            X_reduced = mrmr_reduction(self.task, X, y, self.keep_k)\n        elif self.reduction_method == 'variance_threshold':\n            X_reduced = var_reduction(X, y)\n        elif self.reduction_method == 'corr':\n            X_reduced = kbest_reduction(self.task, X, y, self.keep_k)\n        elif self.reduction_method == 'chi2':\n            if self.task not in ['binary', 'multiclass']:\n                raise ValueError('chi-squared reduction can only be done with classification tasks')\n            X_reduced = chi2_reduction(X, y, self.keep_k)\n        else:\n            raise ValueError('Unsupported reduction method: {}'.format(self.reduction_method))\n\n        for col in categorical_columns:\n            if col in X_reduced.columns:\n                inv_map = {v: k for k, v in mappin[col].items()}\n                X_reduced[col] = X_reduced[col].map(inv_map)\n\n        return X_reduced\n\n    def _train_autogluon_with_cv(self) -&gt; None:\n        self.predictors, leaderboard, self.best_fold, self.X_val, self.y_val = train_autogluon_with_cv(\n            pd.concat([self.X_train, self.y_train], axis=1),\n            pd.concat([self.X_test, self.y_test], axis=1),\n            target_variable=self.target_variable,\n            task=self.task,\n            extra_metrics=self.extra_metrics,\n            eval_metric=self.eval_metric,\n            num_folds=self.k_folds,\n            output_dir=(self.output_dir / 'autogluon_models'),\n            **self.kwargs\n        )\n\n        self.predictor = self.predictors[self.best_fold]\n        self.trainer_config['best_fold'] = self.best_fold\n\n        # Update train data to remove validation\n        self.X_train = self.X_train[~self.X_train.index.isin(self.X_val.index)]\n        self.y_train = self.y_train[~self.y_train.index.isin(self.y_val.index)]\n\n        print('\\nModel Leaderboard (Displays values in \"mean [min, max]\" format across training folds)\\n------------------------------------------------------------------------------------')\n        print(tabulate(\n            leaderboard.sort_values(by='score_test', ascending=False)[self.show_leaderboard],\n            tablefmt = \"fancy_grid\",\n            headers=\"keys\",\n            showindex=False\n        ))\n\n    def _train_autogluon(self) -&gt; None:\n        self.predictor = TabularPredictor(\n            label=self.target_variable, \n            problem_type=self.task, \n            eval_metric=self.eval_metric,\n            path=(self.output_dir / 'autogluon_models' / 'autogluon_models_best_fold'),\n            log_to_file=False,\n        ).fit(\n            pd.concat([self.X_train, self.y_train], axis=1),\n            **self.kwargs\n        )\n\n        self.X_val, self.y_val = self.predictor.load_data_internal(data='val', return_y=True)\n        # Update train data to remove validation\n        self.X_train = self.X_train[~self.X_train.index.isin(self.X_val.index)]\n        self.y_train = self.y_train[~self.y_train.index.isin(self.y_val.index)]\n\n        train_leaderboard = self.predictor.leaderboard(\n            pd.concat([self.X_train, self.y_train], axis=1),\n            extra_metrics=self.extra_metrics).round(2)\n        val_leaderboard = self.predictor.leaderboard(\n            pd.concat([self.X_val, self.y_val], axis=1),\n            extra_metrics=self.extra_metrics).round(2)\n        test_leaderboard = self.predictor.leaderboard(\n            pd.concat([self.X_test, self.y_test], axis=1),\n            extra_metrics=self.extra_metrics).round(2)\n\n        leaderboard = pd.merge(\n            pd.merge(\n                format_leaderboard(train_leaderboard, self.extra_metrics, 'score_train'),\n                format_leaderboard(val_leaderboard, self.extra_metrics, 'score_val'),\n                on='model'\n            ),\n            format_leaderboard(test_leaderboard, self.extra_metrics, 'score_test'),\n            on='model'\n        )\n\n        print('\\nModel Leaderboard\\n----------------')\n        print(tabulate(\n            leaderboard.sort_values(by='score_test', ascending=False)[self.show_leaderboard],\n            tablefmt = \"fancy_grid\",\n            headers=\"keys\",\n            showindex=False))\n\n    def run(\n            self,\n            data: pd.DataFrame,\n            target_variable: str,\n            test_size: float = 0.2,\n            exclude: List[str] | None = None,\n            stratify_on: str | None = None,\n            explain: bool = False,\n            k_folds: int = 5,\n            **kwargs:dict\n        ) -&gt; None:\n        \"\"\"\n        Execute the jarvAIs Trainer pipeline on the given dataset.\n\n        Args:\n            data (pd.DataFrame): The input dataset containing features and target.\n            target_variable (str): The name of the target variable in the dataset.\n            test_size (float, optional): Proportion of the dataset to include in the test split. \n                Must be between 0 and 1. Default is 0.2.\n            exclude (list of str, optional): List of columns to exclude from the feature set. \n                Default is an empty list.\n            stratify_on (str, optional): Column to use for stratification, if any. \n                Must be compatible with `target_variable`.\n            explain (bool, optional): Whether to generate explainability reports for the model. \n                Default is False.\n            k_folds (int, optional): Number of folds for cross-validation. If 1, uses AutoGluon-specific validation. \n                Default is 5.\n            kwargs (dict, optional): Additional arguments passed to the AutoGluon predictor's `fit` method.\n        \"\"\"\n        self.trainer_config = dict()\n        self.trainer_config['task'] = self.task\n        self.trainer_config['output_dir'] = self.output_dir.as_posix()\n\n        self.target_variable = target_variable\n        self.trainer_config['target_variable'] = target_variable\n        self.k_folds = k_folds\n        self.trainer_config['k_folds'] = k_folds\n        self.kwargs = kwargs\n\n        self.trainer_config['test_size'] = test_size\n        self.trainer_config['stratify_on'] = stratify_on\n\n        # Initialize mutable defaults\n        if exclude is None:\n            exclude = []\n\n        if isinstance(target_variable, list): # Happens for survival data\n            exclude += target_variable\n        else:\n            exclude.append(target_variable)\n\n        try:\n            X = data.drop(columns=exclude)\n            y = data[target_variable]\n        except KeyError as e:\n            raise ValueError(f\"Invalid column specified: {e}\")\n\n        # Optional feature reduction\n        if getattr(self, \"reduction_method\", None):\n            print(f\"Applying {self.reduction_method} for feature reduction\")\n            X = self._feature_reduction(X, y)\n            print(f\"Features retained: {list(X.columns)}\")\n\n            self.feature_names = list(X.columns)\n            self.trainer_config['reduction_method'] = self.reduction_method\n            self.trainer_config['reduced_feature_set'] = self.feature_names\n\n        if self.task in {'binary', 'multiclass'}:\n            stratify_col = (\n                y.astype(str) + '_' + data[stratify_on].astype(str)\n                if stratify_on is not None\n                else y\n            )\n        else:\n            stratify_col = None\n\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n            X, y, test_size=test_size, stratify=stratify_col, random_state=42)\n\n        if self.task == 'survival':\n            self.predictors, scores, data_train, data_val = train_survival_models(\n                self.X_train, \n                self.y_train, \n                self.X_test, \n                self.y_test, \n                self.output_dir\n            )\n            self.predictor = self.predictors[max(scores, key=scores.get)]\n            self.trainer_config['survival_models_info'] = scores\n\n            self.X_train, self.y_train = data_train.drop(columns=['time', 'event']), data_train[['time', 'event']] \n            self.X_val, self.y_val = data_val.drop(columns=['time', 'event']), data_val[['time', 'event']] \n        else:\n            (self.output_dir / 'autogluon_models').mkdir(exist_ok=True, parents=True)\n\n            if self.task in ['binary', 'multiclass']:\n                self.eval_metric = 'roc_auc'\n            elif self.task == 'regression':\n                self.eval_metric = 'r2'\n\n            ag_auprc_scorer = make_scorer(\n                name='auprc', # Move this to a seperate file?\n                score_func=auprc,\n                optimum=1,\n                greater_is_better=True,\n                needs_class=True)\n\n            # When changing extra_metrics consider where it's used and make updates accordingly\n            self.extra_metrics = ['f1', ag_auprc_scorer] if self.task in ['binary', 'multiclass'] else ['root_mean_squared_error']\n            self.show_leaderboard = ['model', 'score_test', 'score_val', 'score_train']\n\n            custom_hyperparameters = get_hyperparameter_config('default')\n            custom_hyperparameters[SimpleRegressionModel] = {}\n            kwargs['hyperparameters'] = custom_hyperparameters\n\n            if k_folds &gt; 1:\n                self._train_autogluon_with_cv()\n            else:\n                self._train_autogluon()\n\n        self.trained = True\n\n        self.data_dir = self.output_dir / 'data'\n        self.data_dir.mkdir(parents=True, exist_ok=True)\n        self.X_train.to_csv((self.data_dir / 'X_train.csv'), index=False)\n        self.X_test.to_csv((self.data_dir / 'X_test.csv'), index=False)\n        self.X_val.to_csv((self.data_dir / 'X_val.csv'), index=False)\n        self.y_train.to_csv((self.data_dir / 'y_train.csv'), index=False)\n        self.y_test.to_csv((self.data_dir / 'y_test.csv'), index=False)\n        self.y_val.to_csv((self.data_dir / 'y_val.csv'), index=False)\n\n        with (self.output_dir / 'trainer_config.yaml').open('w') as f:\n            yaml.dump(self.trainer_config, f)\n\n        if explain:\n            explainer = Explainer.from_trainer(self)\n            explainer.run()\n\n    def model_names(self) -&gt; List[str]:\n        \"\"\"\n        Returns all trainer model names.\n\n        This method retrieves the names of all models associated with the \n        current predictor. It requires that the predictor has been trained.\n\n        Returns:\n            list: A list of model names available in the predictor.\n\n        Raises:\n            ValueError: If the model has not been trained (`self.trained` is False).\n        \"\"\"\n        if not self.trained:\n            raise ValueError(\"The model must be trained before accessing model names.\")\n\n        if self.task == 'survival':\n            return list(self.predictors.keys())\n        else:        \n            return self.predictor.model_names()\n\n    def infer(self, data: pd.DataFrame, model: str = None) -&gt; np.ndarray:\n        \"\"\"\n        Perform inference using the trained predictor on the provided data.\n\n        This method generates predictions based on the input data using the \n        specified model. If no model is provided, the default model is used. \n        The predictor must be trained before inference can be performed.\n\n        Args:\n            data (pd.DataFrame): The input data for which inference is to be performed.\n            model (str, optional): The name of the model to use for inference. \n                If None, the default model is used.\n\n        Returns:\n            np.ndarray: The prediction results from the model.\n\n        Raises:\n            ValueError: If the model has not been trained (`self.trained` is False).\n            ValueError: If the specified model name is not found in the predictor.\n        \"\"\"\n        if not self.trained:\n            raise ValueError(\"The model must be trained before performing inference.\")\n        if not model is None and not model in self.model_names():\n            raise ValueError(f\"Model '{model}' not in trainer. Use model_names() to list valid available models.\")\n\n        if self.task == 'survival':\n            if model is None:\n                inference = self.predictor.predict(data)\n            else:\n                inference = self.predictors[model].predict(data)\n        else:\n            if self.predictor.can_predict_proba:\n                inference = self.predictor.predict_proba(data, model, as_pandas=False)[:, 1]\n            else:\n                inference = self.predictor.predict(data, model, as_pandas=False)\n\n        return inference\n\n    @classmethod\n    def load_trainer(cls, project_dir: str | Path):\n        \"\"\"\n        Load a trained TrainerSupervised from the specified directory.\n\n        Args:\n            project_dir (str or Path, optional): The directory where the trainer was run.\n\n        Returns:\n            trainer (TrainerSupervised): The loaded Trainer.\n        \"\"\"\n        project_dir = Path(project_dir)\n        with (project_dir / 'trainer_config.yaml').open('r') as f:\n            trainer_config = yaml.safe_load(f)\n\n        trainer = cls()\n        trainer.task = trainer_config['task']\n        trainer.output_dir = project_dir\n\n        if trainer.task == 'survival':\n            model_dir = (project_dir / 'survival_models')\n\n            trainer.predictors = {}\n            model_info = trainer_config['survival_models_info']\n            for model_name, _ in model_info.items():\n                if model_name == 'MTLR':\n                    trainer.predictors[model_name] = LitMTLR.load_from_checkpoint(model_dir / \"MTLR.ckpt\")\n                elif model_name == 'DeepSurv':\n                    trainer.predictors[model_name] = LitDeepSurv.load_from_checkpoint(model_dir / \"DeepSurv.ckpt\")\n                else:\n                    with (model_dir / f'{model_name}.pkl').open(\"rb\") as f:\n                        trainer.predictors[model_name] = pickle.load(f)\n\n            trainer.predictor = trainer.predictors[max(model_info, key=model_info.get)]\n        else:\n            model_dir = (project_dir / 'autogluon_models' / 'autogluon_models_best_fold')\n            trainer.predictor = TabularPredictor.load(model_dir, verbosity=1)\n\n        trainer.trained = True\n\n        trainer.X_test = pd.read_csv(project_dir / 'data' / 'X_test.csv')\n        trainer.X_val = pd.read_csv(project_dir / 'data' / 'X_val.csv')\n        trainer.X_train = pd.read_csv(project_dir / 'data' / 'X_train.csv')\n        trainer.y_test = pd.read_csv(project_dir / 'data' / 'y_test.csv').squeeze()\n        trainer.y_val = pd.read_csv(project_dir / 'data' / 'y_val.csv').squeeze()\n        trainer.y_train = pd.read_csv(project_dir / 'data' / 'y_train.csv').squeeze()\n\n        return trainer\n</code></pre>"},{"location":"api/trainer/#jarvais.trainer.TrainerSupervised.run","title":"<code>run(data, target_variable, test_size=0.2, exclude=None, stratify_on=None, explain=False, k_folds=5, **kwargs)</code>","text":"<p>Execute the jarvAIs Trainer pipeline on the given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The input dataset containing features and target.</p> required <code>target_variable</code> <code>str</code> <p>The name of the target variable in the dataset.</p> required <code>test_size</code> <code>float</code> <p>Proportion of the dataset to include in the test split.  Must be between 0 and 1. Default is 0.2.</p> <code>0.2</code> <code>exclude</code> <code>list of str</code> <p>List of columns to exclude from the feature set.  Default is an empty list.</p> <code>None</code> <code>stratify_on</code> <code>str</code> <p>Column to use for stratification, if any.  Must be compatible with <code>target_variable</code>.</p> <code>None</code> <code>explain</code> <code>bool</code> <p>Whether to generate explainability reports for the model.  Default is False.</p> <code>False</code> <code>k_folds</code> <code>int</code> <p>Number of folds for cross-validation. If 1, uses AutoGluon-specific validation.  Default is 5.</p> <code>5</code> <code>kwargs</code> <code>dict</code> <p>Additional arguments passed to the AutoGluon predictor's <code>fit</code> method.</p> <code>{}</code> Source code in <code>src/jarvais/trainer/trainer.py</code> <pre><code>def run(\n        self,\n        data: pd.DataFrame,\n        target_variable: str,\n        test_size: float = 0.2,\n        exclude: List[str] | None = None,\n        stratify_on: str | None = None,\n        explain: bool = False,\n        k_folds: int = 5,\n        **kwargs:dict\n    ) -&gt; None:\n    \"\"\"\n    Execute the jarvAIs Trainer pipeline on the given dataset.\n\n    Args:\n        data (pd.DataFrame): The input dataset containing features and target.\n        target_variable (str): The name of the target variable in the dataset.\n        test_size (float, optional): Proportion of the dataset to include in the test split. \n            Must be between 0 and 1. Default is 0.2.\n        exclude (list of str, optional): List of columns to exclude from the feature set. \n            Default is an empty list.\n        stratify_on (str, optional): Column to use for stratification, if any. \n            Must be compatible with `target_variable`.\n        explain (bool, optional): Whether to generate explainability reports for the model. \n            Default is False.\n        k_folds (int, optional): Number of folds for cross-validation. If 1, uses AutoGluon-specific validation. \n            Default is 5.\n        kwargs (dict, optional): Additional arguments passed to the AutoGluon predictor's `fit` method.\n    \"\"\"\n    self.trainer_config = dict()\n    self.trainer_config['task'] = self.task\n    self.trainer_config['output_dir'] = self.output_dir.as_posix()\n\n    self.target_variable = target_variable\n    self.trainer_config['target_variable'] = target_variable\n    self.k_folds = k_folds\n    self.trainer_config['k_folds'] = k_folds\n    self.kwargs = kwargs\n\n    self.trainer_config['test_size'] = test_size\n    self.trainer_config['stratify_on'] = stratify_on\n\n    # Initialize mutable defaults\n    if exclude is None:\n        exclude = []\n\n    if isinstance(target_variable, list): # Happens for survival data\n        exclude += target_variable\n    else:\n        exclude.append(target_variable)\n\n    try:\n        X = data.drop(columns=exclude)\n        y = data[target_variable]\n    except KeyError as e:\n        raise ValueError(f\"Invalid column specified: {e}\")\n\n    # Optional feature reduction\n    if getattr(self, \"reduction_method\", None):\n        print(f\"Applying {self.reduction_method} for feature reduction\")\n        X = self._feature_reduction(X, y)\n        print(f\"Features retained: {list(X.columns)}\")\n\n        self.feature_names = list(X.columns)\n        self.trainer_config['reduction_method'] = self.reduction_method\n        self.trainer_config['reduced_feature_set'] = self.feature_names\n\n    if self.task in {'binary', 'multiclass'}:\n        stratify_col = (\n            y.astype(str) + '_' + data[stratify_on].astype(str)\n            if stratify_on is not None\n            else y\n        )\n    else:\n        stratify_col = None\n\n    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n        X, y, test_size=test_size, stratify=stratify_col, random_state=42)\n\n    if self.task == 'survival':\n        self.predictors, scores, data_train, data_val = train_survival_models(\n            self.X_train, \n            self.y_train, \n            self.X_test, \n            self.y_test, \n            self.output_dir\n        )\n        self.predictor = self.predictors[max(scores, key=scores.get)]\n        self.trainer_config['survival_models_info'] = scores\n\n        self.X_train, self.y_train = data_train.drop(columns=['time', 'event']), data_train[['time', 'event']] \n        self.X_val, self.y_val = data_val.drop(columns=['time', 'event']), data_val[['time', 'event']] \n    else:\n        (self.output_dir / 'autogluon_models').mkdir(exist_ok=True, parents=True)\n\n        if self.task in ['binary', 'multiclass']:\n            self.eval_metric = 'roc_auc'\n        elif self.task == 'regression':\n            self.eval_metric = 'r2'\n\n        ag_auprc_scorer = make_scorer(\n            name='auprc', # Move this to a seperate file?\n            score_func=auprc,\n            optimum=1,\n            greater_is_better=True,\n            needs_class=True)\n\n        # When changing extra_metrics consider where it's used and make updates accordingly\n        self.extra_metrics = ['f1', ag_auprc_scorer] if self.task in ['binary', 'multiclass'] else ['root_mean_squared_error']\n        self.show_leaderboard = ['model', 'score_test', 'score_val', 'score_train']\n\n        custom_hyperparameters = get_hyperparameter_config('default')\n        custom_hyperparameters[SimpleRegressionModel] = {}\n        kwargs['hyperparameters'] = custom_hyperparameters\n\n        if k_folds &gt; 1:\n            self._train_autogluon_with_cv()\n        else:\n            self._train_autogluon()\n\n    self.trained = True\n\n    self.data_dir = self.output_dir / 'data'\n    self.data_dir.mkdir(parents=True, exist_ok=True)\n    self.X_train.to_csv((self.data_dir / 'X_train.csv'), index=False)\n    self.X_test.to_csv((self.data_dir / 'X_test.csv'), index=False)\n    self.X_val.to_csv((self.data_dir / 'X_val.csv'), index=False)\n    self.y_train.to_csv((self.data_dir / 'y_train.csv'), index=False)\n    self.y_test.to_csv((self.data_dir / 'y_test.csv'), index=False)\n    self.y_val.to_csv((self.data_dir / 'y_val.csv'), index=False)\n\n    with (self.output_dir / 'trainer_config.yaml').open('w') as f:\n        yaml.dump(self.trainer_config, f)\n\n    if explain:\n        explainer = Explainer.from_trainer(self)\n        explainer.run()\n</code></pre>"},{"location":"api/trainer/#jarvais.trainer.TrainerSupervised.model_names","title":"<code>model_names()</code>","text":"<p>Returns all trainer model names.</p> <p>This method retrieves the names of all models associated with the  current predictor. It requires that the predictor has been trained.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>List[str]</code> <p>A list of model names available in the predictor.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model has not been trained (<code>self.trained</code> is False).</p> Source code in <code>src/jarvais/trainer/trainer.py</code> <pre><code>def model_names(self) -&gt; List[str]:\n    \"\"\"\n    Returns all trainer model names.\n\n    This method retrieves the names of all models associated with the \n    current predictor. It requires that the predictor has been trained.\n\n    Returns:\n        list: A list of model names available in the predictor.\n\n    Raises:\n        ValueError: If the model has not been trained (`self.trained` is False).\n    \"\"\"\n    if not self.trained:\n        raise ValueError(\"The model must be trained before accessing model names.\")\n\n    if self.task == 'survival':\n        return list(self.predictors.keys())\n    else:        \n        return self.predictor.model_names()\n</code></pre>"},{"location":"api/trainer/#jarvais.trainer.TrainerSupervised.infer","title":"<code>infer(data, model=None)</code>","text":"<p>Perform inference using the trained predictor on the provided data.</p> <p>This method generates predictions based on the input data using the  specified model. If no model is provided, the default model is used.  The predictor must be trained before inference can be performed.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The input data for which inference is to be performed.</p> required <code>model</code> <code>str</code> <p>The name of the model to use for inference.  If None, the default model is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The prediction results from the model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model has not been trained (<code>self.trained</code> is False).</p> <code>ValueError</code> <p>If the specified model name is not found in the predictor.</p> Source code in <code>src/jarvais/trainer/trainer.py</code> <pre><code>def infer(self, data: pd.DataFrame, model: str = None) -&gt; np.ndarray:\n    \"\"\"\n    Perform inference using the trained predictor on the provided data.\n\n    This method generates predictions based on the input data using the \n    specified model. If no model is provided, the default model is used. \n    The predictor must be trained before inference can be performed.\n\n    Args:\n        data (pd.DataFrame): The input data for which inference is to be performed.\n        model (str, optional): The name of the model to use for inference. \n            If None, the default model is used.\n\n    Returns:\n        np.ndarray: The prediction results from the model.\n\n    Raises:\n        ValueError: If the model has not been trained (`self.trained` is False).\n        ValueError: If the specified model name is not found in the predictor.\n    \"\"\"\n    if not self.trained:\n        raise ValueError(\"The model must be trained before performing inference.\")\n    if not model is None and not model in self.model_names():\n        raise ValueError(f\"Model '{model}' not in trainer. Use model_names() to list valid available models.\")\n\n    if self.task == 'survival':\n        if model is None:\n            inference = self.predictor.predict(data)\n        else:\n            inference = self.predictors[model].predict(data)\n    else:\n        if self.predictor.can_predict_proba:\n            inference = self.predictor.predict_proba(data, model, as_pandas=False)[:, 1]\n        else:\n            inference = self.predictor.predict(data, model, as_pandas=False)\n\n    return inference\n</code></pre>"},{"location":"api/trainer/#jarvais.trainer.TrainerSupervised.load_trainer","title":"<code>load_trainer(project_dir)</code>  <code>classmethod</code>","text":"<p>Load a trained TrainerSupervised from the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>project_dir</code> <code>str or Path</code> <p>The directory where the trainer was run.</p> required <p>Returns:</p> Name Type Description <code>trainer</code> <code>TrainerSupervised</code> <p>The loaded Trainer.</p> Source code in <code>src/jarvais/trainer/trainer.py</code> <pre><code>@classmethod\ndef load_trainer(cls, project_dir: str | Path):\n    \"\"\"\n    Load a trained TrainerSupervised from the specified directory.\n\n    Args:\n        project_dir (str or Path, optional): The directory where the trainer was run.\n\n    Returns:\n        trainer (TrainerSupervised): The loaded Trainer.\n    \"\"\"\n    project_dir = Path(project_dir)\n    with (project_dir / 'trainer_config.yaml').open('r') as f:\n        trainer_config = yaml.safe_load(f)\n\n    trainer = cls()\n    trainer.task = trainer_config['task']\n    trainer.output_dir = project_dir\n\n    if trainer.task == 'survival':\n        model_dir = (project_dir / 'survival_models')\n\n        trainer.predictors = {}\n        model_info = trainer_config['survival_models_info']\n        for model_name, _ in model_info.items():\n            if model_name == 'MTLR':\n                trainer.predictors[model_name] = LitMTLR.load_from_checkpoint(model_dir / \"MTLR.ckpt\")\n            elif model_name == 'DeepSurv':\n                trainer.predictors[model_name] = LitDeepSurv.load_from_checkpoint(model_dir / \"DeepSurv.ckpt\")\n            else:\n                with (model_dir / f'{model_name}.pkl').open(\"rb\") as f:\n                    trainer.predictors[model_name] = pickle.load(f)\n\n        trainer.predictor = trainer.predictors[max(model_info, key=model_info.get)]\n    else:\n        model_dir = (project_dir / 'autogluon_models' / 'autogluon_models_best_fold')\n        trainer.predictor = TabularPredictor.load(model_dir, verbosity=1)\n\n    trainer.trained = True\n\n    trainer.X_test = pd.read_csv(project_dir / 'data' / 'X_test.csv')\n    trainer.X_val = pd.read_csv(project_dir / 'data' / 'X_val.csv')\n    trainer.X_train = pd.read_csv(project_dir / 'data' / 'X_train.csv')\n    trainer.y_test = pd.read_csv(project_dir / 'data' / 'y_test.csv').squeeze()\n    trainer.y_val = pd.read_csv(project_dir / 'data' / 'y_val.csv').squeeze()\n    trainer.y_train = pd.read_csv(project_dir / 'data' / 'y_train.csv').squeeze()\n\n    return trainer\n</code></pre>"},{"location":"get_started/analyzer/","title":"Analyzer Quick Start","text":""},{"location":"get_started/analyzer/#analyzer","title":"Analyzer","text":"<p>The <code>Analyzer</code> module is designed for data visualization and exploration. It helps to gain insights into the data, identify patterns, and assess relationships between different features, which is essential for building effective models.</p>"},{"location":"get_started/analyzer/#example-usage","title":"Example Usage","text":"<pre><code>from jarvais.analyzer import Analyzer\n\nanalyzer = Analyzer(data, target_variable='target', output_dir='.')\nanalyzer.run()\n</code></pre>"},{"location":"get_started/analyzer/#example-output","title":"Example Output","text":"<pre><code>Feature Types:\n  - Categorical: ['Gender', 'Disease Type', 'Treatment']\n  - Continuous: ['Age', 'Tumor Size']\n\nOutlier Detection:\n  - Outliers found in Gender: ['Male: 5 out of 1000']\n  - Outliers found in Disease Type: ['Lung Cancer: 10 out of 1000']\n  - No Outliers found in Treatment\n  - Outliers found in Tumor Size: ['12.5: 2 out of 1000']\n</code></pre>"},{"location":"get_started/analyzer/#tableonedata-summary","title":"TableOne(Data Summary)","text":"Category Missing Overall n 1000 Age, mean (SD) 0 58.2 (12.3) Tumor Size, mean (SD) 0 4.5 (1.2) Gender, n (%) Female 520 (52%) Male 480 (48%) Disease Type, n (%) Breast Cancer 300 (30%) Lung Cancer 150 (15%) Prostate Cancer 100 (10%)"},{"location":"get_started/analyzer/#output-files","title":"Output Files","text":"<p>The Analyzer module generates the following files and directories:</p> <ul> <li>analysis_report.pdf: A PDF report summarizing the analysis results.</li> <li>config.yaml: Configuration file for the analysis setup.</li> <li>tableone.csv: CSV file containing summary statistics for the dataset.</li> <li>updated_data.csv: CSV file with the cleaned and processed data.</li> </ul>"},{"location":"get_started/analyzer/#figures","title":"Figures","text":""},{"location":"get_started/analyzer/#1-frequency-tables","title":"1. Frequency Tables","text":"<p>Visualizations comparing different categorical features.</p> <p></p>"},{"location":"get_started/analyzer/#2-multi-plots","title":"2. Multi-plots","text":"<p>Visualizations showing combinations of features for deeper analysis.</p> <p></p>"},{"location":"get_started/analyzer/#additional-figures","title":"Additional Figures","text":""},{"location":"get_started/analyzer/#1-pairplot","title":"1. Pairplot","text":"<p>Pairwise relationships between continuous variables.</p> <p></p>"},{"location":"get_started/analyzer/#2-pearson-correlation-matrix","title":"2. Pearson Correlation Matrix","text":"<p>A heatmap visualizing Pearson correlations between variables.</p> <p></p>"},{"location":"get_started/analyzer/#3-spearman-correlation-matrix","title":"3. Spearman Correlation Matrix","text":"<p>A heatmap visualizing Spearman correlations between variables.</p> <p></p>"},{"location":"get_started/analyzer/#4-umap-of-continuous-data","title":"4. UMAP of Continuous Data","text":"<p>UMAP visualization of continuous data.</p> <p></p>"},{"location":"get_started/analyzer/#5-kaplan-meier-curve-survival","title":"5. Kaplan Meier Curve (Survival)","text":"<p>Kaplan Meier Curves for all categorical variables. An option exclusive to survival data.</p> <p></p>"},{"location":"get_started/analyzer/#analysis-report","title":"Analysis Report","text":""},{"location":"get_started/explainer/","title":"Explainer Quick Start","text":""},{"location":"get_started/explainer/#explainer-module","title":"Explainer Module","text":"<p>The <code>Explainer</code> module is designed to evaluate trained models by generating diagnostic plots, auditing bias, and producing comprehensive reports. It supports various supervised learning tasks, including classification, regression, and survival models. </p> <p>The module provides an easy-to-use interface for model diagnostics, bias analysis, and feature importance visualization, facilitating deeper insights into the model's performance and fairness.</p>"},{"location":"get_started/explainer/#features","title":"Features","text":"<ul> <li>Diagnostic Plots: Generates performance diagnostics, including classification metrics, regression plots, and SHAP value visualizations.</li> <li>Bias Audit: Identifies potential biases in model predictions with respect to sensitive features.</li> <li>Feature Importance: Calculates and visualizes feature importance using permutation importance or model-specific methods.</li> <li>Comprehensive Reports: Creates a detailed PDF report summarizing all diagnostic results.</li> </ul>"},{"location":"get_started/explainer/#example-usage","title":"Example Usage","text":"<pre><code>from jarvais.explainer import Explainer\n\n# Prefered method is to initialize from trainer\nexp = Explainer.from_trainer(trainer)\nexp.run()\n</code></pre>"},{"location":"get_started/explainer/#output-files","title":"Output Files","text":"<p>The Explainer module generates the following files and directories:</p> <ul> <li>explainer_report.pdf: A PDF report summarizing the model diagnostics, bias audit results, and feature importance.</li> <li>bias/: Contains CSV files with bias metrics for different sensitive features.</li> </ul>"},{"location":"get_started/explainer/#common-figures","title":"Common Figures","text":""},{"location":"get_started/explainer/#feature-importance","title":"Feature Importance","text":""},{"location":"get_started/explainer/#bootsrapped-metrics","title":"Bootsrapped Metrics","text":""},{"location":"get_started/explainer/#classification-figures","title":"Classification Figures","text":""},{"location":"get_started/explainer/#confusion-matrix","title":"Confusion Matrix","text":""},{"location":"get_started/explainer/#model-evaluation","title":"Model Evaluation","text":""},{"location":"get_started/explainer/#shap-plots","title":"Shap Plots","text":""},{"location":"get_started/explainer/#regression-figures","title":"Regression Figures","text":""},{"location":"get_started/explainer/#residual-plots","title":"Residual Plots","text":""},{"location":"get_started/explainer/#true-vs-predicted","title":"True vs Predicted","text":""},{"location":"get_started/explainer/#explainer-report","title":"Explainer Report","text":""},{"location":"get_started/trainer/","title":"Trainer Quick Start","text":""},{"location":"get_started/trainer/#trainer-module","title":"Trainer Module","text":"<p>The <code>Trainer</code> module simplifies and automates the process of feature reduction, model training, and evaluation for various machine learning tasks, ensuring flexibility and efficiency.</p>"},{"location":"get_started/trainer/#key-features","title":"Key Features","text":"<ol> <li> <p>Feature Reduction:</p> <ul> <li>Supports methods such as <code>mrmr</code>, <code>variance_threshold</code>, <code>corr</code>, and <code>chi2</code> to identify and retain relevant features.</li> </ul> </li> <li> <p>Automated Model Training:</p> <ul> <li>Integrates with AutoGluon for model training, selection, and optimization.</li> <li>Handles tasks such as binary classification, multiclass classification, regression, and survival.</li> </ul> </li> </ol>"},{"location":"get_started/trainer/#example-usage","title":"Example Usage","text":"<pre><code>from jarvais.trainer import TrainerSupervised\n\ntrainer = TrainerSupervised(task='binary', output_dir='./trainer_outputs')\ntrainer.run(data=data, target_variable='target', save_data=True)\n</code></pre>"},{"location":"get_started/trainer/#example-output","title":"Example Output","text":"<pre><code>Training fold 1/5...  \nFold 1 score: `0.8467207586933614`\n\nTraining fold 2/5...  \nFold 2 score: `0.8487846136306914`\n...\n</code></pre>"},{"location":"get_started/trainer/#model-leaderboard","title":"Model Leaderboard","text":"<p>Displays values in <code>mean [min, max]</code> format across training folds.</p> Model Score Test Score Val Score Train WeightedEnsemble_L2 AUROC: 0.82 [0.82, 0.83] AUROC: 0.85 [0.85, 0.85] AUROC: 1.0 [1.0, 1.0] F1: 0.13 [0.11, 0.14] F1: 0.09 [0.07, 0.12] F1: 0.95 [0.9, 1.0] AUPRC: 0.48 [0.45, 0.52] AUPRC: 0.47 [0.44, 0.49] AUPRC: 0.96 [0.91, 1.0] ExtraTreesGini AUROC: 0.82 [0.82, 0.82] AUROC: 0.84 [0.84, 0.84] AUROC: 1.0 [1.0, 1.0] F1: 0.21 [0.19, 0.22] F1: 0.16 [0.14, 0.18] F1: 1.0 [1.0, 1.0] AUPRC: 0.45 [0.45, 0.45] AUPRC: 0.43 [0.41, 0.45] AUPRC: 1.0 [1.0, 1.0] ..."},{"location":"get_started/trainer/#output-files","title":"Output Files","text":"<p>Binary/Regression/Multiclass:</p> <pre><code>\u251c\u2500\u2500 autogluon_models\n\u2502   \u251c\u2500\u2500 autogluon_models_best_fold\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 autogluon_models_fold_1\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 autogluon_models_fold_2\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 autogluon_models_fold_3\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 autogluon_models_fold_4\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 autogluon_models_fold_5\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n</code></pre> <p>Survival:</p> <pre><code>\u2514\u2500\u2500 survival_models\n    \u251c\u2500\u2500 CoxPH.pkl\n    \u251c\u2500\u2500 GradientBoosting.pkl\n    \u251c\u2500\u2500 RandomForest.pkl\n    \u2514\u2500\u2500 SVM.pkl\n    \u251c\u2500\u2500 lightning_logs\n    \u2502   \u251c\u2500\u2500 version_0\n    \u2502   \u251c\u2500\u2500 ...\n    \u251c\u2500\u2500 DeepSurv.ckpt\n    \u251c\u2500\u2500 MTLR.ckpt\n</code></pre>"},{"location":"tutorials/classification/","title":"Classification","text":"In\u00a0[1]: Copied! <pre>import sys\n\nimport os\n\n# Get the absolute path of the project root directory\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Add the project root directory to the Python path\nsys.path.append(project_root)\n</pre> import sys  import os  # Get the absolute path of the project root directory project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Add the project root directory to the Python path sys.path.append(project_root) In\u00a0[2]: Copied! <pre>import pandas as pd\n\n\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Define the path to the data directory\ndata_dir = os.path.join(project_root, 'data')\n\n# Example: Access a specific data file in the data directory\ndata_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv')\ndf = pd.read_csv(data_file_path)\n</pre>  import pandas as pd   project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Define the path to the data directory data_dir = os.path.join(project_root, 'data')  # Example: Access a specific data file in the data directory data_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv') df = pd.read_csv(data_file_path) <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[2], line 11\n      9 # Example: Access a specific data file in the data directory\n     10 data_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv')\n---&gt; 11 df = pd.read_csv(data_file_path)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '/home/runner/work/jarvais/jarvais/data/RADCURE_challenge_clinical.csv'</pre> In\u00a0[3]: Copied! <pre>from jarvais.analyzer import Analyzer\nfrom pprint import pprint\n\ndf.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)\n\nconfig = Analyzer.dry_run(df)\n\npprint(config)\n</pre> from jarvais.analyzer import Analyzer from pprint import pprint  df.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)  config = Analyzer.dry_run(df)  pprint(config) <pre>/home/runner/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 4\n      1 from jarvais.analyzer import Analyzer\n      2 from pprint import pprint\n----&gt; 4 df.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)\n      6 config = Analyzer.dry_run(df)\n      8 pprint(config)\n\nNameError: name 'df' is not defined</pre> In\u00a0[4]: Copied! <pre>import yaml\nfrom pathlib import Path\n\nconfig['columns']['categorical'].remove('Dose')\nconfig['columns']['continuous'].append('Dose') \n\npprint(config)\n\nanalyzer_path = Path('outputs/analyzer')\nanalyzer_path.mkdir(parents=True, exist_ok=True)\n\nwith open(analyzer_path / 'config.yaml', 'w') as f:\n            yaml.dump(config, f)\n</pre> import yaml from pathlib import Path  config['columns']['categorical'].remove('Dose') config['columns']['continuous'].append('Dose')   pprint(config)  analyzer_path = Path('outputs/analyzer') analyzer_path.mkdir(parents=True, exist_ok=True)  with open(analyzer_path / 'config.yaml', 'w') as f:             yaml.dump(config, f) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 4\n      1 import yaml\n      2 from pathlib import Path\n----&gt; 4 config['columns']['categorical'].remove('Dose')\n      5 config['columns']['continuous'].append('Dose') \n      7 pprint(config)\n\nNameError: name 'config' is not defined</pre> In\u00a0[5]: Copied! <pre>from jarvais.analyzer import Analyzer\n\nanalyzer = Analyzer(df, target_variable='Chemotherapy', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')\n\nanalyzer.run()\n</pre> from jarvais.analyzer import Analyzer  analyzer = Analyzer(df, target_variable='Chemotherapy', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')  analyzer.run() <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 3\n      1 from jarvais.analyzer import Analyzer\n----&gt; 3 analyzer = Analyzer(df, target_variable='Chemotherapy', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')\n      5 analyzer.run()\n\nNameError: name 'df' is not defined</pre> In\u00a0[6]: Copied! <pre>from jarvais.trainer import TrainerSupervised\n\ndf = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)\n\ntrainer = TrainerSupervised(task='binary', output_dir='./outputs/trainer')\ntrainer.run(df, 'Chemotherapy')\n</pre> from jarvais.trainer import TrainerSupervised  df = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)  trainer = TrainerSupervised(task='binary', output_dir='./outputs/trainer') trainer.run(df, 'Chemotherapy') <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[6], line 3\n      1 from jarvais.trainer import TrainerSupervised\n----&gt; 3 df = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)\n      5 trainer = TrainerSupervised(task='binary', output_dir='./outputs/trainer')\n      6 trainer.run(df, 'Chemotherapy')\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: './outputs/analyzer/updated_data.csv'</pre> In\u00a0[7]: Copied! <pre>trainer.X_test\n</pre> trainer.X_test <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 trainer.X_test\n\nNameError: name 'trainer' is not defined</pre> In\u00a0[8]: Copied! <pre>from jarvais.explainer import Explainer\n\nsensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}\n\nexp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features)\nexp.run()\n</pre> from jarvais.explainer import Explainer  sensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}  exp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features) exp.run() <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[8], line 3\n      1 from jarvais.explainer import Explainer\n----&gt; 3 sensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}\n      5 exp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features)\n      6 exp.run()\n\nNameError: name 'trainer' is not defined</pre>"},{"location":"tutorials/regression/","title":"Regression","text":"In\u00a0[1]: Copied! <pre>import sys\n\nimport os\n\n# Get the absolute path of the project root directory\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Add the project root directory to the Python path\nsys.path.append(project_root)\n</pre> import sys  import os  # Get the absolute path of the project root directory project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Add the project root directory to the Python path sys.path.append(project_root) In\u00a0[2]: Copied! <pre>import pandas as pd\n\n\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Define the path to the data directory\ndata_dir = os.path.join(project_root, 'data')\n\n# Example: Access a specific data file in the data directory\ndata_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv')\ndf = pd.read_csv(data_file_path)\n</pre> import pandas as pd   project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Define the path to the data directory data_dir = os.path.join(project_root, 'data')  # Example: Access a specific data file in the data directory data_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv') df = pd.read_csv(data_file_path) <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[2], line 11\n      9 # Example: Access a specific data file in the data directory\n     10 data_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv')\n---&gt; 11 df = pd.read_csv(data_file_path)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '/home/runner/work/jarvais/jarvais/data/RADCURE_challenge_clinical.csv'</pre> In\u00a0[3]: Copied! <pre>from jarvais.analyzer import Analyzer\nfrom pprint import pprint\n\ndf.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)\n\nconfig = Analyzer.dry_run(df)\n\npprint(config)\n</pre> from jarvais.analyzer import Analyzer from pprint import pprint  df.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)  config = Analyzer.dry_run(df)  pprint(config) <pre>/home/runner/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 4\n      1 from jarvais.analyzer import Analyzer\n      2 from pprint import pprint\n----&gt; 4 df.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)\n      6 config = Analyzer.dry_run(df)\n      8 pprint(config)\n\nNameError: name 'df' is not defined</pre> In\u00a0[4]: Copied! <pre>import yaml\nfrom pathlib import Path\n\nconfig['columns']['categorical'].remove('Dose')\nconfig['columns']['continuous'].append('Dose') \n\npprint(config)\n\nanalyzer_path = Path('outputs/analyzer')\nanalyzer_path.mkdir(parents=True, exist_ok=True)\n\nwith open(analyzer_path / 'config.yaml', 'w') as f:\n            yaml.dump(config, f)\n</pre> import yaml from pathlib import Path  config['columns']['categorical'].remove('Dose') config['columns']['continuous'].append('Dose')   pprint(config)  analyzer_path = Path('outputs/analyzer') analyzer_path.mkdir(parents=True, exist_ok=True)  with open(analyzer_path / 'config.yaml', 'w') as f:             yaml.dump(config, f) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 4\n      1 import yaml\n      2 from pathlib import Path\n----&gt; 4 config['columns']['categorical'].remove('Dose')\n      5 config['columns']['continuous'].append('Dose') \n      7 pprint(config)\n\nNameError: name 'config' is not defined</pre> In\u00a0[5]: Copied! <pre>from jarvais.analyzer import Analyzer\n\nanalyzer = Analyzer(df, target_variable='Dose', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')\n\nanalyzer.run()\n</pre> from jarvais.analyzer import Analyzer  analyzer = Analyzer(df, target_variable='Dose', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')  analyzer.run() <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 3\n      1 from jarvais.analyzer import Analyzer\n----&gt; 3 analyzer = Analyzer(df, target_variable='Dose', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')\n      5 analyzer.run()\n\nNameError: name 'df' is not defined</pre> In\u00a0[6]: Copied! <pre>from jarvais.trainer import TrainerSupervised\n\ndf = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)\n\ntrainer = TrainerSupervised(task='regression', output_dir='./outputs/trainer')\ntrainer.run(df, 'Dose')\n</pre> from jarvais.trainer import TrainerSupervised  df = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)  trainer = TrainerSupervised(task='regression', output_dir='./outputs/trainer') trainer.run(df, 'Dose') <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[6], line 3\n      1 from jarvais.trainer import TrainerSupervised\n----&gt; 3 df = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)\n      5 trainer = TrainerSupervised(task='regression', output_dir='./outputs/trainer')\n      6 trainer.run(df, 'Dose')\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: './outputs/analyzer/updated_data.csv'</pre> In\u00a0[7]: Copied! <pre>from jarvais.explainer import Explainer\n\nsensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}\n\nexp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features)\nexp.run()\n</pre> from jarvais.explainer import Explainer  sensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}  exp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features) exp.run() <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 3\n      1 from jarvais.explainer import Explainer\n----&gt; 3 sensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}\n      5 exp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features)\n      6 exp.run()\n\nNameError: name 'trainer' is not defined</pre>"},{"location":"tutorials/survival/","title":"Survival","text":"In\u00a0[1]: Copied! <pre>import sys\n\nimport os\n\n# Get the absolute path of the project root directory\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Add the project root directory to the Python path\nsys.path.append(project_root)\n</pre> import sys  import os  # Get the absolute path of the project root directory project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Add the project root directory to the Python path sys.path.append(project_root) In\u00a0[2]: Copied! <pre>import pandas as pd\n\n\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Define the path to the data directory\ndata_dir = os.path.join(project_root, 'data')\n\n# Example: Access a specific data file in the data directory\ndata_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv')\ndf = pd.read_csv(data_file_path)\n</pre> import pandas as pd   project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Define the path to the data directory data_dir = os.path.join(project_root, 'data')  # Example: Access a specific data file in the data directory data_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv') df = pd.read_csv(data_file_path) <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[2], line 11\n      9 # Example: Access a specific data file in the data directory\n     10 data_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv')\n---&gt; 11 df = pd.read_csv(data_file_path)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '/home/runner/work/jarvais/jarvais/data/RADCURE_challenge_clinical.csv'</pre> In\u00a0[3]: Copied! <pre>from jarvais.analyzer import Analyzer\nfrom pprint import pprint\n\ndf.drop(columns=[\"Study ID\", \"split\"], inplace=True)\ndf.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)\n\nconfig = Analyzer.dry_run(df)\n\npprint(config)\n</pre> from jarvais.analyzer import Analyzer from pprint import pprint  df.drop(columns=[\"Study ID\", \"split\"], inplace=True) df.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)  config = Analyzer.dry_run(df)  pprint(config) <pre>/home/runner/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 4\n      1 from jarvais.analyzer import Analyzer\n      2 from pprint import pprint\n----&gt; 4 df.drop(columns=[\"Study ID\", \"split\"], inplace=True)\n      5 df.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)\n      7 config = Analyzer.dry_run(df)\n\nNameError: name 'df' is not defined</pre> In\u00a0[4]: Copied! <pre>import yaml\nfrom pathlib import Path\n\nconfig['columns']['categorical'].remove('Dose')\nconfig['columns']['continuous'].append('Dose') \n\npprint(config)\n\nanalyzer_path = Path('radcure_outputs/analyzer')\nanalyzer_path.mkdir(parents=True, exist_ok=True)\n\nwith open(analyzer_path / 'config.yaml', 'w') as f:\n            yaml.dump(config, f)\n</pre> import yaml from pathlib import Path  config['columns']['categorical'].remove('Dose') config['columns']['continuous'].append('Dose')   pprint(config)  analyzer_path = Path('radcure_outputs/analyzer') analyzer_path.mkdir(parents=True, exist_ok=True)  with open(analyzer_path / 'config.yaml', 'w') as f:             yaml.dump(config, f) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[4], line 4\n      1 import yaml\n      2 from pathlib import Path\n----&gt; 4 config['columns']['categorical'].remove('Dose')\n      5 config['columns']['continuous'].append('Dose') \n      7 pprint(config)\n\nNameError: name 'config' is not defined</pre> In\u00a0[5]: Copied! <pre>from jarvais.analyzer import Analyzer\n\nanalyzer = Analyzer(df, task='survival', target_variable='event', output_dir='./radcure_outputs/analyzer', one_hot_encode=True, config='radcure_outputs/analyzer/config.yaml')\n\nanalyzer.run()\n</pre> from jarvais.analyzer import Analyzer  analyzer = Analyzer(df, task='survival', target_variable='event', output_dir='./radcure_outputs/analyzer', one_hot_encode=True, config='radcure_outputs/analyzer/config.yaml')  analyzer.run() <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[5], line 3\n      1 from jarvais.analyzer import Analyzer\n----&gt; 3 analyzer = Analyzer(df, task='survival', target_variable='event', output_dir='./radcure_outputs/analyzer', one_hot_encode=True, config='radcure_outputs/analyzer/config.yaml')\n      5 analyzer.run()\n\nNameError: name 'df' is not defined</pre> In\u00a0[6]: Copied! <pre>from jarvais.trainer import TrainerSupervised\n\ndf = pd.read_csv('./radcure_outputs/analyzer/updated_data.csv', index_col=0)\ndf.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)\n\ntrainer = TrainerSupervised(task='survival', output_dir='./radcure_outputs/ED_trainer_explainer',)\ntrainer.run(df, ['event','time'])\n</pre> from jarvais.trainer import TrainerSupervised  df = pd.read_csv('./radcure_outputs/analyzer/updated_data.csv', index_col=0) df.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)  trainer = TrainerSupervised(task='survival', output_dir='./radcure_outputs/ED_trainer_explainer',) trainer.run(df, ['event','time']) <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[6], line 3\n      1 from jarvais.trainer import TrainerSupervised\n----&gt; 3 df = pd.read_csv('./radcure_outputs/analyzer/updated_data.csv', index_col=0)\n      4 df.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)\n      6 trainer = TrainerSupervised(task='survival', output_dir='./radcure_outputs/ED_trainer_explainer',)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: './radcure_outputs/analyzer/updated_data.csv'</pre> In\u00a0[7]: Copied! <pre>from jarvais.trainer import TrainerSupervised\n\ntrainer = TrainerSupervised.load_trainer('./radcure_outputs/ED_trainer_explainer')\n</pre> from jarvais.trainer import TrainerSupervised  trainer = TrainerSupervised.load_trainer('./radcure_outputs/ED_trainer_explainer') <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[7], line 3\n      1 from jarvais.trainer import TrainerSupervised\n----&gt; 3 trainer = TrainerSupervised.load_trainer('./radcure_outputs/ED_trainer_explainer')\n\nFile ~/work/jarvais/jarvais/src/jarvais/trainer/trainer.py:396, in TrainerSupervised.load_trainer(cls, project_dir)\n    386 \"\"\"\n    387 Load a trained TrainerSupervised from the specified directory.\n    388 \n   (...)\n    393     trainer (TrainerSupervised): The loaded Trainer.\n    394 \"\"\"\n    395 project_dir = Path(project_dir)\n--&gt; 396 with (project_dir / 'trainer_config.yaml').open('r') as f:\n    397     trainer_config = yaml.safe_load(f)\n    399 trainer = cls()\n\nFile ~/work/jarvais/jarvais/.pixi/envs/default/lib/python3.12/pathlib.py:1013, in Path.open(self, mode, buffering, encoding, errors, newline)\n   1011 if \"b\" not in mode:\n   1012     encoding = io.text_encoding(encoding)\n-&gt; 1013 return io.open(self, mode, buffering, encoding, errors, newline)\n\nFileNotFoundError: [Errno 2] No such file or directory: 'radcure_outputs/ED_trainer_explainer/trainer_config.yaml'</pre> In\u00a0[8]: Copied! <pre>from jarvais.explainer import Explainer\n\nexp = Explainer.from_trainer(trainer)\nexp.run()\n</pre> from jarvais.explainer import Explainer  exp = Explainer.from_trainer(trainer) exp.run() <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[8], line 3\n      1 from jarvais.explainer import Explainer\n----&gt; 3 exp = Explainer.from_trainer(trainer)\n      4 exp.run()\n\nNameError: name 'trainer' is not defined</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}]}