{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#welcome-to-jarvais","title":"Welcome to jarvAIs","text":"<p>Official Github here.</p>"},{"location":"#overview","title":"Overview","text":"<p><code>jarvAIs</code> is a Python package designed to automate and enhance machine learning workflows. The primary goal of this project is to reduce redundancy in repetitive tasks, improve consistency, and elevate the quality of standardized processes in oncology research.</p> <p>Follow pixi installation process found here</p> <pre><code># Clone Repo\ngit clone https://github.com/pmcdi/jarvais.git\n\n# Navigate to project\ncd jarvais\n\n# Install dependencies\npixi install\n</code></pre>"},{"location":"#modules","title":"Modules","text":"<p>This package consists of 3 different modules:</p> <ul> <li>Analyzer: A module that analyzes and processes data, providing valuable insights for downstream tasks.</li> <li>Trainer: A module for training machine learning models, designed to be flexible and efficient.</li> <li>Explainer: A module that explains model predictions, offering interpretability and transparency in decision-making.</li> </ul>"},{"location":"api/analyzer/","title":"Analyzer","text":""},{"location":"api/analyzer/#analyzer","title":"Analyzer","text":"<p>The <code>Analyzer</code> class is part of the <code>jarvais.analyzer</code> module. It provides tools for exploring datasets and identifying issues.</p>"},{"location":"api/analyzer/#jarvais.analyzer.Analyzer","title":"<code>jarvais.analyzer.Analyzer</code>","text":"<p>A data analysis and cleaning tool for preprocessing datasets, generating reports, and visualizations.</p> Features <ul> <li>Handles missing values and outliers.</li> <li>Infers column types (categorical, continuous, date).</li> <li>Supports one-hot encoding and survival analysis.</li> <li>Generates summary statistics and correlation plots.</li> <li>Produces a comprehensive PDF analysis report.</li> </ul> <p>Attributes:</p> Name Type Description <code>data</code> <code>DataFrame</code> <p>Input dataset.</p> <code>target_variable</code> <code>str</code> <p>Target variable in the dataset.</p> <code>task</code> <code>str</code> <p>Type of analysis task.</p> <code>one_hot_encode</code> <code>bool</code> <p>Whether to one-hot encode categorical columns.</p> <code>config</code> <code>str | Path</code> <p>Path to a YAML configuration file.</p> <code>output_dir</code> <code>str | Path</code> <p>Directory to save outputs. Default is the current directory.</p> Example <pre><code>from jarvais.analyzer import Analyzer\nimport pandas as pd\n\ndata = pd.DataFrame({\n    \"age\": [25, 32, 40],\n    \"income\": [50000, 60000, 75000],\n    \"category\": [\"A\", \"B\", \"A\"]\n})\n\nanalyzer = Analyzer(data, target_variable=\"income\", task=\"regression\")\nanalyzer.run()\n</code></pre> Source code in <code>src/jarvais/analyzer/analyzer.py</code> <pre><code>class Analyzer:\n    \"\"\"\n    A data analysis and cleaning tool for preprocessing datasets, generating reports, and visualizations.\n\n    Features:\n        - Handles missing values and outliers.\n        - Infers column types (categorical, continuous, date).\n        - Supports one-hot encoding and survival analysis.\n        - Generates summary statistics and correlation plots.\n        - Produces a comprehensive PDF analysis report.\n\n    Attributes:\n        data (pd.DataFrame): Input dataset.\n        target_variable (str, optional): Target variable in the dataset.\n        task (str, optional): Type of analysis task.\n        one_hot_encode (bool, optional): Whether to one-hot encode categorical columns.\n        config (str | Path, optional): Path to a YAML configuration file.\n        output_dir (str | Path, optional): Directory to save outputs. Default is the current directory.\n\n    Example:\n        ```python\n        from jarvais.analyzer import Analyzer\n        import pandas as pd\n\n        data = pd.DataFrame({\n            \"age\": [25, 32, 40],\n            \"income\": [50000, 60000, 75000],\n            \"category\": [\"A\", \"B\", \"A\"]\n        })\n\n        analyzer = Analyzer(data, target_variable=\"income\", task=\"regression\")\n        analyzer.run()\n        ```\n    \"\"\"\n    def __init__(\n            self,\n            data: pd.DataFrame,\n            target_variable: str | None = None,\n            task: str | None = None,\n            one_hot_encode: bool = False,\n            config: str | Path = None,\n            output_dir: str | Path = None\n        ) -&gt; None:\n\n        self.data = data\n        self.target_variable = target_variable\n        self.task = task\n        self.one_hot_encode = one_hot_encode\n\n        assert_message = \"When setting task to 'survival', target_variable must be 'event' and 'time' must be in data\"\n        if self.task == 'survival':\n            assert target_variable == 'event' and 'time' in data.columns, assert_message\n\n        self.output_dir = Path.cwd() if output_dir is None else Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n\n        if config is not None:\n            config = Path(config)\n            if config.is_file():\n                with config.open('r') as file:\n                    self.config = yaml.safe_load(file)\n            else:\n                raise ValueError(f'Config file does not exist at {config}')\n        else:\n            self.config = config\n\n        self.outlier_analysis = '' # Used later when writing to PDF\n\n    def _create_config(self) -&gt; None:\n        \"\"\"\n        Create and save a configuration file for column types, outlier handling, and missing value strategies.\n\n        Steps:\n        1. **Infer Column Types**: Identifies categorical, continuous, and date columns using `infer_types`.\n        2. **Handle NaN Columns**: Drops columns entirely filled with NaN and updates the continuous column list.\n        3. **Outlier Detection**: Identifies outliers in categorical columns and stores the mappings.\n        4. **Missing Value Strategy**: Sets default imputation strategies for categorical and continuous variables.\n        \"\"\"\n        print('Config file not found. Creating custom...')\n\n        self.config = {}\n        columns = {}\n\n        self.categorical_columns, self.continuous_columns, self.date_columns = infer_types(self.data)\n        # Replace all non numerical values with NaN\n        self.data[self.continuous_columns] = self.data[self.continuous_columns].apply(pd.to_numeric, errors='coerce')\n\n        nan_ = self.data.apply(lambda col: col.isna().all())\n        nan_columns = nan_[nan_].index.tolist()\n        if len(nan_columns) &gt; 0:\n            print(\"Columns that are all NaN(probably ID columns) dropping...: \", nan_columns)\n            self.continuous_columns = list(set(self.continuous_columns) - set(nan_columns))\n\n        print(\"Used a heuristic to define categorical and continuous columns. Please review!\")\n\n        columns['categorical'] = self.categorical_columns\n        columns['continuous'] = self.continuous_columns\n        columns['date'] = self.date_columns\n        columns['other'] = nan_columns\n\n        self.config['columns'] = columns\n\n        outlier_analysis, mapping = get_outliers(self.data, self.categorical_columns)\n\n        self.outlier_analysis += outlier_analysis\n        self.config['mapping'] = mapping\n\n        self.config['missingness_strategy'] = {}\n        # Defining default replacement for each missing categorical variable\n        self.config['missingness_strategy']['categorical'] = {cat :'Unknown' for cat in self.categorical_columns}\n        # Defining default replacement for each missing continuous variable\n        self.config['missingness_strategy']['continuous'] = {cont :'median' for cont in self.continuous_columns}\n\n    def _apply_config(self) -&gt; None:\n\n        print('Applying changes from config...\\n')\n\n        for key in self.config['mapping'].keys():\n            assert key in self.data.columns, f\"{key} in mapping file not found data\"\n            self.data.loc[:, [key]] = self.data.loc[:, key].replace(self.config['mapping'][key])\n\n        self.data = replace_missing(self.data, self.categorical_columns, self.continuous_columns, self.config)\n\n    def _create_multiplots(self, figures_dir: Path) -&gt; None:\n        \"\"\"Generate and save multiplots for each categorical variable against all continuous variables.\"\"\"\n        self.multiplots = [] # Used to save in PDF later\n\n        (figures_dir / 'multiplots').mkdir(parents=True, exist_ok=True)\n\n        self.multiplots = Parallel(n_jobs=-1)(\n            delayed(plot_one_multiplot)(\n                self.data,\n                self.umap_data,\n                var,\n                self.continuous_columns,\n                figures_dir\n            ) for var in self.categorical_columns\n        )\n\n    def run(self) -&gt; None:\n        \"\"\"Run the data cleaning and visualization process.\"\"\"\n        if self.config is None:\n            self._create_config()\n        else:\n            self.continuous_columns = self.config['columns']['continuous']\n            self.categorical_columns = self.config['columns']['categorical']\n            # Replace all non numerical values with NaN\n            self.data[self.continuous_columns] = self.data[self.continuous_columns].apply(pd.to_numeric, errors='coerce')\n            self.outlier_analysis, _ = get_outliers(self.data, self.categorical_columns)\n\n        print(f\"Feature Types:\\n  - Categorical: {self.categorical_columns}\\n  - Continuous: {self.continuous_columns}\")\n        print(f\"\\n\\nOutlier Analysis:\\n{self.outlier_analysis}\")\n\n        with open(self.output_dir / 'config.yaml', 'w') as f:\n            yaml.dump(self.config, f)\n\n        self._apply_config()\n\n        # Create Table One\n        df_keep = self.data[self.continuous_columns + self.categorical_columns]\n\n        self.mytable = TableOne(df_keep, categorical=self.categorical_columns, pval=False)\n        print(self.mytable.tabulate(tablefmt = \"fancy_grid\"))\n        self.mytable.to_csv(self.output_dir / 'tableone.csv')\n\n        # PLOTS\n        figures_dir = self.output_dir / 'figures'\n        figures_dir.mkdir(exist_ok=True, parents=True)\n\n        if self.task == 'survival':\n            data_x = self.data.drop(columns=['time', 'event'])\n            data_y = self.data[['time', 'event']]\n            categorical_columns  = [cat for cat in self.categorical_columns if cat != 'event']\n            plot_kaplan_meier_by_category(\n                data_x, data_y,\n                categorical_columns,\n                figures_dir / 'kaplan_meier'\n            )\n\n        # Correlation Plots\n        p_corr = self.data[self.continuous_columns].corr(method=\"pearson\")\n        s_corr = self.data[self.continuous_columns].corr(method=\"spearman\")\n        size = len(self.continuous_columns)*1.5\n        plot_corr(p_corr, size, file_name='pearson_correlation.png', output_dir=figures_dir)\n        plot_corr(s_corr, size, file_name='spearman_correlation.png', output_dir=figures_dir)\n\n        # Categorical cross frequency table\n        plot_frequency_table(self.data, self.categorical_columns, figures_dir)\n\n        # UMAP reduced data + Plots\n        self.umap_data = plot_umap(self.data, self.continuous_columns, figures_dir)\n\n        # Plot pairplot: keeping only the top ten correlated pairs in the pair plot\n        if self.target_variable in self.categorical_columns:\n            plot_pairplot(self.data, self.continuous_columns, output_dir=figures_dir, target_variable=self.target_variable)\n        else:\n            plot_pairplot(self.data, self.continuous_columns, output_dir=figures_dir)\n\n        # Create Multiplots\n        self._create_multiplots(figures_dir)\n\n        if self.one_hot_encode:\n            self.data = pd.get_dummies(\n                self.data,\n                columns=[cat for cat in self.categorical_columns if cat != self.target_variable],\n                dtype=float\n            )\n\n        self.data.to_csv(self.output_dir / 'updated_data.csv')\n\n        # Create Output PDF\n        generate_analysis_report_pdf(\n            self.outlier_analysis,\n            self.multiplots,\n            self.categorical_columns,\n            self.output_dir\n        )\n\n    @classmethod\n    def dry_run(cls, data: pd.DataFrame) -&gt; dict:\n        \"\"\"Simply returns generated config and displays TableOne.\"\"\"\n        analyzer = cls(data)\n        analyzer._create_config()\n\n        df_keep = analyzer.data[analyzer.continuous_columns + analyzer.categorical_columns]\n\n        print(f\"\\n\\nFeature Types:\\n  - Categorical: {analyzer.categorical_columns}\\n  - Continuous: {analyzer.continuous_columns}\")\n        print(f\"\\n\\nOutlier Analysis:\\n{analyzer.outlier_analysis}\")\n\n        mytable = TableOne(df_keep, categorical=analyzer.categorical_columns, pval=False)\n        print(mytable.tabulate(tablefmt = \"fancy_grid\"))\n\n        return analyzer.config\n</code></pre>"},{"location":"api/analyzer/#jarvais.analyzer.Analyzer.run","title":"<code>run()</code>","text":"<p>Run the data cleaning and visualization process.</p> Source code in <code>src/jarvais/analyzer/analyzer.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Run the data cleaning and visualization process.\"\"\"\n    if self.config is None:\n        self._create_config()\n    else:\n        self.continuous_columns = self.config['columns']['continuous']\n        self.categorical_columns = self.config['columns']['categorical']\n        # Replace all non numerical values with NaN\n        self.data[self.continuous_columns] = self.data[self.continuous_columns].apply(pd.to_numeric, errors='coerce')\n        self.outlier_analysis, _ = get_outliers(self.data, self.categorical_columns)\n\n    print(f\"Feature Types:\\n  - Categorical: {self.categorical_columns}\\n  - Continuous: {self.continuous_columns}\")\n    print(f\"\\n\\nOutlier Analysis:\\n{self.outlier_analysis}\")\n\n    with open(self.output_dir / 'config.yaml', 'w') as f:\n        yaml.dump(self.config, f)\n\n    self._apply_config()\n\n    # Create Table One\n    df_keep = self.data[self.continuous_columns + self.categorical_columns]\n\n    self.mytable = TableOne(df_keep, categorical=self.categorical_columns, pval=False)\n    print(self.mytable.tabulate(tablefmt = \"fancy_grid\"))\n    self.mytable.to_csv(self.output_dir / 'tableone.csv')\n\n    # PLOTS\n    figures_dir = self.output_dir / 'figures'\n    figures_dir.mkdir(exist_ok=True, parents=True)\n\n    if self.task == 'survival':\n        data_x = self.data.drop(columns=['time', 'event'])\n        data_y = self.data[['time', 'event']]\n        categorical_columns  = [cat for cat in self.categorical_columns if cat != 'event']\n        plot_kaplan_meier_by_category(\n            data_x, data_y,\n            categorical_columns,\n            figures_dir / 'kaplan_meier'\n        )\n\n    # Correlation Plots\n    p_corr = self.data[self.continuous_columns].corr(method=\"pearson\")\n    s_corr = self.data[self.continuous_columns].corr(method=\"spearman\")\n    size = len(self.continuous_columns)*1.5\n    plot_corr(p_corr, size, file_name='pearson_correlation.png', output_dir=figures_dir)\n    plot_corr(s_corr, size, file_name='spearman_correlation.png', output_dir=figures_dir)\n\n    # Categorical cross frequency table\n    plot_frequency_table(self.data, self.categorical_columns, figures_dir)\n\n    # UMAP reduced data + Plots\n    self.umap_data = plot_umap(self.data, self.continuous_columns, figures_dir)\n\n    # Plot pairplot: keeping only the top ten correlated pairs in the pair plot\n    if self.target_variable in self.categorical_columns:\n        plot_pairplot(self.data, self.continuous_columns, output_dir=figures_dir, target_variable=self.target_variable)\n    else:\n        plot_pairplot(self.data, self.continuous_columns, output_dir=figures_dir)\n\n    # Create Multiplots\n    self._create_multiplots(figures_dir)\n\n    if self.one_hot_encode:\n        self.data = pd.get_dummies(\n            self.data,\n            columns=[cat for cat in self.categorical_columns if cat != self.target_variable],\n            dtype=float\n        )\n\n    self.data.to_csv(self.output_dir / 'updated_data.csv')\n\n    # Create Output PDF\n    generate_analysis_report_pdf(\n        self.outlier_analysis,\n        self.multiplots,\n        self.categorical_columns,\n        self.output_dir\n    )\n</code></pre>"},{"location":"api/analyzer/#jarvais.analyzer.Analyzer.dry_run","title":"<code>dry_run(data)</code>  <code>classmethod</code>","text":"<p>Simply returns generated config and displays TableOne.</p> Source code in <code>src/jarvais/analyzer/analyzer.py</code> <pre><code>@classmethod\ndef dry_run(cls, data: pd.DataFrame) -&gt; dict:\n    \"\"\"Simply returns generated config and displays TableOne.\"\"\"\n    analyzer = cls(data)\n    analyzer._create_config()\n\n    df_keep = analyzer.data[analyzer.continuous_columns + analyzer.categorical_columns]\n\n    print(f\"\\n\\nFeature Types:\\n  - Categorical: {analyzer.categorical_columns}\\n  - Continuous: {analyzer.continuous_columns}\")\n    print(f\"\\n\\nOutlier Analysis:\\n{analyzer.outlier_analysis}\")\n\n    mytable = TableOne(df_keep, categorical=analyzer.categorical_columns, pval=False)\n    print(mytable.tabulate(tablefmt = \"fancy_grid\"))\n\n    return analyzer.config\n</code></pre>"},{"location":"api/explainer/","title":"Explainer","text":""},{"location":"api/explainer/#explainer","title":"Explainer","text":"<p>The <code>Explainer</code> class is part of the <code>jarvais.explainer</code> module. It generates explainability reports for trained models.</p> <p>The <code>BiasExplainer</code> class is used by the <code>Explainer</code> class to run a bias audit.</p>"},{"location":"api/explainer/#jarvais.explainer.Explainer","title":"<code>jarvais.explainer.Explainer</code>","text":"<p>A class to generate diagnostic plots and reports for models trained using TrainerSupervised.</p> <p>Attributes:</p> Name Type Description <code>trainer</code> <code>TrainerSupervised</code> <p>The TrainerSupervised object containing the trained model.</p> <code>predictor</code> <code>object</code> <p>The AutoGluon predictor object used for inference.</p> <code>X_train</code> <code>DataFrame</code> <p>The training dataset used to train the model.</p> <code>X_test</code> <code>DataFrame</code> <p>The test dataset for evaluating the model.</p> <code>y_test</code> <code>DataFrame</code> <p>The true target values for the test dataset.</p> <code>output_dir</code> <code>Path</code> <p>The directory where plots, reports, and outputs are saved.</p> <code>sensitive_features</code> <code>list</code> <p>List of features considered sensitive for bias auditing.</p> Source code in <code>src/jarvais/explainer/explainer.py</code> <pre><code>class Explainer():\n    \"\"\"\n    A class to generate diagnostic plots and reports for models trained using TrainerSupervised.\n\n    Attributes:\n        trainer (TrainerSupervised): The TrainerSupervised object containing the trained model.\n        predictor (object): The AutoGluon predictor object used for inference.\n        X_train (pd.DataFrame): The training dataset used to train the model.\n        X_test (pd.DataFrame): The test dataset for evaluating the model.\n        y_test (pd.DataFrame): The true target values for the test dataset.\n        output_dir (Path): The directory where plots, reports, and outputs are saved.\n        sensitive_features (list, optional): List of features considered sensitive for bias auditing.\n    \"\"\"\n    def __init__(\n            self,\n            trainer,\n            X_train: pd.DataFrame,\n            X_test: pd.DataFrame,\n            y_test: pd.DataFrame,\n            output_dir: str | Path | None = None,\n            sensitive_features: list | None = None,\n        ) -&gt; None:\n\n        self.trainer = trainer\n        self.predictor = trainer.predictor\n        self.X_train = X_train\n        self.X_test = X_test\n        self.y_test = y_test\n        self.sensitive_features = sensitive_features\n\n        self.output_dir = Path.cwd() if output_dir is None else Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        (self.output_dir / 'figures').mkdir(parents=True, exist_ok=True)\n\n    def run(self) -&gt; None:\n        \"\"\"Generate diagnostic plots and reports for the trained model.\"\"\"\n        if self.trainer.task != 'survival':\n            plot_violin_of_bootsrapped_metrics(\n                self.predictor,\n                self.X_test,\n                self.y_test,\n                self.trainer.X_val,\n                self.trainer.y_val,\n                self.X_train,\n                self.trainer.y_train,\n                output_dir=self.output_dir / 'figures'\n            )      \n\n            self._run_bias_audit()      \n\n        if self.trainer.task in ['binary', 'multiclass']:\n            plot_classification_diagnostics(\n                self.y_test,\n                self.predictor.predict_proba(self.X_test).iloc[:, 1],\n                self.trainer.y_val,\n                self.predictor.predict_proba(self.trainer.X_val).iloc[:, 1],\n                self.trainer.y_train,\n                self.predictor.predict_proba(self.X_train).iloc[:, 1],\n                output_dir=self.output_dir / 'figures'\n            )\n            plot_shap_values(\n                self.predictor,\n                self.X_train,\n                self.X_test,\n                output_dir=self.output_dir / 'figures'\n            )\n\n        elif self.trainer.task == 'regression':\n            plot_regression_diagnostics(\n                self.y_test,\n                self.predictor.predict(self.X_test, as_pandas=False),\n                output_dir=self.output_dir / 'figures'\n            )\n\n        # Plot feature importance\n        if self.trainer.task == 'survival': # NEEDS TO BE UPDATED\n            model = self.trainer.predictors['CoxPH']\n            result = permutation_importance(model, self.X_test,\n                                            Surv.from_dataframe('event', 'time', self.y_test),\n                                            n_repeats=15)\n\n            importance_df = pd.DataFrame(\n                {\n                    \"importance\": result[\"importances_mean\"],\n                    \"stddev\": result[\"importances_std\"],\n                },\n                index=self.X_test.columns,\n            ).sort_values(by=\"importance\", ascending=False)\n            model_name = 'CoxPH'\n        else:\n            importance_df = self.predictor.feature_importance(\n                pd.concat([self.X_test, self.y_test], axis=1))\n            model_name = self.predictor.model_best\n\n        plot_feature_importance(importance_df, self.output_dir / 'figures', model_name)\n        generate_explainer_report_pdf(self.trainer.task, self.output_dir)\n\n    def _run_bias_audit(self) -&gt; List[pd.DataFrame]:\n\n        self.sensitive_features = infer_sensitive_features(self.X_test) if self.sensitive_features is None else self.sensitive_features\n        bias_output_dir = self.output_dir / 'bias'\n        bias_output_dir.mkdir(parents=True, exist_ok=True)\n\n        metrics = ['mean_prediction'] if self.trainer.task == 'regression' else ['mean_prediction', 'false_positive_rate'] \n\n        bias = BiasExplainer(\n            self.y_test, \n            self.trainer.infer(self.X_test), \n            self.sensitive_features,\n            self.trainer.task, \n            bias_output_dir,\n            metrics\n        )\n        bias.run(relative=True)\n\n    @classmethod\n    def from_trainer(cls, trainer, **kwargs):\n        \"\"\"Create Explainer object from TrainerSupervised object.\"\"\"\n        return cls(trainer, trainer.X_train, trainer.X_test, trainer.y_test, trainer.output_dir, **kwargs)\n</code></pre>"},{"location":"api/explainer/#jarvais.explainer.Explainer.run","title":"<code>run()</code>","text":"<p>Generate diagnostic plots and reports for the trained model.</p> Source code in <code>src/jarvais/explainer/explainer.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Generate diagnostic plots and reports for the trained model.\"\"\"\n    if self.trainer.task != 'survival':\n        plot_violin_of_bootsrapped_metrics(\n            self.predictor,\n            self.X_test,\n            self.y_test,\n            self.trainer.X_val,\n            self.trainer.y_val,\n            self.X_train,\n            self.trainer.y_train,\n            output_dir=self.output_dir / 'figures'\n        )      \n\n        self._run_bias_audit()      \n\n    if self.trainer.task in ['binary', 'multiclass']:\n        plot_classification_diagnostics(\n            self.y_test,\n            self.predictor.predict_proba(self.X_test).iloc[:, 1],\n            self.trainer.y_val,\n            self.predictor.predict_proba(self.trainer.X_val).iloc[:, 1],\n            self.trainer.y_train,\n            self.predictor.predict_proba(self.X_train).iloc[:, 1],\n            output_dir=self.output_dir / 'figures'\n        )\n        plot_shap_values(\n            self.predictor,\n            self.X_train,\n            self.X_test,\n            output_dir=self.output_dir / 'figures'\n        )\n\n    elif self.trainer.task == 'regression':\n        plot_regression_diagnostics(\n            self.y_test,\n            self.predictor.predict(self.X_test, as_pandas=False),\n            output_dir=self.output_dir / 'figures'\n        )\n\n    # Plot feature importance\n    if self.trainer.task == 'survival': # NEEDS TO BE UPDATED\n        model = self.trainer.predictors['CoxPH']\n        result = permutation_importance(model, self.X_test,\n                                        Surv.from_dataframe('event', 'time', self.y_test),\n                                        n_repeats=15)\n\n        importance_df = pd.DataFrame(\n            {\n                \"importance\": result[\"importances_mean\"],\n                \"stddev\": result[\"importances_std\"],\n            },\n            index=self.X_test.columns,\n        ).sort_values(by=\"importance\", ascending=False)\n        model_name = 'CoxPH'\n    else:\n        importance_df = self.predictor.feature_importance(\n            pd.concat([self.X_test, self.y_test], axis=1))\n        model_name = self.predictor.model_best\n\n    plot_feature_importance(importance_df, self.output_dir / 'figures', model_name)\n    generate_explainer_report_pdf(self.trainer.task, self.output_dir)\n</code></pre>"},{"location":"api/explainer/#jarvais.explainer.Explainer.from_trainer","title":"<code>from_trainer(trainer, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create Explainer object from TrainerSupervised object.</p> Source code in <code>src/jarvais/explainer/explainer.py</code> <pre><code>@classmethod\ndef from_trainer(cls, trainer, **kwargs):\n    \"\"\"Create Explainer object from TrainerSupervised object.\"\"\"\n    return cls(trainer, trainer.X_train, trainer.X_test, trainer.y_test, trainer.output_dir, **kwargs)\n</code></pre>"},{"location":"api/explainer/#jarvais.explainer.BiasExplainer","title":"<code>jarvais.explainer.BiasExplainer</code>","text":"<p>A class for explaining and analyzing bias in a predictive model's outcomes based on sensitive features.</p> <p>This class performs various fairness audits by evaluating predictive outcomes with respect to sensitive features such as gender, age, race, and more. It first runs statistical analyses using the OLS regression F-statistic p-value to assess any possibility  of bias in the model's predictions based on sensitive features. If the p-value is less than 0.05, indicating potential bias,  the class generates visualizations (such as violin plots) and calculates fairness metrics (e.g., demographic parity, equalized odds).  The results are presented for each sensitive feature, with optional relative fairness comparisons.</p> <p>Attributes:</p> Name Type Description <code>y_true</code> <code>DataFrame</code> <p>The true target values for the model.</p> <code>y_pred</code> <code>DataFrame</code> <p>The predicted values from the model.</p> <code>sensitive_features</code> <code>dict or DataFrame</code> <p>A dictionary or DataFrame containing sensitive features used for fairness analysis.</p> <code>metrics</code> <code>list</code> <p>A list of metrics to calculate for fairness analysis. Defaults to ['mean_prediction', 'false_positive_rate', 'true_positive_rate'].</p> <code>mapper</code> <code>dict</code> <p>A dictionary mapping internal metric names to user-friendly descriptions.</p> <code>kwargs</code> <code>dict</code> <p>Additional parameters passed to various methods, such as metric calculation and plot generation.</p> Source code in <code>src/jarvais/explainer/bias.py</code> <pre><code>class BiasExplainer():\n    \"\"\"\n    A class for explaining and analyzing bias in a predictive model's outcomes based on sensitive features.\n\n    This class performs various fairness audits by evaluating predictive outcomes with respect to sensitive features such as\n    gender, age, race, and more. It first runs statistical analyses using the OLS regression F-statistic p-value to assess any possibility \n    of bias in the model's predictions based on sensitive features. If the p-value is less than 0.05, indicating potential bias, \n    the class generates visualizations (such as violin plots) and calculates fairness metrics (e.g., demographic parity, equalized odds). \n    The results are presented for each sensitive feature, with optional relative fairness comparisons.\n\n    Attributes:\n        y_true (pd.DataFrame):\n            The true target values for the model.\n        y_pred (pd.DataFrame):\n            The predicted values from the model.\n        sensitive_features (dict or pd.DataFrame):\n            A dictionary or DataFrame containing sensitive features used for fairness analysis.\n        metrics (list):\n            A list of metrics to calculate for fairness analysis. Defaults to ['mean_prediction', 'false_positive_rate', 'true_positive_rate'].\n        mapper (dict):\n            A dictionary mapping internal metric names to user-friendly descriptions.\n        kwargs (dict):\n            Additional parameters passed to various methods, such as metric calculation and plot generation.\n    \"\"\"\n    def __init__(\n            self, \n            y_true: pd.DataFrame, \n            y_pred: pd.DataFrame, \n            sensitive_features: dict, \n            task: str,\n            output_dir: Path,\n            metrics: list = ['mean_prediction', 'false_positive_rate', 'true_positive_rate'], \n            **kwargs: dict\n        ) -&gt; None:\n        self.y_true = y_true\n        self.y_pred = y_pred\n        self.task = task\n        self.output_dir = output_dir\n        self.mapper = {\"mean_prediction\": \"Demographic Parity\",\n                       \"false_positive_rate\": \"(FPR) Equalized Odds\",\n                       \"true_positive_rate\": \"(TPR) Equalized Odds or Equal Opportunity\"}\n        self.metrics = metrics\n        self.kwargs = kwargs\n\n        # Convert sensitive_features to DataFrame or leave as Series\n        if isinstance(sensitive_features, pd.DataFrame) or isinstance(sensitive_features, pd.Series):\n            self.sensitive_features = sensitive_features\n        elif isinstance(sensitive_features, dict):\n            self.sensitive_features = pd.DataFrame.from_dict(sensitive_features)\n        elif isinstance(sensitive_features, list):\n            if any(isinstance(item, list) for item in sensitive_features):\n                self.sensitive_features = pd.DataFrame(sensitive_features, columns=[f'sensitive_feature_{i}' for i in range(len(sensitive_features))])\n            else:\n                self.sensitive_features = pd.DataFrame(sensitive_features, columns=['sensitive_feature'])\n        else:\n            raise ValueError(\"sensitive_features must be a pandas DataFrame, Series, dictionary or list\")\n\n    def _generate_violin(self, sensitive_feature: str, bias_metric:np.ndarray) -&gt; None:\n        \"\"\"Generate a violin plot for the bias metric.\"\"\"\n        plt.figure(figsize=(8, 6)) \n        sns.set_theme(style=\"whitegrid\")  \n\n        sns.violinplot(\n            x=self.sensitive_features[sensitive_feature], \n            y=bias_metric, \n            palette=\"muted\",  \n            inner=\"quart\", \n            linewidth=1.25 \n        )\n\n        bias_metric_name = 'log_loss' if self.task == 'binary' else 'root_mean_squared_error'\n\n        plt.title(f'{bias_metric_name.title()} Distribution by {sensitive_feature}', fontsize=16, weight='bold')  \n        plt.xlabel(f'{sensitive_feature}', fontsize=14)  \n        plt.ylabel(f'{bias_metric_name.title()} per Patient', fontsize=14) \n        plt.xticks(rotation=45, ha='right')\n\n        plt.tight_layout()  \n        plt.savefig(self.output_dir / f'{sensitive_feature}_{bias_metric_name}.png') \n        plt.show()\n\n    def _fit_OLS(self, sensitive_feature: str, bias_metric:np.ndarray) -&gt; float:\n        \"\"\"Fit a statsmodels OLS model to the bias metric data.\"\"\"\n        one_hot_encoded = pd.get_dummies(self.sensitive_features[sensitive_feature], prefix=sensitive_feature)\n\n        X = one_hot_encoded.values  \n        y = bias_metric  \n\n        X_columns = one_hot_encoded.columns  \n        X = sm.add_constant(X.astype(float), has_constant='add')\n\n        model = sm.OLS(y, X).fit()\n\n        if model.f_pvalue &lt; 0.05:\n            summary = model.summary(xname=['const'] + X_columns.tolist())\n            print(f'Possible Bias in {sensitive_feature.title()}:\\n')\n            print(summary)\n\n            with (self.output_dir / f'{sensitive_feature}_model_summary.txt').open('w') as f:\n                f.write(summary.as_text())\n\n        return model.f_pvalue\n\n    def _calculate_fair_metrics(\n            self, \n            sensitive_feature: str, \n            fairness_threshold: float, \n            relative: bool\n        ) -&gt; pd.DataFrame:\n        \"\"\"Calculate the Fairlearn metrics and return the results in a DataFrame.\"\"\"\n        _metrics = {metric: get_metric(metric, sensitive_features=self.sensitive_features[sensitive_feature]) for metric in self.metrics}\n        metric_frame = fm.MetricFrame(\n            metrics=_metrics, \n            y_true=self.y_true, \n            y_pred=self.y_pred, \n            sensitive_features=self.sensitive_features[sensitive_feature], \n            **self.kwargs\n        )\n        result = pd.DataFrame(metric_frame.by_group.T, index=_metrics.keys())\n        result = result.rename(columns=self.mapper)\n\n        if relative:\n            largest_feature = self.sensitive_features[sensitive_feature].mode().iloc[0]\n            results_relative = result.T / result[largest_feature]\n            results_relative = results_relative.applymap(\n                lambda x: f\"{x:.3f} \u2705\" if x &lt;= fairness_threshold or 1/x &lt;= fairness_threshold \n                else f\"{x:.3f} \u274c\")\n            result = pd.concat([result, results_relative.T.rename(index=lambda x: f\"Relative {x}\")])\n\n        return result\n\n    def run(\n            self, \n            relative: bool = False, \n            fairness_threshold: float = 1.2\n        ) -&gt; None:\n        \"\"\"\n        Runs the bias explainer analysis on the provided data. It first evaluates the potential bias in the model's predictions\n        using the OLS regression F-statistic p-value. If the p-value is below the threshold of 0.05, indicating \n        potential bias in the sensitive feature, the method proceeds to generate visualizations and calculate fairness metrics.\n\n        Args:\n            relative (bool): \n                If True, the metrics will be presented relative to the most frequent value of each sensitive feature.\n            fairness_threshold (float): \n                A threshold for determining fairness based on relative metrics. If the relative metric exceeds this threshold, \n                a warning flag will be applied.\n        \"\"\"\n        if self.task == 'binary':\n            log_loss_per_patient = self.y_true.index.map(\n                lambda idx: log_loss([self.y_true[idx]], [self.y_pred[idx]], labels=self.y_true.unique())\n            )\n            bias_metric = np.array(log_loss_per_patient)\n            self.y_pred = (self.y_pred &gt;= .5).astype(int)\n        else: # Regression(root mean_squared_error)\n            bias_metric = np.sqrt((self.y_true.to_numpy() - self.y_pred.to_numpy()) ** 2)\n\n        self.results = []\n        for sensitive_feature in self.sensitive_features.columns:\n            f_pvalue = self._fit_OLS(sensitive_feature, bias_metric)\n            if f_pvalue &lt; 0.05:\n                self._generate_violin(sensitive_feature, bias_metric)\n                result = self._calculate_fair_metrics(sensitive_feature, fairness_threshold, relative)\n\n                print(f\"Subgroup Analysis({sensitive_feature.title()})\")\n                print(f\"{tabulate(result.iloc[:, :4], headers='keys', tablefmt='fancy_grid')}\\n\")\n                result.to_csv(self.output_dir / f'{sensitive_feature}_fm_metrics.csv')\n</code></pre>"},{"location":"api/explainer/#jarvais.explainer.BiasExplainer.run","title":"<code>run(relative=False, fairness_threshold=1.2)</code>","text":"<p>Runs the bias explainer analysis on the provided data. It first evaluates the potential bias in the model's predictions using the OLS regression F-statistic p-value. If the p-value is below the threshold of 0.05, indicating  potential bias in the sensitive feature, the method proceeds to generate visualizations and calculate fairness metrics.</p> <p>Parameters:</p> Name Type Description Default <code>relative</code> <code>bool</code> <p>If True, the metrics will be presented relative to the most frequent value of each sensitive feature.</p> <code>False</code> <code>fairness_threshold</code> <code>float</code> <p>A threshold for determining fairness based on relative metrics. If the relative metric exceeds this threshold,  a warning flag will be applied.</p> <code>1.2</code> Source code in <code>src/jarvais/explainer/bias.py</code> <pre><code>def run(\n        self, \n        relative: bool = False, \n        fairness_threshold: float = 1.2\n    ) -&gt; None:\n    \"\"\"\n    Runs the bias explainer analysis on the provided data. It first evaluates the potential bias in the model's predictions\n    using the OLS regression F-statistic p-value. If the p-value is below the threshold of 0.05, indicating \n    potential bias in the sensitive feature, the method proceeds to generate visualizations and calculate fairness metrics.\n\n    Args:\n        relative (bool): \n            If True, the metrics will be presented relative to the most frequent value of each sensitive feature.\n        fairness_threshold (float): \n            A threshold for determining fairness based on relative metrics. If the relative metric exceeds this threshold, \n            a warning flag will be applied.\n    \"\"\"\n    if self.task == 'binary':\n        log_loss_per_patient = self.y_true.index.map(\n            lambda idx: log_loss([self.y_true[idx]], [self.y_pred[idx]], labels=self.y_true.unique())\n        )\n        bias_metric = np.array(log_loss_per_patient)\n        self.y_pred = (self.y_pred &gt;= .5).astype(int)\n    else: # Regression(root mean_squared_error)\n        bias_metric = np.sqrt((self.y_true.to_numpy() - self.y_pred.to_numpy()) ** 2)\n\n    self.results = []\n    for sensitive_feature in self.sensitive_features.columns:\n        f_pvalue = self._fit_OLS(sensitive_feature, bias_metric)\n        if f_pvalue &lt; 0.05:\n            self._generate_violin(sensitive_feature, bias_metric)\n            result = self._calculate_fair_metrics(sensitive_feature, fairness_threshold, relative)\n\n            print(f\"Subgroup Analysis({sensitive_feature.title()})\")\n            print(f\"{tabulate(result.iloc[:, :4], headers='keys', tablefmt='fancy_grid')}\\n\")\n            result.to_csv(self.output_dir / f'{sensitive_feature}_fm_metrics.csv')\n</code></pre>"},{"location":"api/functional/","title":"Functional","text":""},{"location":"api/functional/#functional","title":"Functional","text":""},{"location":"api/functional/#jarvais.utils.functional","title":"<code>jarvais.utils.functional</code>","text":""},{"location":"api/functional/#jarvais.utils.functional.auprc","title":"<code>auprc(y_true, y_scores)</code>","text":"<p>Calculate the Area Under the Precision-Recall Curve (AUPRC).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>True binary labels. Shape (n_samples,).</p> required <code>y_scores</code> <code>ndarray</code> <p>Predicted scores or probabilities. Shape (n_samples,).</p> required <p>Returns:</p> Name Type Description <code>auprc_score</code> <code>float</code> <p>The AUPRC value.</p> Source code in <code>src/jarvais/utils/functional.py</code> <pre><code>def auprc(y_true: np.ndarray, y_scores: np.ndarray) -&gt; float:\n    \"\"\"\n    Calculate the Area Under the Precision-Recall Curve (AUPRC).\n\n    Args:\n        y_true (np.ndarray): True binary labels. Shape (n_samples,).\n        y_scores (np.ndarray): Predicted scores or probabilities. Shape (n_samples,).\n\n    Returns:\n        auprc_score (float): The AUPRC value.\n    \"\"\"\n    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n    return auc(recall, precision)\n</code></pre>"},{"location":"api/functional/#jarvais.utils.functional.bootstrap_metric","title":"<code>bootstrap_metric(y_test, y_pred, f, nsamples=100)</code>","text":"<p>Compute a metric using bootstrapping to estimate its variability.</p> <p>Parameters:</p> Name Type Description Default <code>y_test</code> <code>ndarray</code> <p>True labels. Shape (n_samples,).</p> required <code>y_pred</code> <code>ndarray</code> <p>Predicted values. Shape (n_samples,).</p> required <code>f</code> <code>Callable[[ndarray, ndarray], float]</code> <p>A function that calculates the metric.</p> required <code>nsamples</code> <code>int</code> <p>The number of bootstrap samples. Defaults to 100.</p> <code>100</code> <p>Returns:</p> Name Type Description <code>bootstrapped_values</code> <code>List[float]</code> <p>A list of metric values computed on each bootstrap sample.</p> Source code in <code>src/jarvais/utils/functional.py</code> <pre><code>def bootstrap_metric(\n        y_test: np.ndarray,\n        y_pred: np.ndarray,\n        f: Callable[[np.ndarray, np.ndarray], float],\n        nsamples: int=100\n    ) -&gt; List[float]:\n    \"\"\"\n    Compute a metric using bootstrapping to estimate its variability.\n\n    Args:\n        y_test (np.ndarray): True labels. Shape (n_samples,).\n        y_pred (np.ndarray): Predicted values. Shape (n_samples,).\n        f (Callable[[np.ndarray, np.ndarray], float]): A function that calculates the metric.\n        nsamples (int, optional): The number of bootstrap samples. Defaults to 100.\n\n    Returns:\n        bootstrapped_values (List[float]): A list of metric values computed on each bootstrap sample.\n    \"\"\"\n    np.random.seed(0)\n    values = []\n\n    for _ in range(nsamples):\n        idx = np.random.randint(len(y_test), size=len(y_test))\n        pred_sample = y_pred[idx]\n        y_test_sample = y_test[idx]\n        val = f(y_test_sample.ravel(), pred_sample.ravel())\n        values.append(val)\n    return values\n</code></pre>"},{"location":"api/pdf/","title":"PDF","text":""},{"location":"api/pdf/#pdf","title":"PDF","text":""},{"location":"api/pdf/#jarvais.utils.pdf","title":"<code>jarvais.utils.pdf</code>","text":""},{"location":"api/pdf/#jarvais.utils.pdf.generate_analysis_report_pdf","title":"<code>generate_analysis_report_pdf(outlier_analysis, multiplots, categorical_columns, output_dir)</code>","text":"<p>Generate a PDF report for the analysis, including plots, tables, and outlier analysis.</p> <p>Parameters:</p> Name Type Description Default <code>outlier_analysis</code> <code>str</code> <p>Text summary of outlier analysis to include in the report.</p> required <code>multiplots</code> <code>list</code> <p>A list of paths to plots to include in the multiplots section.</p> required <code>categorical_columns</code> <code>list</code> <p>A list of categorical columns to use for multiplots.</p> required <code>output_dir</code> <code>str | Path</code> <p>The directory where the generated PDF report will be saved.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>The function saves the generated PDF to the specified output directory.</p> Source code in <code>src/jarvais/utils/pdf.py</code> <pre><code>def generate_analysis_report_pdf(\n        outlier_analysis: str,\n        multiplots: list,\n        categorical_columns: list,\n        output_dir: str | Path\n    ) -&gt; None:\n    \"\"\"\n    Generate a PDF report for the analysis, including plots, tables, and outlier analysis.\n\n    Args:\n        outlier_analysis (str): Text summary of outlier analysis to include in the report.\n        multiplots (list): A list of paths to plots to include in the multiplots section.\n        categorical_columns (list): A list of categorical columns to use for multiplots.\n        output_dir (str | Path): The directory where the generated PDF report will be saved.\n\n    Returns:\n        None: The function saves the generated PDF to the specified output directory.\n    \"\"\"\n    output_dir = Path(output_dir)\n    figures_dir = output_dir / 'figures'\n\n    # Instantiate PDF\n    pdf = FPDF()\n    pdf.add_page()\n    script_dir = Path(__file__).resolve().parent\n\n    # Adding unicode fonts\n    font_path = (script_dir / 'fonts/Inter_28pt-Regular.ttf')\n    pdf.add_font(\"inter\", style=\"\", fname=font_path)\n    font_path = (script_dir / 'fonts/Inter_28pt-Bold.ttf')\n    pdf.add_font(\"inter\", style=\"b\", fname=font_path)\n    pdf.set_font('inter', '', 24)\n\n    # Title\n    pdf.write(5, \"Analysis Report\\n\\n\")\n\n    # Add outlier analysis\n    if outlier_analysis != '':\n        pdf.set_font('inter', '', 12)\n        pdf.write(5, \"Outlier Analysis:\\n\")\n        pdf.set_font('inter', '', 10)\n        pdf.write(5, outlier_analysis)\n\n    # Add page-wide pairplots\n    pdf.image((figures_dir / 'pairplot.png'), Align.C, w=pdf.epw-20)\n    pdf.add_page()\n\n    # Add correlation plots\n    pdf.image((figures_dir / 'pearson_correlation.png'), Align.C, h=pdf.eph/2)\n    pdf.image((figures_dir / 'spearman_correlation.png'), Align.C, h=pdf.eph/2)\n\n    # Add multiplots\n    if multiplots and categorical_columns:\n        pdf = _add_multiplots(pdf, multiplots, categorical_columns)\n\n    # Add demographic breakdown \"table one\"\n    path_tableone = output_dir / 'tableone.csv'\n    if path_tableone.exists():\n        csv_df = pd.read_csv(path_tableone, na_filter=False).astype(str)\n        pdf = _add_table(pdf, csv_df)\n\n    # Save PDF\n    pdf.output(output_dir / 'analysis_report.pdf')\n</code></pre>"},{"location":"api/pdf/#jarvais.utils.pdf.generate_explainer_report_pdf","title":"<code>generate_explainer_report_pdf(problem_type, output_dir)</code>","text":"<p>Generate a PDF report for the explainer with visualizations and metrics.</p> <p>This function creates a PDF report that includes plots and metrics  relevant to the specified problem type. The report is saved in the  specified output directory.</p> <p>Parameters:</p> Name Type Description Default <code>problem_type</code> <code>str</code> <p>The type of machine learning problem.  Supported values are 'binary', 'multiclass', 'regression',  and 'survival'.</p> required <code>output_dir</code> <code>str | Path</code> <p>The directory where the generated PDF  report will be saved.</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>The function saves the generated PDF to the specified output directory.</p> Source code in <code>src/jarvais/utils/pdf.py</code> <pre><code>def generate_explainer_report_pdf(\n        problem_type: str,\n        output_dir: str | Path\n    ) -&gt; None:\n    \"\"\"\n    Generate a PDF report for the explainer with visualizations and metrics.\n\n    This function creates a PDF report that includes plots and metrics \n    relevant to the specified problem type. The report is saved in the \n    specified output directory.\n\n    Args:\n        problem_type (str): The type of machine learning problem. \n            Supported values are 'binary', 'multiclass', 'regression', \n            and 'survival'.\n        output_dir (str | Path): The directory where the generated PDF \n            report will be saved.\n\n    Returns:\n        None: The function saves the generated PDF to the specified output directory.\n    \"\"\"\n    output_dir = Path(output_dir)\n    figures_dir = output_dir / 'figures'\n\n    # Instantiate PDF\n    pdf = FPDF()\n    pdf.add_page()\n    script_dir = Path(__file__).resolve().parent\n\n    # Adding unicode fonts\n    font_path = (script_dir / 'fonts/Inter_28pt-Regular.ttf')\n    pdf.add_font(\"inter\", style=\"\", fname=font_path)\n    font_path = (script_dir / 'fonts/Inter_28pt-Bold.ttf')\n    pdf.add_font(\"inter\", style=\"b\", fname=font_path)\n    pdf.set_font('inter', '', 24)\n\n    # Title\n    pdf.write(5, \"Explainer Report\\n\\n\")\n\n    if problem_type != 'survival':\n        pdf.image((figures_dir / 'test_metrics_bootstrap.png'), Align.C, h=pdf.eph//3.5, w=pdf.epw-20)\n        pdf.image((figures_dir / 'validation_metrics_bootstrap.png'), Align.C, h=pdf.eph//3.5, w=pdf.epw-20)\n        pdf.image((figures_dir /  'train_metrics_bootstrap.png'), Align.C, h=pdf.eph//3.5, w=pdf.epw-20)\n        pdf.add_page()\n\n    pdf.image((figures_dir / 'feature_importance.png'), Align.C, w=pdf.epw-20)\n    pdf.add_page()\n\n    if problem_type in ['binary', 'multiclass']:\n        pdf.image((figures_dir / 'model_evaluation.png'), Align.C, w=pdf.epw-20)\n        pdf.image((figures_dir / 'confusion_matrix.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n        pdf.add_page()\n\n        pdf.image((figures_dir / 'shap_barplot.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n        pdf.image((output_dir /  'figures' / 'shap_heatmap.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n    elif problem_type == 'regression':\n        pdf.image((figures_dir / 'residual_plot.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n        pdf.image((output_dir /  'figures' / 'true_vs_predicted.png'), Align.C, h=pdf.eph/2, w=pdf.epw-20)\n\n    # Save PDF\n    pdf.output((output_dir / 'explainer_report.pdf'))\n</code></pre>"},{"location":"api/plot/","title":"Plotting","text":""},{"location":"api/plot/#plot","title":"Plot","text":""},{"location":"api/plot/#jarvais.utils.plot","title":"<code>jarvais.utils.plot</code>","text":""},{"location":"api/plot/#jarvais.utils.plot.plot_corr","title":"<code>plot_corr(corr, size, output_dir, file_name='correlation_matrix.png')</code>","text":"<p>Plots a lower-triangle heatmap of the correlation matrix and saves it as an image file.</p> <p>Parameters:</p> Name Type Description Default <code>corr</code> <code>DataFrame</code> <p>Correlation matrix to visualize.</p> required <code>size</code> <code>float</code> <p>Size of the heatmap figure.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the output image.</p> required <code>file_name</code> <code>str</code> <p>Name of the saved image file. Defaults to 'correlation_matrix.png'.</p> <code>'correlation_matrix.png'</code> Example <pre><code>import pandas as pd\nfrom pathlib import Path\n\n# Sample data\ndf = pd.DataFrame({\n    'A': [1, 2, 3, 4, 5],\n    'B': [5, 4, 3, 2, 1],\n    'C': [2, 3, 4, 5, 6]\n})\n\n# Compute Spearman correlation\ncorr_matrix = df.corr(method='spearman')\n\n# Plot and save the heatmap\nplot_corr(corr=corr_matrix, size=6, output_dir=Path('./output'))\n</code></pre> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_corr(\n        corr: pd.DataFrame,\n        size: float,\n        output_dir: Path,\n        file_name: str = 'correlation_matrix.png'\n    ) -&gt; None:\n    \"\"\"\n    Plots a lower-triangle heatmap of the correlation matrix and saves it as an image file.\n\n    Args:\n        corr (pd.DataFrame): Correlation matrix to visualize.\n        size (float): Size of the heatmap figure.\n        output_dir (Path): Directory to save the output image.\n        file_name (str): Name of the saved image file. Defaults to 'correlation_matrix.png'.\n\n    Example:\n        ```python\n        import pandas as pd\n        from pathlib import Path\n\n        # Sample data\n        df = pd.DataFrame({\n            'A': [1, 2, 3, 4, 5],\n            'B': [5, 4, 3, 2, 1],\n            'C': [2, 3, 4, 5, 6]\n        })\n\n        # Compute Spearman correlation\n        corr_matrix = df.corr(method='spearman')\n\n        # Plot and save the heatmap\n        plot_corr(corr=corr_matrix, size=6, output_dir=Path('./output'))\n        ```\n    \"\"\"\n    fig, ax = plt.subplots(1, 1, figsize=(size, size))\n    mask = np.triu(np.ones_like(corr, dtype=bool)) # Keep only lower triangle\n    np.fill_diagonal(mask, False)\n    sns.heatmap(corr, mask=mask, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidth=.5, fmt=\"1.2f\", ax=ax)\n    plt.title('Correlation Matrix')\n    plt.tight_layout()\n\n    figure_path = output_dir / file_name\n    fig.savefig(figure_path)\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_frequency_table","title":"<code>plot_frequency_table(data, columns, output_dir)</code>","text":"<p>Generates and saves heatmap visualizations for frequency tables of all column pair combinations.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input dataset containing the columns to analyze.</p> required <code>columns</code> <code>list</code> <p>List of column names to create frequency tables for.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the generated heatmaps.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_frequency_table(\n        data: pd.DataFrame,\n        columns: list,\n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Generates and saves heatmap visualizations for frequency tables of all column pair combinations.\n\n    Args:\n        data (pd.DataFrame): Input dataset containing the columns to analyze.\n        columns (list): List of column names to create frequency tables for.\n        output_dir (Path): Directory to save the generated heatmaps.\n    \"\"\"\n    frequency_dir = Path(output_dir) / 'frequency_tables'\n    frequency_dir.mkdir(parents=True, exist_ok=True)\n\n    for column_1, column_2 in combinations(columns, 2):\n        heatmap_data = pd.crosstab(data[column_1], data[column_2])\n        plt.figure(figsize=(8, 6))\n        sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt='d', linewidth=.5)\n        plt.title(f'Frequency Table for {column_1} and {column_2}')\n        plt.xlabel(column_2)\n        plt.ylabel(column_1)\n        plt.savefig(frequency_dir / f'{column_1}_vs_{column_2}.png')\n        plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_pairplot","title":"<code>plot_pairplot(data, continuous_columns, output_dir, target_variable=None, n_keep=10)</code>","text":"<p>Generates a pair plot of the specified continuous columns in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The input DataFrame containing the data to be visualized.</p> required <code>continuous_columns</code> <code>list</code> <p>A list of column names corresponding to continuous variables.</p> required <code>output_dir</code> <code>Path</code> <p>Directory where the resulting plot will be saved.</p> required <code>target_variable</code> <code>str</code> <p>The target variable to use as a hue for coloring the pair plot. Defaults to None.</p> <code>None</code> <code>n_keep</code> <code>int</code> <p>The maximum number of continuous columns to include in the plot.  If exceeded, the most correlated columns are selected. Defaults to 10.</p> <code>10</code> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_pairplot(\n        data: pd.DataFrame,\n        continuous_columns: list,\n        output_dir: Path,\n        target_variable: str = None,\n        n_keep: int = 10\n    ) -&gt; None:\n    \"\"\"\n    Generates a pair plot of the specified continuous columns in the dataset.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame containing the data to be visualized.\n        continuous_columns (list): A list of column names corresponding to continuous variables.\n        output_dir (Path): Directory where the resulting plot will be saved.\n        target_variable (str, optional): The target variable to use as a hue for coloring the pair plot. Defaults to None.\n        n_keep (int, optional): The maximum number of continuous columns to include in the plot. \n            If exceeded, the most correlated columns are selected. Defaults to 10.\n    \"\"\"\n    if len(continuous_columns) &gt; n_keep:\n        spearman_corr = data[continuous_columns].corr(method=\"spearman\") \n        corr_pairs = spearman_corr.abs().unstack().sort_values(\n            kind=\"quicksort\",\n            ascending=False\n        ).drop_duplicates()\n        top_10_pairs = corr_pairs[corr_pairs &lt; 1].nlargest(5)\n        columns_to_plot = list({index for pair in top_10_pairs.index for index in pair})\n    else:\n        columns_to_plot = continuous_columns\n\n    hue = target_variable\n    if target_variable is not None:\n        columns_to_plot += [target_variable]\n\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    g = sns.pairplot(data[columns_to_plot], hue=hue)\n    g.figure.suptitle(\"Pair Plot\", y=1.08)\n\n    figure_path = output_dir / 'pairplot.png'\n    plt.savefig(figure_path)\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_umap","title":"<code>plot_umap(data, continuous_columns, output_dir)</code>","text":"<p>Generates a 2D UMAP projection of the specified continuous columns and saves the resulting scatter plot.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The input DataFrame containing the data to be visualized.</p> required <code>continuous_columns</code> <code>list</code> <p>A list of column names corresponding to continuous variables  to be included in the UMAP projection.</p> required <code>output_dir</code> <code>Path</code> <p>Directory where the resulting plot will be saved.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A 2D NumPy array of the UMAP-transformed data.</p> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_umap(\n        data: pd.DataFrame,\n        continuous_columns: list,\n        output_dir: Path\n    ) -&gt; np.ndarray:\n    \"\"\"\n    Generates a 2D UMAP projection of the specified continuous columns and saves the resulting scatter plot.\n\n    Args:\n        data (pd.DataFrame): The input DataFrame containing the data to be visualized.\n        continuous_columns (list): A list of column names corresponding to continuous variables \n            to be included in the UMAP projection.\n        output_dir (Path): Directory where the resulting plot will be saved.\n\n    Returns:\n        np.ndarray: A 2D NumPy array of the UMAP-transformed data.\n    \"\"\"\n    umap_data = UMAP(n_components=2).fit_transform(data[continuous_columns])\n\n    fig, ax = plt.subplots(figsize=(8, 8), dpi=72)\n    sns.scatterplot(x=umap_data[:,0], y=umap_data[:,1], alpha=.7, ax=ax)\n    plt.title('UMAP of Continuous Variables')\n\n    figure_path = output_dir / 'umap_continuous_data.png'\n    fig.savefig(figure_path)\n    plt.close()\n\n    return umap_data\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_kaplan_meier_by_category","title":"<code>plot_kaplan_meier_by_category(data_x, data_y, categorical_columns, output_dir)</code>","text":"<p>Plots Kaplan-Meier survival curves for each category in the specified categorical columns.</p> <p>Parameters:</p> Name Type Description Default <code>data_x</code> <code>DataFrame</code> <p>Dataset containing the categorical columns to group by.</p> required <code>data_y</code> <code>DataFrame</code> <p>Dataset containing 'time' and 'event' columns for survival analysis.</p> required <code>categorical_columns</code> <code>list</code> <p>List of categorical column names to generate survival curves for.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the Kaplan-Meier survival curve plots.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_kaplan_meier_by_category(\n        data_x: pd.DataFrame,\n        data_y: pd.DataFrame,\n        categorical_columns: list,\n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Plots Kaplan-Meier survival curves for each category in the specified categorical columns.\n\n    Args:\n        data_x (pd.DataFrame): Dataset containing the categorical columns to group by.\n        data_y (pd.DataFrame): Dataset containing 'time' and 'event' columns for survival analysis.\n        categorical_columns (list): List of categorical column names to generate survival curves for.\n        output_dir (Path): Directory to save the Kaplan-Meier survival curve plots.\n    \"\"\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    for cat_col in categorical_columns:\n        plt.figure(figsize=(10, 6))\n        plt.title(f\"Kaplan-Meier Survival Curve by {cat_col}\")\n\n        unique_categories = data_x[cat_col].unique()\n\n        # Plot survival curves for each category\n        for category in unique_categories:\n            mask_category = data_x[cat_col] == category\n            try: # To catch when there are not enough samples for category\n                time_category, survival_prob_category, conf_int = kaplan_meier_estimator(\n                    data_y[\"event\"][mask_category].astype(bool),\n                    data_y[\"time\"][mask_category],\n                    conf_type=\"log-log\",\n                )\n\n                plt.step(\n                    time_category,\n                    survival_prob_category,\n                    where=\"post\",\n                    label=f\"{cat_col} = {category}\"\n                )\n                plt.fill_between(\n                    time_category,\n                    conf_int[0],\n                    conf_int[1],\n                    alpha=0.25,\n                    step=\"post\"\n                )\n            except Exception as _:\n                pass\n\n        results_multivariate = multivariate_logrank_test(\n            data_y['time'], \n            data_x[cat_col], \n            data_y['event']\n        )\n        multivariate_p_value = results_multivariate.p_value\n\n        plt.text(0.6, 0.1, f\"Multivariate log-rank p-value: {multivariate_p_value:.4e}\",\n                 fontsize=10, transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.8))\n        plt.ylim(0, 1)\n        plt.ylabel(r\"Estimated Probability of Survival $\\hat{S}(t)$\")\n        plt.xlabel(\"Time $t$\")\n        plt.legend(loc=\"best\")\n        plt.grid(alpha=0.3)\n        plt.savefig(output_dir / f'kaplan_meier_{cat_col}.png')\n        plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_feature_importance","title":"<code>plot_feature_importance(df, output_dir, model_name='')</code>","text":"<p>Plots feature importance with standard deviation and p-value significance.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing the feature importance data.  Look at example for required format.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the feature importance plot.</p> required <code>model_name</code> <code>str</code> <p>Optional name of the model, included in the plot title.</p> <code>''</code> Example <pre><code>import pandas as pd\nfrom pathlib import Path\n\ndf = pd.DataFrame({\n    'importance': [0.25, 0.18, 0.12, 0.10],\n    'stddev': [0.03, 0.02, 0.01, 0.015],\n    'p_value': [0.03, 0.07, 0.01, 0.2]\n}, index=['Feature A', 'Feature B', 'Feature C', 'Feature D'])\n\nplot_feature_importance(df, Path('./output'))\n</code></pre> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_feature_importance(df: pd.DataFrame, output_dir: Path, model_name: str=''):\n    \"\"\"\n    Plots feature importance with standard deviation and p-value significance.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing the feature importance data. \n            Look at example for required format.\n        output_dir (Path): Directory to save the feature importance plot.\n        model_name (str): Optional name of the model, included in the plot title.\n\n    Example:\n        ```python\n        import pandas as pd\n        from pathlib import Path\n\n        df = pd.DataFrame({\n            'importance': [0.25, 0.18, 0.12, 0.10],\n            'stddev': [0.03, 0.02, 0.01, 0.015],\n            'p_value': [0.03, 0.07, 0.01, 0.2]\n        }, index=['Feature A', 'Feature B', 'Feature C', 'Feature D'])\n\n        plot_feature_importance(df, Path('./output'))\n        ```\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(20, 12), dpi=72)\n\n    bars = ax.bar(df.index, df['importance'], yerr=df['stddev'], capsize=5, color='skyblue', edgecolor='black')\n\n    if 'p_value' in df.columns:\n        for bar, p_value in zip(bars, df['p_value']):\n            height = bar.get_height()\n            significance = '*' if p_value &lt; 0.05 else ''\n            ax.text(bar.get_x() + bar.get_width() / 2.0, height + 0.002, significance,\n                    ha='center', va='bottom', fontsize=10, color='red')\n\n    ax.set_xlabel('Feature', fontsize=14)\n    ax.set_ylabel('Importance', fontsize=14)\n    ax.set_title(f'Feature Importance with Standard Deviation and p-value Significance ({model_name})', fontsize=16)\n    ax.axhline(0, color='grey', linewidth=0.8)\n\n    ax.set_xticks(np.arange(len(df.index.values)))\n    ax.set_xticklabels(df.index.values, rotation=60, ha='right', fontsize=10)\n\n    ax.grid(axis='y', linestyle='--', alpha=0.7)\n\n    significance_patch = plt.Line2D([0], [0], color='red', marker='*', linestyle='None', markersize=10, label='p &lt; 0.05')\n    ax.legend(handles=[significance_patch], loc='upper right', fontsize=12)\n\n    plt.tight_layout()\n    fig.savefig(output_dir / 'feature_importance.png')\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_shap_values","title":"<code>plot_shap_values(predictor, X_train, X_test, output_dir, max_display=10)</code>","text":"<p>Generates and saves SHAP value visualizations, including a heatmap and a bar plot, for a autogluon tabular model.</p> <p>Parameters:</p> Name Type Description Default <code>predictor</code> <code>TabularPredictor</code> <p>The trained tabular predictor model for which SHAP values are calculated.</p> required <code>X_train</code> <code>DataFrame</code> <p>Training dataset used to create the SHAP background data.</p> required <code>X_test</code> <code>DataFrame</code> <p>Test dataset used to evaluate and compute SHAP values.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the SHAP value visualizations.</p> required <code>max_display</code> <code>int</code> <p>Maximum number of features to display in the visualizations. Defaults to 10.</p> <code>10</code> Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_shap_values(\n        predictor: TabularPredictor,\n        X_train: pd.DataFrame,\n        X_test: pd.DataFrame,\n        output_dir: Path,\n        max_display: int = 10,\n    ) -&gt; None:\n    \"\"\"\n    Generates and saves SHAP value visualizations, including a heatmap and a bar plot, for a autogluon tabular model.\n\n    Args:\n        predictor (TabularPredictor): The trained tabular predictor model for which SHAP values are calculated.\n        X_train (pd.DataFrame): Training dataset used to create the SHAP background data.\n        X_test (pd.DataFrame): Test dataset used to evaluate and compute SHAP values.\n        output_dir (Path): Directory to save the SHAP value visualizations.\n        max_display (int): Maximum number of features to display in the visualizations. Defaults to 10.\n    \"\"\"\n    predictor = ModelWrapper(predictor, X_train.columns)\n    background_data = shap.sample(X_train, 100)\n    shap_exp = shap.KernelExplainer(predictor.predict_proba, background_data)\n\n    # sample 100 samples from test set to evaluate with shap values\n    test_data = shap.sample(X_test, 100)\n\n    # Compute SHAP values for the test set\n    shap_values = shap_exp(test_data)\n\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    fig, ax = plt.subplots(figsize=(20, 12), dpi=72)\n    shap.plots.heatmap(shap_values[...,1], max_display=max_display, show=False, ax=ax)\n    fig.savefig(output_dir / 'shap_heatmap.png')\n    plt.close()\n\n    fig, ax = plt.subplots(figsize=(20, 12), dpi=72)\n    shap.plots.bar(shap_values[...,1], max_display=max_display, show=False, ax=ax)\n    fig.savefig(output_dir / 'shap_barplot.png')\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_violin_of_bootsrapped_metrics","title":"<code>plot_violin_of_bootsrapped_metrics(predictor, X_test, y_test, X_val, y_val, X_train, y_train, output_dir)</code>","text":"<p>Generates violin plots for bootstrapped model performance metrics across train, validation, and test datasets.</p> <p>Parameters:</p> Name Type Description Default <code>predictor</code> <code>TabularPredictor</code> <p>The trained model predictor for evaluating performance metrics.</p> required <code>X_test</code> <code>DataFrame</code> <p>Test features dataset.</p> required <code>y_test</code> <code>DataFrame</code> <p>Test target values.</p> required <code>X_val</code> <code>DataFrame</code> <p>Validation features dataset.</p> required <code>y_val</code> <code>DataFrame</code> <p>Validation target values.</p> required <code>X_train</code> <code>DataFrame</code> <p>Training features dataset.</p> required <code>y_train</code> <code>DataFrame</code> <p>Training target values.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the generated violin plots.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_violin_of_bootsrapped_metrics(\n        predictor: TabularPredictor,\n        X_test: pd.DataFrame,\n        y_test: pd.DataFrame,\n        X_val: pd.DataFrame,\n        y_val: pd.DataFrame,\n        X_train: pd.DataFrame,\n        y_train: pd.DataFrame,\n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Generates violin plots for bootstrapped model performance metrics across train, validation, and test datasets.\n\n    Args:\n        predictor (TabularPredictor): The trained model predictor for evaluating performance metrics.\n        X_test (pd.DataFrame): Test features dataset.\n        y_test (pd.DataFrame): Test target values.\n        X_val (pd.DataFrame): Validation features dataset.\n        y_val (pd.DataFrame): Validation target values.\n        X_train (pd.DataFrame): Training features dataset.\n        y_train (pd.DataFrame): Training target values.\n        output_dir (Path): Directory to save the generated violin plots.\n    \"\"\"\n    # Define metrics based on the problem type\n    if predictor.problem_type == 'regression':\n        metrics = [('R Squared', r2_score), ('Root Mean Squared Error', root_mean_squared_error)]\n    else:\n        metrics = [('AUROC', roc_auc_score), ('AUPRC', auprc)]\n\n    # Prepare lists for DataFrame\n    results = []\n\n    # Loop through models and metrics to compute bootstrapped values\n    for model_name in predictor.model_names():\n        if predictor.problem_type == 'regression':\n            y_pred_test = predictor.predict(X_test, model=model_name)\n            y_pred_val = predictor.predict(X_val, model=model_name)\n            y_pred_train = predictor.predict(X_train, model=model_name)\n        else:\n            y_pred_test = predictor.predict_proba(X_test, model=model_name).iloc[:, 1]\n            y_pred_val = predictor.predict_proba(X_val, model=model_name).iloc[:, 1]\n            y_pred_train = predictor.predict_proba(X_train, model=model_name).iloc[:, 1]\n\n        for metric_name, metric_func in metrics:\n            test_values = bootstrap_metric(y_test.to_numpy(), y_pred_test.to_numpy(), metric_func)\n            results.extend([(model_name, metric_name, 'Test', value) for value in test_values])\n\n            val_values = bootstrap_metric(y_val.to_numpy(), y_pred_val.to_numpy(), metric_func)\n            results.extend([(model_name, metric_name, 'Validation', value) for value in val_values])\n\n            train_values = bootstrap_metric(y_train.to_numpy(), y_pred_train.to_numpy(), metric_func)\n            results.extend([(model_name, metric_name, 'Train', value) for value in train_values])\n\n    # Create a results DataFrame\n    result_df = pd.DataFrame(results, columns=['model', 'metric', 'data_split', 'value'])\n\n     # Sort models by median metric value within each combination of metric and data_split\n    model_order_per_split = {}\n    for split in ['Test', 'Validation', 'Train']:\n        split_order = (\n            result_df[result_df['data_split'] == split]\n            .groupby(['metric', 'model'])['value']\n            .median()\n            .reset_index()\n            .sort_values(by=['metric', 'value'], ascending=[True, False])\n            .groupby('metric')['model']\n            .apply(list)\n            .to_dict()\n        )\n        model_order_per_split[split] = split_order\n\n    # Function to create violin plots for a specific data split\n    def create_violin_plot(data_split, save_path):\n        sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n        subset = result_df[result_df['data_split'] == data_split]\n        g = sns.FacetGrid(\n            subset,\n            col=\"metric\",\n            margin_titles=True,\n            height=4,\n            aspect=1.5,\n            xlim=(0,1.1)\n        )\n\n        # Create violin plots with sorted models\n        def violin_plot(data, **kwargs):\n            metric = data.iloc[0]['metric']\n            order = model_order_per_split[data_split].get(metric, None)\n            sns.violinplot(data=data, x=\"value\", y=\"model\", linewidth=1, order=order, **kwargs)\n\n        g.map_dataframe(violin_plot)\n\n        # Adjust the titles and axis labels\n        g.set_titles(col_template=\"{col_name}\")\n        g.set_axis_labels(\"Metric Value\", \"Model\")\n\n        # Add overall title and adjust layout\n        g.figure.suptitle(f\"Model Performance of {data_split} Data (Bootstrapped)\", fontsize=16)\n        g.tight_layout(w_pad=0.5, h_pad=1)\n\n        # Save the plot\n        g.savefig(save_path, dpi=500)\n        plt.close()\n\n    # Generate and save plots for each data split\n    create_violin_plot('Test', output_dir / 'test_metrics_bootstrap.png')\n    create_violin_plot('Validation', output_dir / 'validation_metrics_bootstrap.png')\n    create_violin_plot('Train', output_dir / 'train_metrics_bootstrap.png')\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_regression_diagnostics","title":"<code>plot_regression_diagnostics(y_true, y_pred, output_dir)</code>","text":"<p>Generates diagnostic plots for evaluating a regression model.</p> Plots <ul> <li>True vs. Predicted values plot.</li> <li>Residuals plot.</li> <li>Histogram of residuals.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>Array of true target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>Array of predicted values from the regression model.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the diagnostic plots.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_regression_diagnostics(\n        y_true: np.ndarray, \n        y_pred: np.ndarray, \n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Generates diagnostic plots for evaluating a regression model.\n\n    Plots:\n        - True vs. Predicted values plot.\n        - Residuals plot.\n        - Histogram of residuals.\n\n    Args:\n        y_true (np.ndarray): Array of true target values.\n        y_pred (np.ndarray): Array of predicted values from the regression model.\n        output_dir (Path): Directory to save the diagnostic plots.\n    \"\"\"\n    residuals = y_true - y_pred\n\n    # Regression Line\n    plt.figure(figsize=(10, 6))\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    sns.scatterplot(x=y_true, y=y_pred, alpha=0.5)\n    sns.lineplot(x=y_true, y=y_true, color='red')  # Perfect prediction line\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs Predicted Values')\n    plt.savefig(output_dir / 'true_vs_predicted.png')\n    plt.close()\n\n    # Residuals\n    plt.figure(figsize=(10, 6))\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    sns.scatterplot(x=y_pred, y=residuals, alpha=0.5)\n    plt.axhline(0, color='red', linestyle='--')\n    plt.xlabel('Fitted Values')\n    plt.ylabel('Residuals')\n    plt.title('Residual Plot')\n    plt.savefig(output_dir / 'residual_plot.png')\n    plt.close()\n\n    # Residual Histogram\n    plt.figure(figsize=(10, 6))\n    sns.set_theme(style=\"darkgrid\", font=\"Arial\")\n    sns.histplot(residuals, kde=True, bins=30)\n    plt.xlabel('Residuals')\n    plt.title('Histogram of Residuals')\n    plt.savefig(output_dir / 'residual_hist.png')\n    plt.close()\n</code></pre>"},{"location":"api/plot/#jarvais.utils.plot.plot_classification_diagnostics","title":"<code>plot_classification_diagnostics(y_test, y_test_pred, y_val, y_val_pred, y_train, y_train_pred, output_dir)</code>","text":"<p>Generates diagnostic plots for evaluating a classification model.</p> Plots <ul> <li>Epic model evaluation plots (ROC Curve, Precision-Recall Curve, Calibration Curve, Sensitivity/Flag Curve).</li> <li>Confusion Matrix.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_test</code> <code>DataFrame</code> <p>True labels for the test dataset.</p> required <code>y_test_pred</code> <code>DataFrame</code> <p>Predicted probabilities for the test dataset.</p> required <code>y_val</code> <code>DataFrame</code> <p>True labels for the validation dataset.</p> required <code>y_val_pred</code> <code>DataFrame</code> <p>Predicted probabilities for the validation dataset.</p> required <code>y_train</code> <code>DataFrame</code> <p>True labels for the training dataset.</p> required <code>y_train_pred</code> <code>DataFrame</code> <p>Predicted probabilities for the training dataset.</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save the diagnostic plots.</p> required Source code in <code>src/jarvais/utils/plot.py</code> <pre><code>def plot_classification_diagnostics(\n        y_test: pd.DataFrame,\n        y_test_pred: pd.DataFrame,\n        y_val: pd.DataFrame,\n        y_val_pred: pd.DataFrame,\n        y_train: pd.DataFrame,\n        y_train_pred: pd.DataFrame,\n        output_dir: Path\n    ) -&gt; None:\n    \"\"\"\n    Generates diagnostic plots for evaluating a classification model.\n\n    Plots:\n        - Epic model evaluation plots (ROC Curve, Precision-Recall Curve, Calibration Curve, Sensitivity/Flag Curve).\n        - Confusion Matrix.\n\n    Args:\n        y_test (pd.DataFrame): True labels for the test dataset.\n        y_test_pred (pd.DataFrame): Predicted probabilities for the test dataset.\n        y_val (pd.DataFrame): True labels for the validation dataset.\n        y_val_pred (pd.DataFrame): Predicted probabilities for the validation dataset.\n        y_train (pd.DataFrame): True labels for the training dataset.\n        y_train_pred (pd.DataFrame): Predicted probabilities for the training dataset.\n        output_dir (Path): Directory to save the diagnostic plots.\n    \"\"\"\n    plot_epic_copy(\n        y_test.to_numpy(),\n        y_test_pred.to_numpy(),\n        y_val.to_numpy(),\n        y_val_pred.to_numpy(),\n        y_train.to_numpy(),\n        y_train_pred.to_numpy() ,\n        output_dir\n    )\n\n    conf_matrix = confusion_matrix(y_test, y_test_pred.apply(lambda x: 1 if x &gt;= 0.5 else 0))\n\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.savefig(output_dir / 'confusion_matrix.png')\n    plt.close()\n</code></pre>"},{"location":"api/trainer/","title":"Trainer","text":""},{"location":"api/trainer/#trainersupervised","title":"TrainerSupervised","text":"<p>The <code>TrainerSupervised</code> class is part of the <code>jarvais.trainer</code> module.</p>"},{"location":"api/trainer/#jarvais.trainer.TrainerSupervised","title":"<code>jarvais.trainer.TrainerSupervised</code>","text":"<p>TrainerSupervised class for supervised jarvAIs workflows.</p> <p>This class provides functionality for feature reduction, training models (e.g., AutoGluon, survival models),  and performing inference. It supports various tasks such as binary/multiclass classification, regression,  and survival analysis.</p> <p>Attributes:</p> Name Type Description <code>task</code> <code>str</code> <p>Type of task. Must be one of {'binary', 'multiclass', 'regression', 'survival'}. </p> <code>reduction_method</code> <code>str | None</code> <p>Feature reduction method. Supported methods include  {'mrmr', 'variance_threshold', 'corr', 'chi2'}.</p> <code>keep_k</code> <code>int</code> <p>Number of features to retain during reduction.</p> <code>output_dir</code> <code>str | Path</code> <p>Directory for saving outputs. Defaults to the current working directory.</p> Example <pre><code>from jarvais.trainer import TrainerSupervised\n\ntrainer = TrainerSupervised(\n    task=\"binary\",\n    reduction_method=\"mrmr\",\n    keep_k=10,\n    output_dir=\"./results\"\n)\ntrainer.run(data=my_data, target_variable=\"target\")\n\npredictions = trainer.infer(new_data)\n</code></pre> Source code in <code>src/jarvais/trainer/trainer.py</code> <pre><code>class TrainerSupervised:\n    \"\"\"\n    TrainerSupervised class for supervised jarvAIs workflows.\n\n    This class provides functionality for feature reduction, training models (e.g., AutoGluon, survival models), \n    and performing inference. It supports various tasks such as binary/multiclass classification, regression, \n    and survival analysis.\n\n    Attributes:\n        task (str, optional): Type of task. Must be one of {'binary', 'multiclass', 'regression', 'survival'}. \n        reduction_method (str | None, optional): Feature reduction method. Supported methods include \n            {'mrmr', 'variance_threshold', 'corr', 'chi2'}.\n        keep_k (int, optional): Number of features to retain during reduction.\n        output_dir (str | Path, optional): Directory for saving outputs. Defaults to the current working directory.\n\n    Example:\n        ```python\n        from jarvais.trainer import TrainerSupervised\n\n        trainer = TrainerSupervised(\n            task=\"binary\",\n            reduction_method=\"mrmr\",\n            keep_k=10,\n            output_dir=\"./results\"\n        )\n        trainer.run(data=my_data, target_variable=\"target\")\n\n        predictions = trainer.infer(new_data)\n        ```\n    \"\"\"\n    def __init__(\n            self,\n            task: str=None,\n            reduction_method: str | None = None,\n            keep_k: int = 2,\n            output_dir: str | Path = None\n        ) -&gt; None:\n\n        self.task = task\n        self.reduction_method = reduction_method\n        self.keep_k = keep_k\n\n        if task not in ['binary', 'multiclass', 'regression', 'survival', None]:\n            raise ValueError(\"Invalid task parameter. Choose one of: 'binary', 'multiclass', 'regression', 'survival'. Providing None defaults to Autogluon infering.\")\n\n        self.output_dir = Path.cwd() if output_dir is None else Path(output_dir)\n        self.output_dir.mkdir(exist_ok=True, parents=True)\n\n    def _feature_reduction(self, X: pd.DataFrame, y: pd.DataFrame | pd.Series) -&gt; pd.DataFrame:\n        \"\"\"\n        Reduce features based on the specified reduction method. \n\n        One-hot encoding applied before reduction and reverted afterward.\n        \"\"\"\n        # Step 1: Identify categorical columns\n        categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n\n        mappin = {}\n\n        def find_category_mappings(df, variable):\n            return {k: i for i, k in enumerate(df[variable].dropna().unique(), 0)}\n\n        def integer_encode(df, variable, ordinal_mapping):\n            df[variable] = df[variable].map(ordinal_mapping)\n\n        for variable in categorical_columns:\n            mappings = find_category_mappings(X, variable)\n            mappin[variable] = mappings\n\n        for variable in categorical_columns:\n            integer_encode(X, variable, mappin[variable])\n\n        # Step 3: Perform feature reduction\n        if self.reduction_method == 'mrmr':\n            X_reduced = mrmr_reduction(self.task, X, y, self.keep_k)\n        elif self.reduction_method == 'variance_threshold':\n            X_reduced = var_reduction(X, y)\n        elif self.reduction_method == 'corr':\n            X_reduced = kbest_reduction(self.task, X, y, self.keep_k)\n        elif self.reduction_method == 'chi2':\n            if self.task not in ['binary', 'multiclass']:\n                raise ValueError('chi-squared reduction can only be done with classification tasks')\n            X_reduced = chi2_reduction(X, y, self.keep_k)\n        else:\n            raise ValueError('Unsupported reduction method: {}'.format(self.reduction_method))\n\n        for col in categorical_columns:\n            if col in X_reduced.columns:\n                inv_map = {v: k for k, v in mappin[col].items()}\n                X_reduced[col] = X_reduced[col].map(inv_map)\n\n        return X_reduced\n\n    def _train_autogluon_with_cv(self) -&gt; None:\n        self.predictors, leaderboard, self.best_fold, self.X_val, self.y_val = train_autogluon_with_cv(\n            pd.concat([self.X_train, self.y_train], axis=1),\n            pd.concat([self.X_test, self.y_test], axis=1),\n            target_variable=self.target_variable,\n            task=self.task,\n            extra_metrics=self.extra_metrics,\n            eval_metric=self.eval_metric,\n            num_folds=self.k_folds,\n            output_dir=(self.output_dir / 'autogluon_models'),\n            **self.kwargs\n        )\n\n        self.predictor = self.predictors[self.best_fold]\n        self.trainer_config['best_fold'] = self.best_fold\n\n        # Update train data to remove validation\n        self.X_train = self.X_train[~self.X_train.index.isin(self.X_val.index)]\n        self.y_train = self.y_train[~self.y_train.index.isin(self.y_val.index)]\n\n        print('\\nModel Leaderboard (Displays values in \"mean [min, max]\" format across training folds)\\n------------------------------------------------------------------------------------')\n        print(tabulate(\n            leaderboard.sort_values(by='score_test', ascending=False)[self.show_leaderboard],\n            tablefmt = \"fancy_grid\",\n            headers=\"keys\",\n            showindex=False\n        ))\n\n    def _train_autogluon(self) -&gt; None:\n        self.predictor = TabularPredictor(\n            label=self.target_variable, \n            problem_type=self.task, \n            eval_metric=self.eval_metric,\n            path=(self.output_dir / 'autogluon_models' / 'autogluon_models_best_fold'),\n            log_to_file=False,\n        ).fit(\n            pd.concat([self.X_train, self.y_train], axis=1),\n            **self.kwargs\n        )\n\n        self.X_val, self.y_val = self.predictor.load_data_internal(data='val', return_y=True)\n        # Update train data to remove validation\n        self.X_train = self.X_train[~self.X_train.index.isin(self.X_val.index)]\n        self.y_train = self.y_train[~self.y_train.index.isin(self.y_val.index)]\n\n        train_leaderboard = self.predictor.leaderboard(\n            pd.concat([self.X_train, self.y_train], axis=1),\n            extra_metrics=self.extra_metrics).round(2)\n        val_leaderboard = self.predictor.leaderboard(\n            pd.concat([self.X_val, self.y_val], axis=1),\n            extra_metrics=self.extra_metrics).round(2)\n        test_leaderboard = self.predictor.leaderboard(\n            pd.concat([self.X_test, self.y_test], axis=1),\n            extra_metrics=self.extra_metrics).round(2)\n\n        leaderboard = pd.merge(\n            pd.merge(\n                format_leaderboard(train_leaderboard, self.extra_metrics, 'score_train'),\n                format_leaderboard(val_leaderboard, self.extra_metrics, 'score_val'),\n                on='model'\n            ),\n            format_leaderboard(test_leaderboard, self.extra_metrics, 'score_test'),\n            on='model'\n        )\n\n        print('\\nModel Leaderboard\\n----------------')\n        print(tabulate(\n            leaderboard.sort_values(by='score_test', ascending=False)[self.show_leaderboard],\n            tablefmt = \"fancy_grid\",\n            headers=\"keys\",\n            showindex=False))\n\n    def run(\n            self,\n            data: pd.DataFrame,\n            target_variable: str,\n            test_size: float = 0.2,\n            exclude: List[str] | None = None,\n            stratify_on: str | None = None,\n            explain: bool = False,\n            k_folds: int = 5,\n            **kwargs:dict\n        ) -&gt; None:\n        \"\"\"\n        Execute the jarvAIs Trainer pipeline on the given dataset.\n\n        Args:\n            data (pd.DataFrame): The input dataset containing features and target.\n            target_variable (str): The name of the target variable in the dataset.\n            test_size (float, optional): Proportion of the dataset to include in the test split. \n                Must be between 0 and 1. Default is 0.2.\n            exclude (list of str, optional): List of columns to exclude from the feature set. \n                Default is an empty list.\n            stratify_on (str, optional): Column to use for stratification, if any. \n                Must be compatible with `target_variable`.\n            explain (bool, optional): Whether to generate explainability reports for the model. \n                Default is False.\n            k_folds (int, optional): Number of folds for cross-validation. If 1, uses AutoGluon-specific validation. \n                Default is 5.\n            kwargs (dict, optional): Additional arguments passed to the AutoGluon predictor's `fit` method.\n        \"\"\"\n        self.trainer_config = dict()\n        self.trainer_config['task'] = self.task\n        self.trainer_config['output_dir'] = self.output_dir.as_posix()\n\n        self.target_variable = target_variable\n        self.trainer_config['target_variable'] = target_variable\n        self.k_folds = k_folds\n        self.trainer_config['k_folds'] = k_folds\n        self.kwargs = kwargs\n\n        self.trainer_config['test_size'] = test_size\n        self.trainer_config['stratify_on'] = stratify_on\n\n        # Initialize mutable defaults\n        if exclude is None:\n            exclude = []\n\n        if isinstance(target_variable, list): # Happens for survival data\n            exclude += target_variable\n        else:\n            exclude.append(target_variable)\n\n        try:\n            X = data.drop(columns=exclude)\n            y = data[target_variable]\n        except KeyError as e:\n            raise ValueError(f\"Invalid column specified: {e}\")\n\n        # Optional feature reduction\n        if getattr(self, \"reduction_method\", None):\n            print(f\"Applying {self.reduction_method} for feature reduction\")\n            X = self._feature_reduction(X, y)\n            print(f\"Features retained: {list(X.columns)}\")\n\n            self.feature_names = list(X.columns)\n            self.trainer_config['reduction_method'] = self.reduction_method\n            self.trainer_config['reduced_feature_set'] = self.feature_names\n\n        if self.task in {'binary', 'multiclass'}:\n            stratify_col = (\n                y.astype(str) + '_' + data[stratify_on].astype(str)\n                if stratify_on is not None\n                else y\n            )\n        else:\n            stratify_col = None\n\n        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n            X, y, test_size=test_size, stratify=stratify_col, random_state=42)\n\n        if self.task == 'survival':\n            self.predictors, scores, data_train, data_val = train_survival_models(\n                self.X_train, \n                self.y_train, \n                self.X_test, \n                self.y_test, \n                self.output_dir\n            )\n            self.predictor = self.predictors[max(scores, key=scores.get)]\n            self.trainer_config['survival_models_info'] = scores\n\n            self.X_train, self.y_train = data_train.drop(columns=['time', 'event']), data_train[['time', 'event']] \n            self.X_val, self.y_val = data_val.drop(columns=['time', 'event']), data_val[['time', 'event']] \n        else:\n            (self.output_dir / 'autogluon_models').mkdir(exist_ok=True, parents=True)\n\n            if self.task in ['binary', 'multiclass']:\n                self.eval_metric = 'roc_auc'\n            elif self.task == 'regression':\n                self.eval_metric = 'r2'\n\n            ag_auprc_scorer = make_scorer(\n                name='auprc', # Move this to a seperate file?\n                score_func=auprc,\n                optimum=1,\n                greater_is_better=True,\n                needs_class=True)\n\n            # When changing extra_metrics consider where it's used and make updates accordingly\n            self.extra_metrics = ['f1', ag_auprc_scorer] if self.task in ['binary', 'multiclass'] else ['root_mean_squared_error']\n            self.show_leaderboard = ['model', 'score_test', 'score_val', 'score_train']\n\n            custom_hyperparameters = get_hyperparameter_config('default')\n            custom_hyperparameters[SimpleRegressionModel] = {}\n            kwargs['hyperparameters'] = custom_hyperparameters\n\n            if k_folds &gt; 1:\n                self._train_autogluon_with_cv()\n            else:\n                self._train_autogluon()\n\n        self.data_dir = self.output_dir / 'data'\n        self.data_dir.mkdir(parents=True, exist_ok=True)\n        self.X_train.to_csv((self.data_dir / 'X_train.csv'), index=False)\n        self.X_test.to_csv((self.data_dir / 'X_test.csv'), index=False)\n        self.X_val.to_csv((self.data_dir / 'X_val.csv'), index=False)\n        self.y_train.to_csv((self.data_dir / 'y_train.csv'), index=False)\n        self.y_test.to_csv((self.data_dir / 'y_test.csv'), index=False)\n        self.y_val.to_csv((self.data_dir / 'y_val.csv'), index=False)\n\n        with (self.output_dir / 'trainer_config.yaml').open('w') as f:\n            yaml.dump(self.trainer_config, f)\n\n        if explain:\n            explainer = Explainer.from_trainer(self)\n            explainer.run()\n\n    def infer(self, data: pd.DataFrame, model: str = None) -&gt; pd.DataFrame | pd.Series | np.ndarray:\n        \"\"\"\n        Perform inference using the trained predictor on the provided data.\n\n        Args:\n            data (pd.DataFrame): The input data for which inference is to be performed.\n            model (str, optional): The name of the model to use for inference. If None, the default model is used.\n\n        Returns:\n            pd.DataFrame, pd.Series, or np.ndarray: The prediction results from the model.\n        \"\"\"\n        if hasattr(self.predictor, 'can_predict_proba'): # Autogluon\n            if self.predictor.can_predict_proba:\n                inference =  self.predictor.predict_proba(data, model).iloc[:, 1]\n            else:\n                inference = self.predictor.predict(data, model)\n        else: # Survival models\n            if model is None:\n                inference = self.predictor.predict(data)\n            else:\n                inference = self.predictors[model].predict(data)\n\n        return inference\n\n    @classmethod\n    def load_trainer(cls, project_dir: str | Path):\n        \"\"\"\n        Load a trained TrainerSupervised from the specified directory.\n\n        Args:\n            project_dir (str or Path, optional): The directory where the trainer was run.\n\n        Returns:\n            TrainerSupervised: The loaded Trainer.\n        \"\"\"\n        project_dir = Path(project_dir)\n        with (project_dir / 'trainer_config.yaml').open('r') as f:\n            trainer_config = yaml.safe_load(f)\n\n        trainer = cls()\n        trainer.task = trainer_config['task']\n\n        if trainer.task == 'survival':\n            model_dir = (project_dir / 'survival_models')\n\n            trainer.predictors = {}\n            model_info = trainer_config['survival_models_info']\n            for model_name, _ in model_info.items():\n                if model_name == 'MTLR':\n                    trainer.predictors[model_name] = LitMTLR.load_from_checkpoint(model_dir / \"MTLR.ckpt\")\n                elif model_name == 'DeepSurv':\n                    trainer.predictors[model_name] = LitDeepSurv.load_from_checkpoint(model_dir / \"DeepSurv.ckpt\")\n                else:\n                    with (model_dir / f'{model_name}.pkl').open(\"rb\") as f:\n                        trainer.predictors[model_name] = pickle.load(f)\n\n            trainer.predictor = trainer.predictors[max(model_info, key=model_info.get)]\n        else:\n            model_dir = (project_dir / 'autogluon_models' / 'autogluon_models_best_fold')\n            trainer.predictor = TabularPredictor.load(model_dir, verbosity=1)\n\n        trainer.X_test = pd.read_csv(project_dir / 'data' / 'X_test.csv')\n        trainer.X_val = pd.read_csv(project_dir / 'data' / 'X_val.csv')\n        trainer.X_train = pd.read_csv(project_dir / 'data' / 'X_train.csv')\n        trainer.y_test = pd.read_csv(project_dir / 'data' / 'y_test.csv').squeeze()\n        trainer.y_val = pd.read_csv(project_dir / 'data' / 'y_val.csv').squeeze()\n        trainer.y_train = pd.read_csv(project_dir / 'data' / 'y_train.csv').squeeze()\n\n        return trainer\n</code></pre>"},{"location":"api/trainer/#jarvais.trainer.TrainerSupervised.run","title":"<code>run(data, target_variable, test_size=0.2, exclude=None, stratify_on=None, explain=False, k_folds=5, **kwargs)</code>","text":"<p>Execute the jarvAIs Trainer pipeline on the given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The input dataset containing features and target.</p> required <code>target_variable</code> <code>str</code> <p>The name of the target variable in the dataset.</p> required <code>test_size</code> <code>float</code> <p>Proportion of the dataset to include in the test split.  Must be between 0 and 1. Default is 0.2.</p> <code>0.2</code> <code>exclude</code> <code>list of str</code> <p>List of columns to exclude from the feature set.  Default is an empty list.</p> <code>None</code> <code>stratify_on</code> <code>str</code> <p>Column to use for stratification, if any.  Must be compatible with <code>target_variable</code>.</p> <code>None</code> <code>explain</code> <code>bool</code> <p>Whether to generate explainability reports for the model.  Default is False.</p> <code>False</code> <code>k_folds</code> <code>int</code> <p>Number of folds for cross-validation. If 1, uses AutoGluon-specific validation.  Default is 5.</p> <code>5</code> <code>kwargs</code> <code>dict</code> <p>Additional arguments passed to the AutoGluon predictor's <code>fit</code> method.</p> <code>{}</code> Source code in <code>src/jarvais/trainer/trainer.py</code> <pre><code>def run(\n        self,\n        data: pd.DataFrame,\n        target_variable: str,\n        test_size: float = 0.2,\n        exclude: List[str] | None = None,\n        stratify_on: str | None = None,\n        explain: bool = False,\n        k_folds: int = 5,\n        **kwargs:dict\n    ) -&gt; None:\n    \"\"\"\n    Execute the jarvAIs Trainer pipeline on the given dataset.\n\n    Args:\n        data (pd.DataFrame): The input dataset containing features and target.\n        target_variable (str): The name of the target variable in the dataset.\n        test_size (float, optional): Proportion of the dataset to include in the test split. \n            Must be between 0 and 1. Default is 0.2.\n        exclude (list of str, optional): List of columns to exclude from the feature set. \n            Default is an empty list.\n        stratify_on (str, optional): Column to use for stratification, if any. \n            Must be compatible with `target_variable`.\n        explain (bool, optional): Whether to generate explainability reports for the model. \n            Default is False.\n        k_folds (int, optional): Number of folds for cross-validation. If 1, uses AutoGluon-specific validation. \n            Default is 5.\n        kwargs (dict, optional): Additional arguments passed to the AutoGluon predictor's `fit` method.\n    \"\"\"\n    self.trainer_config = dict()\n    self.trainer_config['task'] = self.task\n    self.trainer_config['output_dir'] = self.output_dir.as_posix()\n\n    self.target_variable = target_variable\n    self.trainer_config['target_variable'] = target_variable\n    self.k_folds = k_folds\n    self.trainer_config['k_folds'] = k_folds\n    self.kwargs = kwargs\n\n    self.trainer_config['test_size'] = test_size\n    self.trainer_config['stratify_on'] = stratify_on\n\n    # Initialize mutable defaults\n    if exclude is None:\n        exclude = []\n\n    if isinstance(target_variable, list): # Happens for survival data\n        exclude += target_variable\n    else:\n        exclude.append(target_variable)\n\n    try:\n        X = data.drop(columns=exclude)\n        y = data[target_variable]\n    except KeyError as e:\n        raise ValueError(f\"Invalid column specified: {e}\")\n\n    # Optional feature reduction\n    if getattr(self, \"reduction_method\", None):\n        print(f\"Applying {self.reduction_method} for feature reduction\")\n        X = self._feature_reduction(X, y)\n        print(f\"Features retained: {list(X.columns)}\")\n\n        self.feature_names = list(X.columns)\n        self.trainer_config['reduction_method'] = self.reduction_method\n        self.trainer_config['reduced_feature_set'] = self.feature_names\n\n    if self.task in {'binary', 'multiclass'}:\n        stratify_col = (\n            y.astype(str) + '_' + data[stratify_on].astype(str)\n            if stratify_on is not None\n            else y\n        )\n    else:\n        stratify_col = None\n\n    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n        X, y, test_size=test_size, stratify=stratify_col, random_state=42)\n\n    if self.task == 'survival':\n        self.predictors, scores, data_train, data_val = train_survival_models(\n            self.X_train, \n            self.y_train, \n            self.X_test, \n            self.y_test, \n            self.output_dir\n        )\n        self.predictor = self.predictors[max(scores, key=scores.get)]\n        self.trainer_config['survival_models_info'] = scores\n\n        self.X_train, self.y_train = data_train.drop(columns=['time', 'event']), data_train[['time', 'event']] \n        self.X_val, self.y_val = data_val.drop(columns=['time', 'event']), data_val[['time', 'event']] \n    else:\n        (self.output_dir / 'autogluon_models').mkdir(exist_ok=True, parents=True)\n\n        if self.task in ['binary', 'multiclass']:\n            self.eval_metric = 'roc_auc'\n        elif self.task == 'regression':\n            self.eval_metric = 'r2'\n\n        ag_auprc_scorer = make_scorer(\n            name='auprc', # Move this to a seperate file?\n            score_func=auprc,\n            optimum=1,\n            greater_is_better=True,\n            needs_class=True)\n\n        # When changing extra_metrics consider where it's used and make updates accordingly\n        self.extra_metrics = ['f1', ag_auprc_scorer] if self.task in ['binary', 'multiclass'] else ['root_mean_squared_error']\n        self.show_leaderboard = ['model', 'score_test', 'score_val', 'score_train']\n\n        custom_hyperparameters = get_hyperparameter_config('default')\n        custom_hyperparameters[SimpleRegressionModel] = {}\n        kwargs['hyperparameters'] = custom_hyperparameters\n\n        if k_folds &gt; 1:\n            self._train_autogluon_with_cv()\n        else:\n            self._train_autogluon()\n\n    self.data_dir = self.output_dir / 'data'\n    self.data_dir.mkdir(parents=True, exist_ok=True)\n    self.X_train.to_csv((self.data_dir / 'X_train.csv'), index=False)\n    self.X_test.to_csv((self.data_dir / 'X_test.csv'), index=False)\n    self.X_val.to_csv((self.data_dir / 'X_val.csv'), index=False)\n    self.y_train.to_csv((self.data_dir / 'y_train.csv'), index=False)\n    self.y_test.to_csv((self.data_dir / 'y_test.csv'), index=False)\n    self.y_val.to_csv((self.data_dir / 'y_val.csv'), index=False)\n\n    with (self.output_dir / 'trainer_config.yaml').open('w') as f:\n        yaml.dump(self.trainer_config, f)\n\n    if explain:\n        explainer = Explainer.from_trainer(self)\n        explainer.run()\n</code></pre>"},{"location":"api/trainer/#jarvais.trainer.TrainerSupervised.infer","title":"<code>infer(data, model=None)</code>","text":"<p>Perform inference using the trained predictor on the provided data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The input data for which inference is to be performed.</p> required <code>model</code> <code>str</code> <p>The name of the model to use for inference. If None, the default model is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame | Series | ndarray</code> <p>pd.DataFrame, pd.Series, or np.ndarray: The prediction results from the model.</p> Source code in <code>src/jarvais/trainer/trainer.py</code> <pre><code>def infer(self, data: pd.DataFrame, model: str = None) -&gt; pd.DataFrame | pd.Series | np.ndarray:\n    \"\"\"\n    Perform inference using the trained predictor on the provided data.\n\n    Args:\n        data (pd.DataFrame): The input data for which inference is to be performed.\n        model (str, optional): The name of the model to use for inference. If None, the default model is used.\n\n    Returns:\n        pd.DataFrame, pd.Series, or np.ndarray: The prediction results from the model.\n    \"\"\"\n    if hasattr(self.predictor, 'can_predict_proba'): # Autogluon\n        if self.predictor.can_predict_proba:\n            inference =  self.predictor.predict_proba(data, model).iloc[:, 1]\n        else:\n            inference = self.predictor.predict(data, model)\n    else: # Survival models\n        if model is None:\n            inference = self.predictor.predict(data)\n        else:\n            inference = self.predictors[model].predict(data)\n\n    return inference\n</code></pre>"},{"location":"api/trainer/#jarvais.trainer.TrainerSupervised.load_trainer","title":"<code>load_trainer(project_dir)</code>  <code>classmethod</code>","text":"<p>Load a trained TrainerSupervised from the specified directory.</p> <p>Parameters:</p> Name Type Description Default <code>project_dir</code> <code>str or Path</code> <p>The directory where the trainer was run.</p> required <p>Returns:</p> Name Type Description <code>TrainerSupervised</code> <p>The loaded Trainer.</p> Source code in <code>src/jarvais/trainer/trainer.py</code> <pre><code>@classmethod\ndef load_trainer(cls, project_dir: str | Path):\n    \"\"\"\n    Load a trained TrainerSupervised from the specified directory.\n\n    Args:\n        project_dir (str or Path, optional): The directory where the trainer was run.\n\n    Returns:\n        TrainerSupervised: The loaded Trainer.\n    \"\"\"\n    project_dir = Path(project_dir)\n    with (project_dir / 'trainer_config.yaml').open('r') as f:\n        trainer_config = yaml.safe_load(f)\n\n    trainer = cls()\n    trainer.task = trainer_config['task']\n\n    if trainer.task == 'survival':\n        model_dir = (project_dir / 'survival_models')\n\n        trainer.predictors = {}\n        model_info = trainer_config['survival_models_info']\n        for model_name, _ in model_info.items():\n            if model_name == 'MTLR':\n                trainer.predictors[model_name] = LitMTLR.load_from_checkpoint(model_dir / \"MTLR.ckpt\")\n            elif model_name == 'DeepSurv':\n                trainer.predictors[model_name] = LitDeepSurv.load_from_checkpoint(model_dir / \"DeepSurv.ckpt\")\n            else:\n                with (model_dir / f'{model_name}.pkl').open(\"rb\") as f:\n                    trainer.predictors[model_name] = pickle.load(f)\n\n        trainer.predictor = trainer.predictors[max(model_info, key=model_info.get)]\n    else:\n        model_dir = (project_dir / 'autogluon_models' / 'autogluon_models_best_fold')\n        trainer.predictor = TabularPredictor.load(model_dir, verbosity=1)\n\n    trainer.X_test = pd.read_csv(project_dir / 'data' / 'X_test.csv')\n    trainer.X_val = pd.read_csv(project_dir / 'data' / 'X_val.csv')\n    trainer.X_train = pd.read_csv(project_dir / 'data' / 'X_train.csv')\n    trainer.y_test = pd.read_csv(project_dir / 'data' / 'y_test.csv').squeeze()\n    trainer.y_val = pd.read_csv(project_dir / 'data' / 'y_val.csv').squeeze()\n    trainer.y_train = pd.read_csv(project_dir / 'data' / 'y_train.csv').squeeze()\n\n    return trainer\n</code></pre>"},{"location":"get_started/analyzer/","title":"Analyzer Quick Start","text":""},{"location":"get_started/analyzer/#analyzer","title":"Analyzer","text":"<p>The <code>Analyzer</code> module is designed for data visualization and exploration. It helps to gain insights into the data, identify patterns, and assess relationships between different features, which is essential for building effective models.</p>"},{"location":"get_started/analyzer/#example-usage","title":"Example Usage","text":"<pre><code>from jarvais.analyzer import Analyzer\n\nanalyzer = Analyzer(data, target_variable='target', output_dir='.')\nanalyzer.run()\n</code></pre>"},{"location":"get_started/analyzer/#example-output","title":"Example Output","text":"<pre><code>Feature Types:\n  - Categorical: ['Gender', 'Disease Type', 'Treatment']\n  - Continuous: ['Age', 'Tumor Size']\n\nOutlier Detection:\n  - Outliers found in Gender: ['Male: 5 out of 1000']\n  - Outliers found in Disease Type: ['Lung Cancer: 10 out of 1000']\n  - No Outliers found in Treatment\n  - Outliers found in Tumor Size: ['12.5: 2 out of 1000']\n</code></pre>"},{"location":"get_started/analyzer/#tableonedata-summary","title":"TableOne(Data Summary)","text":"Category Missing Overall n 1000 Age, mean (SD) 0 58.2 (12.3) Tumor Size, mean (SD) 0 4.5 (1.2) Gender, n (%) Female 520 (52%) Male 480 (48%) Disease Type, n (%) Breast Cancer 300 (30%) Lung Cancer 150 (15%) Prostate Cancer 100 (10%)"},{"location":"get_started/analyzer/#output-files","title":"Output Files","text":"<p>The Analyzer module generates the following files and directories:</p> <ul> <li>analysis_report.pdf: A PDF report summarizing the analysis results.</li> <li>config.yaml: Configuration file for the analysis setup.</li> <li>tableone.csv: CSV file containing summary statistics for the dataset.</li> <li>updated_data.csv: CSV file with the cleaned and processed data.</li> </ul>"},{"location":"get_started/analyzer/#figures","title":"Figures","text":""},{"location":"get_started/analyzer/#1-frequency-tables","title":"1. Frequency Tables","text":"<p>Visualizations comparing different categorical features.</p> <p></p>"},{"location":"get_started/analyzer/#2-multi-plots","title":"2. Multi-plots","text":"<p>Visualizations showing combinations of features for deeper analysis.</p> <p></p>"},{"location":"get_started/analyzer/#additional-figures","title":"Additional Figures","text":""},{"location":"get_started/analyzer/#1-pairplot","title":"1. Pairplot","text":"<p>Pairwise relationships between continuous variables.</p> <p></p>"},{"location":"get_started/analyzer/#2-pearson-correlation-matrix","title":"2. Pearson Correlation Matrix","text":"<p>A heatmap visualizing Pearson correlations between variables.</p> <p></p>"},{"location":"get_started/analyzer/#3-spearman-correlation-matrix","title":"3. Spearman Correlation Matrix","text":"<p>A heatmap visualizing Spearman correlations between variables.</p> <p></p>"},{"location":"get_started/analyzer/#4-umap-of-continuous-data","title":"4. UMAP of Continuous Data","text":"<p>UMAP visualization of continuous data.</p> <p></p>"},{"location":"get_started/analyzer/#5-kaplan-meier-curve-survival","title":"5. Kaplan Meier Curve (Survival)","text":"<p>Kaplan Meier Curves for all categorical variables. An option exclusive to survival data.</p> <p></p>"},{"location":"get_started/analyzer/#analysis-report","title":"Analysis Report","text":""},{"location":"get_started/explainer/","title":"Explainer Quick Start","text":""},{"location":"get_started/explainer/#explainer-module","title":"Explainer Module","text":"<p>The <code>Explainer</code> module is designed to evaluate trained models by generating diagnostic plots, auditing bias, and producing comprehensive reports. It supports various supervised learning tasks, including classification, regression, and survival models. </p> <p>The module provides an easy-to-use interface for model diagnostics, bias analysis, and feature importance visualization, facilitating deeper insights into the model's performance and fairness.</p>"},{"location":"get_started/explainer/#features","title":"Features","text":"<ul> <li>Diagnostic Plots: Generates performance diagnostics, including classification metrics, regression plots, and SHAP value visualizations.</li> <li>Bias Audit: Identifies potential biases in model predictions with respect to sensitive features.</li> <li>Feature Importance: Calculates and visualizes feature importance using permutation importance or model-specific methods.</li> <li>Comprehensive Reports: Creates a detailed PDF report summarizing all diagnostic results.</li> </ul>"},{"location":"get_started/explainer/#example-usage","title":"Example Usage","text":"<pre><code>from jarvais.explainer import Explainer\n\n# Prefered method is to initialize from trainer\nexp = Explainer.from_trainer(trainer)\nexp.run()\n</code></pre>"},{"location":"get_started/explainer/#output-files","title":"Output Files","text":"<p>The Explainer module generates the following files and directories:</p> <ul> <li>explainer_report.pdf: A PDF report summarizing the model diagnostics, bias audit results, and feature importance.</li> <li>bias/: Contains CSV files with bias metrics for different sensitive features.</li> </ul>"},{"location":"get_started/explainer/#common-figures","title":"Common Figures","text":""},{"location":"get_started/explainer/#feature-importance","title":"Feature Importance","text":""},{"location":"get_started/explainer/#bootsrapped-metrics","title":"Bootsrapped Metrics","text":""},{"location":"get_started/explainer/#classification-figures","title":"Classification Figures","text":""},{"location":"get_started/explainer/#confusion-matrix","title":"Confusion Matrix","text":""},{"location":"get_started/explainer/#model-evaluation","title":"Model Evaluation","text":""},{"location":"get_started/explainer/#shap-plots","title":"Shap Plots","text":""},{"location":"get_started/explainer/#regression-figures","title":"Regression Figures","text":""},{"location":"get_started/explainer/#residual-plots","title":"Residual Plots","text":""},{"location":"get_started/explainer/#true-vs-predicted","title":"True vs Predicted","text":""},{"location":"get_started/explainer/#explainer-report","title":"Explainer Report","text":""},{"location":"get_started/trainer/","title":"Trainer Quick Start","text":""},{"location":"get_started/trainer/#trainer-module","title":"Trainer Module","text":"<p>The <code>Trainer</code> module simplifies and automates the process of feature reduction, model training, and evaluation for various machine learning tasks, ensuring flexibility and efficiency.</p>"},{"location":"get_started/trainer/#key-features","title":"Key Features","text":"<ol> <li> <p>Feature Reduction:</p> <ul> <li>Supports methods such as <code>mrmr</code>, <code>variance_threshold</code>, <code>corr</code>, and <code>chi2</code> to identify and retain relevant features.</li> </ul> </li> <li> <p>Automated Model Training:</p> <ul> <li>Integrates with AutoGluon for model training, selection, and optimization.</li> <li>Handles tasks such as binary classification, multiclass classification, regression, and survival.</li> </ul> </li> </ol>"},{"location":"get_started/trainer/#example-usage","title":"Example Usage","text":"<pre><code>from jarvais.trainer import TrainerSupervised\n\ntrainer = TrainerSupervised(task='binary', output_dir='./trainer_outputs')\ntrainer.run(data=data, target_variable='target', save_data=True)\n</code></pre>"},{"location":"get_started/trainer/#example-output","title":"Example Output","text":"<pre><code>Training fold 1/5...  \nFold 1 score: `0.8467207586933614`\n\nTraining fold 2/5...  \nFold 2 score: `0.8487846136306914`\n...\n</code></pre>"},{"location":"get_started/trainer/#model-leaderboard","title":"Model Leaderboard","text":"<p>Displays values in <code>mean [min, max]</code> format across training folds.</p> Model Score Test Score Val Score Train WeightedEnsemble_L2 AUROC: 0.82 [0.82, 0.83] AUROC: 0.85 [0.85, 0.85] AUROC: 1.0 [1.0, 1.0] F1: 0.13 [0.11, 0.14] F1: 0.09 [0.07, 0.12] F1: 0.95 [0.9, 1.0] AUPRC: 0.48 [0.45, 0.52] AUPRC: 0.47 [0.44, 0.49] AUPRC: 0.96 [0.91, 1.0] ExtraTreesGini AUROC: 0.82 [0.82, 0.82] AUROC: 0.84 [0.84, 0.84] AUROC: 1.0 [1.0, 1.0] F1: 0.21 [0.19, 0.22] F1: 0.16 [0.14, 0.18] F1: 1.0 [1.0, 1.0] AUPRC: 0.45 [0.45, 0.45] AUPRC: 0.43 [0.41, 0.45] AUPRC: 1.0 [1.0, 1.0] ..."},{"location":"get_started/trainer/#output-files","title":"Output Files","text":"<p>Binary/Regression/Multiclass:</p> <pre><code>\u251c\u2500\u2500 autogluon_models\n\u2502   \u251c\u2500\u2500 autogluon_models_best_fold\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 autogluon_models_fold_1\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 autogluon_models_fold_2\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 autogluon_models_fold_3\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 autogluon_models_fold_4\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 autogluon_models_fold_5\n\u2502   \u2502   \u251c\u2500\u2500 learner.pkl\n\u2502   \u2502   \u251c\u2500\u2500 models\n\u2502   \u2502   \u251c\u2500\u2500 ...\n</code></pre> <p>Survival:</p> <pre><code>\u2514\u2500\u2500 survival_models\n    \u251c\u2500\u2500 CoxPH.pkl\n    \u251c\u2500\u2500 GradientBoosting.pkl\n    \u251c\u2500\u2500 RandomForest.pkl\n    \u2514\u2500\u2500 SVM.pkl\n    \u251c\u2500\u2500 lightning_logs\n    \u2502   \u251c\u2500\u2500 version_0\n    \u2502   \u251c\u2500\u2500 ...\n    \u251c\u2500\u2500 DeepSurv.ckpt\n    \u251c\u2500\u2500 MTLR.ckpt\n</code></pre>"},{"location":"tutorials/classification/","title":"Classification","text":"In\u00a0[11]: Copied! <pre>import sys\n\nimport os\n\n# Get the absolute path of the project root directory\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Add the project root directory to the Python path\nsys.path.append(project_root)\n</pre> import sys  import os  # Get the absolute path of the project root directory project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Add the project root directory to the Python path sys.path.append(project_root) In\u00a0[12]: Copied! <pre>import pandas as pd\n\n\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Define the path to the data directory\ndata_dir = os.path.join(project_root, 'data')\n\n# Example: Access a specific data file in the data directory\ndata_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv')\ndf = pd.read_csv(data_file_path)\n</pre>  import pandas as pd   project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Define the path to the data directory data_dir = os.path.join(project_root, 'data')  # Example: Access a specific data file in the data directory data_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv') df = pd.read_csv(data_file_path) In\u00a0[13]: Copied! <pre>from jarvais.analyzer import Analyzer\nfrom pprint import pprint\n\ndf.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)\n\nconfig = Analyzer.dry_run(df)\n\npprint(config)\n</pre> from jarvais.analyzer import Analyzer from pprint import pprint  df.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)  config = Analyzer.dry_run(df)  pprint(config) <pre>Config file not found. Creating custom...\nUsed a heuristic to define categorical and continuous columns. Please review!\n\n\nFeature Types:\n  - Categorical: ['N Stage', 'T Stage', 'Sex', 'Stage', 'Disease Site', 'Dose', 'EGFRI', 'HPV Combined', 'Chemotherapy']\n  - Continuous: ['age at dx']\n\n\nOutlier Analysis:\n  - Outliers found in N Stage: ['N3a: 14 out of 2552', 'NX: 1 out of 2552']\n  - Outliers found in T Stage: ['T2 (2): 1 out of 2552', 'TX: 1 out of 2552', 'T3 (2): 1 out of 2552']\n  - No Outliers found in Sex\n  - Outliers found in Stage: ['IV: 6 out of 2549', 'IIIC: 2 out of 2549', 'IIIA: 2 out of 2549', 'IIA: 1 out of 2549']\n  - Outliers found in Disease Site: ['esophagus: 22 out of 2552', 'salivary glands: 4 out of 2552']\n  - Outliers found in Dose: ['50.0: 9 out of 2552', '69.96: 2 out of 2552', '50.8: 1 out of 2552', '55.0: 1 out of 2552', '53.55: 1 out of 2552', '59.4: 1 out of 2552']\n  - No Outliers found in EGFRI\n  - No Outliers found in HPV Combined\n  - No Outliers found in Chemotherapy\n\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                      \u2502                   \u2502 Missing   \u2502 Overall     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 n                    \u2502                   \u2502           \u2502 2552        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 age at dx, mean (SD) \u2502                   \u2502 0         \u2502 62.0 (11.7) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 N Stage, n (%)       \u2502 N0                \u2502           \u2502 914 (35.8)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N1                \u2502           \u2502 260 (10.2)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2                \u2502           \u2502 161 (6.3)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2a               \u2502           \u2502 75 (2.9)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2b               \u2502           \u2502 585 (22.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2c               \u2502           \u2502 409 (16.0)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3                \u2502           \u2502 106 (4.2)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3a               \u2502           \u2502 14 (0.5)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3b               \u2502           \u2502 27 (1.1)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 NX                \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 T Stage, n (%)       \u2502 T1                \u2502           \u2502 361 (14.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1a               \u2502           \u2502 147 (5.8)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1b               \u2502           \u2502 68 (2.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T2                \u2502           \u2502 747 (29.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T2 (2)            \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T3                \u2502           \u2502 704 (27.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T3 (2)            \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4                \u2502           \u2502 96 (3.8)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4a               \u2502           \u2502 295 (11.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4b               \u2502           \u2502 95 (3.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 TX                \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Tis               \u2502           \u2502 36 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sex, n (%)           \u2502 Female            \u2502           \u2502 513 (20.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Male              \u2502           \u2502 2039 (79.9) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Stage, n (%)         \u2502 0                 \u2502           \u2502 37 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 I                 \u2502           \u2502 289 (11.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 II                \u2502           \u2502 323 (12.7)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IIA               \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 III               \u2502           \u2502 474 (18.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IIIA              \u2502           \u2502 2 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IIIC              \u2502           \u2502 2 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IV                \u2502           \u2502 6 (0.2)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVA               \u2502           \u2502 1187 (46.5) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVB               \u2502           \u2502 228 (8.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 None              \u2502           \u2502 3 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Disease Site, n (%)  \u2502 esophagus         \u2502           \u2502 22 (0.9)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 hypopharynx       \u2502           \u2502 143 (5.6)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 larynx            \u2502           \u2502 727 (28.5)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 lip &amp; oral cavity \u2502           \u2502 82 (3.2)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasal cavity      \u2502           \u2502 51 (2.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasopharynx       \u2502           \u2502 321 (12.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 oropharynx        \u2502           \u2502 1176 (46.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 paranasal sinus   \u2502           \u2502 26 (1.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 salivary glands   \u2502           \u2502 4 (0.2)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dose, n (%)          \u2502 50.0              \u2502           \u2502 9 (0.4)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 50.8              \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 51.0              \u2502           \u2502 177 (6.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 53.55             \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 55.0              \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 59.4              \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 60.0              \u2502           \u2502 288 (11.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 64.0              \u2502           \u2502 208 (8.2)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 66.0              \u2502           \u2502 68 (2.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 69.96             \u2502           \u2502 2 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 70.0              \u2502           \u2502 1796 (70.4) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 EGFRI, n (%)         \u2502 0                 \u2502           \u2502 2452 (96.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 100 (3.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 HPV Combined, n (%)  \u2502 0.0               \u2502           \u2502 437 (17.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1.0               \u2502           \u2502 840 (32.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 None              \u2502           \u2502 1275 (50.0) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Chemotherapy, n (%)  \u2502 0                 \u2502           \u2502 1466 (57.4) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 1086 (42.6) \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n{'columns': {'categorical': ['N Stage',\n                             'T Stage',\n                             'Sex',\n                             'Stage',\n                             'Disease Site',\n                             'Dose',\n                             'EGFRI',\n                             'HPV Combined',\n                             'Chemotherapy'],\n             'continuous': ['age at dx'],\n             'date': [],\n             'other': []},\n 'mapping': {'Chemotherapy': {'0': '0', '1': '1'},\n             'Disease Site': {'esophagus': 'Other',\n                              'hypopharynx': 'hypopharynx',\n                              'larynx': 'larynx',\n                              'lip &amp; oral cavity': 'lip &amp; oral cavity',\n                              'nasal cavity': 'nasal cavity',\n                              'nasopharynx': 'nasopharynx',\n                              'oropharynx': 'oropharynx',\n                              'paranasal sinus': 'paranasal sinus',\n                              'salivary glands': 'Other'},\n             'Dose': {'50.0': 'Other',\n                      '50.8': 'Other',\n                      '51.0': '51.0',\n                      '53.55': 'Other',\n                      '55.0': 'Other',\n                      '59.4': 'Other',\n                      '60.0': '60.0',\n                      '64.0': '64.0',\n                      '66.0': '66.0',\n                      '69.96': 'Other',\n                      '70.0': '70.0'},\n             'EGFRI': {'0': '0', '1': '1'},\n             'HPV Combined': {'0.0': '0.0', '1.0': '1.0', 'nan': 'nan'},\n             'N Stage': {'N0': 'N0',\n                         'N1': 'N1',\n                         'N2': 'N2',\n                         'N2a': 'N2a',\n                         'N2b': 'N2b',\n                         'N2c': 'N2c',\n                         'N3': 'N3',\n                         'N3a': 'Other',\n                         'N3b': 'N3b',\n                         'NX': 'Other'},\n             'Sex': {'Female': 'Female', 'Male': 'Male'},\n             'Stage': {'0': '0',\n                       'I': 'I',\n                       'II': 'II',\n                       'IIA': 'Other',\n                       'III': 'III',\n                       'IIIA': 'Other',\n                       'IIIC': 'Other',\n                       'IV': 'Other',\n                       'IVA': 'IVA',\n                       'IVB': 'IVB',\n                       'nan': 'nan'},\n             'T Stage': {'T1': 'T1',\n                         'T1a': 'T1a',\n                         'T1b': 'T1b',\n                         'T2': 'T2',\n                         'T2 (2)': 'Other',\n                         'T3': 'T3',\n                         'T3 (2)': 'Other',\n                         'T4': 'T4',\n                         'T4a': 'T4a',\n                         'T4b': 'T4b',\n                         'TX': 'Other',\n                         'Tis': 'Tis'}},\n 'missingness_strategy': {'categorical': {'Chemotherapy': 'Unknown',\n                                          'Disease Site': 'Unknown',\n                                          'Dose': 'Unknown',\n                                          'EGFRI': 'Unknown',\n                                          'HPV Combined': 'Unknown',\n                                          'N Stage': 'Unknown',\n                                          'Sex': 'Unknown',\n                                          'Stage': 'Unknown',\n                                          'T Stage': 'Unknown'},\n                          'continuous': {'age at dx': 'median'}}}\n</pre> In\u00a0[14]: Copied! <pre>import yaml\nfrom pathlib import Path\n\nconfig['columns']['categorical'].remove('Dose')\nconfig['columns']['continuous'].append('Dose') \n\npprint(config)\n\nanalyzer_path = Path('outputs/analyzer')\nanalyzer_path.mkdir(parents=True, exist_ok=True)\n\nwith open(analyzer_path / 'config.yaml', 'w') as f:\n            yaml.dump(config, f)\n</pre> import yaml from pathlib import Path  config['columns']['categorical'].remove('Dose') config['columns']['continuous'].append('Dose')   pprint(config)  analyzer_path = Path('outputs/analyzer') analyzer_path.mkdir(parents=True, exist_ok=True)  with open(analyzer_path / 'config.yaml', 'w') as f:             yaml.dump(config, f) <pre>{'columns': {'categorical': ['N Stage',\n                             'T Stage',\n                             'Sex',\n                             'Stage',\n                             'Disease Site',\n                             'EGFRI',\n                             'HPV Combined',\n                             'Chemotherapy'],\n             'continuous': ['age at dx', 'Dose'],\n             'date': [],\n             'other': []},\n 'mapping': {'Chemotherapy': {'0': '0', '1': '1'},\n             'Disease Site': {'esophagus': 'Other',\n                              'hypopharynx': 'hypopharynx',\n                              'larynx': 'larynx',\n                              'lip &amp; oral cavity': 'lip &amp; oral cavity',\n                              'nasal cavity': 'nasal cavity',\n                              'nasopharynx': 'nasopharynx',\n                              'oropharynx': 'oropharynx',\n                              'paranasal sinus': 'paranasal sinus',\n                              'salivary glands': 'Other'},\n             'Dose': {'50.0': 'Other',\n                      '50.8': 'Other',\n                      '51.0': '51.0',\n                      '53.55': 'Other',\n                      '55.0': 'Other',\n                      '59.4': 'Other',\n                      '60.0': '60.0',\n                      '64.0': '64.0',\n                      '66.0': '66.0',\n                      '69.96': 'Other',\n                      '70.0': '70.0'},\n             'EGFRI': {'0': '0', '1': '1'},\n             'HPV Combined': {'0.0': '0.0', '1.0': '1.0', 'nan': 'nan'},\n             'N Stage': {'N0': 'N0',\n                         'N1': 'N1',\n                         'N2': 'N2',\n                         'N2a': 'N2a',\n                         'N2b': 'N2b',\n                         'N2c': 'N2c',\n                         'N3': 'N3',\n                         'N3a': 'Other',\n                         'N3b': 'N3b',\n                         'NX': 'Other'},\n             'Sex': {'Female': 'Female', 'Male': 'Male'},\n             'Stage': {'0': '0',\n                       'I': 'I',\n                       'II': 'II',\n                       'IIA': 'Other',\n                       'III': 'III',\n                       'IIIA': 'Other',\n                       'IIIC': 'Other',\n                       'IV': 'Other',\n                       'IVA': 'IVA',\n                       'IVB': 'IVB',\n                       'nan': 'nan'},\n             'T Stage': {'T1': 'T1',\n                         'T1a': 'T1a',\n                         'T1b': 'T1b',\n                         'T2': 'T2',\n                         'T2 (2)': 'Other',\n                         'T3': 'T3',\n                         'T3 (2)': 'Other',\n                         'T4': 'T4',\n                         'T4a': 'T4a',\n                         'T4b': 'T4b',\n                         'TX': 'Other',\n                         'Tis': 'Tis'}},\n 'missingness_strategy': {'categorical': {'Chemotherapy': 'Unknown',\n                                          'Disease Site': 'Unknown',\n                                          'Dose': 'Unknown',\n                                          'EGFRI': 'Unknown',\n                                          'HPV Combined': 'Unknown',\n                                          'N Stage': 'Unknown',\n                                          'Sex': 'Unknown',\n                                          'Stage': 'Unknown',\n                                          'T Stage': 'Unknown'},\n                          'continuous': {'age at dx': 'median'}}}\n</pre> In\u00a0[15]: Copied! <pre>from jarvais.analyzer import Analyzer\n\nanalyzer = Analyzer(df, target_variable='Chemotherapy', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')\n\nanalyzer.run()\n</pre> from jarvais.analyzer import Analyzer  analyzer = Analyzer(df, target_variable='Chemotherapy', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')  analyzer.run() <pre>Feature Types:\n  - Categorical: ['N Stage', 'T Stage', 'Sex', 'Stage', 'Disease Site', 'EGFRI', 'HPV Combined', 'Chemotherapy']\n  - Continuous: ['age at dx', 'Dose']\n\n\nOutlier Analysis:\n  - Outliers found in N Stage: ['N3a: 14 out of 2552', 'NX: 1 out of 2552']\n  - Outliers found in T Stage: ['T2 (2): 1 out of 2552', 'TX: 1 out of 2552', 'T3 (2): 1 out of 2552']\n  - No Outliers found in Sex\n  - Outliers found in Stage: ['IV: 6 out of 2549', 'IIIC: 2 out of 2549', 'IIIA: 2 out of 2549', 'IIA: 1 out of 2549']\n  - Outliers found in Disease Site: ['esophagus: 22 out of 2552', 'salivary glands: 4 out of 2552']\n  - No Outliers found in EGFRI\n  - No Outliers found in HPV Combined\n  - No Outliers found in Chemotherapy\n\nApplying changes from config...\n\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                      \u2502                   \u2502 Missing   \u2502 Overall     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 n                    \u2502                   \u2502           \u2502 2552        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 age at dx, mean (SD) \u2502                   \u2502 0         \u2502 62.0 (11.7) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dose, mean (SD)      \u2502                   \u2502 0         \u2502 66.9 (5.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 N Stage, n (%)       \u2502 N0                \u2502           \u2502 914 (35.8)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N1                \u2502           \u2502 260 (10.2)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2                \u2502           \u2502 161 (6.3)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2a               \u2502           \u2502 75 (2.9)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2b               \u2502           \u2502 585 (22.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2c               \u2502           \u2502 409 (16.0)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3                \u2502           \u2502 106 (4.2)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3b               \u2502           \u2502 27 (1.1)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Other             \u2502           \u2502 15 (0.6)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 T Stage, n (%)       \u2502 Other             \u2502           \u2502 3 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1                \u2502           \u2502 361 (14.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1a               \u2502           \u2502 147 (5.8)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1b               \u2502           \u2502 68 (2.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T2                \u2502           \u2502 747 (29.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T3                \u2502           \u2502 704 (27.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4                \u2502           \u2502 96 (3.8)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4a               \u2502           \u2502 295 (11.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4b               \u2502           \u2502 95 (3.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Tis               \u2502           \u2502 36 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sex, n (%)           \u2502 Female            \u2502           \u2502 513 (20.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Male              \u2502           \u2502 2039 (79.9) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Stage, n (%)         \u2502 0                 \u2502           \u2502 37 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 I                 \u2502           \u2502 289 (11.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 II                \u2502           \u2502 323 (12.7)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 III               \u2502           \u2502 474 (18.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVA               \u2502           \u2502 1187 (46.5) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVB               \u2502           \u2502 228 (8.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Other             \u2502           \u2502 11 (0.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Unknown           \u2502           \u2502 3 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Disease Site, n (%)  \u2502 Other             \u2502           \u2502 26 (1.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 hypopharynx       \u2502           \u2502 143 (5.6)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 larynx            \u2502           \u2502 727 (28.5)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 lip &amp; oral cavity \u2502           \u2502 82 (3.2)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasal cavity      \u2502           \u2502 51 (2.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasopharynx       \u2502           \u2502 321 (12.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 oropharynx        \u2502           \u2502 1176 (46.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 paranasal sinus   \u2502           \u2502 26 (1.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 EGFRI, n (%)         \u2502 0                 \u2502           \u2502 2452 (96.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 100 (3.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 HPV Combined, n (%)  \u2502 0.0               \u2502           \u2502 437 (17.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1.0               \u2502           \u2502 840 (32.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Unknown           \u2502           \u2502 1275 (50.0) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Chemotherapy, n (%)  \u2502 0                 \u2502           \u2502 1466 (57.4) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 1086 (42.6) \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</pre> In\u00a0[16]: Copied! <pre>from jarvais.trainer import TrainerSupervised\n\ndf = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)\n\ntrainer = TrainerSupervised(task='binary', output_dir='./outputs/trainer')\ntrainer.run(df, 'Chemotherapy')\n</pre> from jarvais.trainer import TrainerSupervised  df = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)  trainer = TrainerSupervised(task='binary', output_dir='./outputs/trainer') trainer.run(df, 'Chemotherapy') <pre>Training fold 1/5...\nFold 1 score: 0.97099667293505\nTraining fold 2/5...\nFold 2 score: 0.9475378178307049\nTraining fold 3/5...\nFold 3 score: 0.9642795830778663\nTraining fold 4/5...\nFold 4 score: 0.9587982832618026\nTraining fold 5/5...\nFold 5 score: 0.9623400639744102\n\nModel Leaderboard (Displays values in \"mean [min, max]\" format across training folds)\n------------------------------------------------------------------------------------\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 model                 \u2502 score_test               \u2502 score_val                \u2502 score_train              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 WeightedEnsemble_L2   \u2502 AUROC 0.94 [0.93, 0.94]  \u2502 AUROC 0.96 [0.95, 0.97]  \u2502 AUROC 0.98 [0.97, 0.99]  \u2502\n\u2502                       \u2502 F1: 0.85 [0.84, 0.86]    \u2502 F1: 0.89 [0.88, 0.91]    \u2502 F1: 0.92 [0.9, 0.94]     \u2502\n\u2502                       \u2502 AUPRC: 0.87 [0.87, 0.88] \u2502 AUPRC: 0.91 [0.9, 0.93]  \u2502 AUPRC: 0.93 [0.91, 0.95] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 CatBoost              \u2502 AUROC 0.94 [0.93, 0.94]  \u2502 AUROC 0.96 [0.94, 0.97]  \u2502 AUROC 0.97 [0.97, 0.98]  \u2502\n\u2502                       \u2502 F1: 0.85 [0.84, 0.85]    \u2502 F1: 0.88 [0.87, 0.91]    \u2502 F1: 0.91 [0.9, 0.91]     \u2502\n\u2502                       \u2502 AUPRC: 0.87 [0.87, 0.88] \u2502 AUPRC: 0.9 [0.89, 0.93]  \u2502 AUPRC: 0.92 [0.92, 0.92] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 NeuralNetTorch        \u2502 AUROC 0.93 [0.93, 0.94]  \u2502 AUROC 0.95 [0.94, 0.96]  \u2502 AUROC 0.98 [0.96, 0.99]  \u2502\n\u2502                       \u2502 F1: 0.85 [0.84, 0.85]    \u2502 F1: 0.88 [0.86, 0.91]    \u2502 F1: 0.92 [0.9, 0.94]     \u2502\n\u2502                       \u2502 AUPRC: 0.87 [0.87, 0.88] \u2502 AUPRC: 0.9 [0.88, 0.92]  \u2502 AUPRC: 0.93 [0.91, 0.94] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 XGBoost               \u2502 AUROC 0.93 [0.93, 0.93]  \u2502 AUROC 0.95 [0.94, 0.97]  \u2502 AUROC 0.98 [0.98, 0.99]  \u2502\n\u2502                       \u2502 F1: 0.85 [0.84, 0.85]    \u2502 F1: 0.88 [0.86, 0.91]    \u2502 F1: 0.92 [0.91, 0.93]    \u2502\n\u2502                       \u2502 AUPRC: 0.87 [0.87, 0.88] \u2502 AUPRC: 0.9 [0.88, 0.93]  \u2502 AUPRC: 0.93 [0.92, 0.94] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 LightGBMXT            \u2502 AUROC 0.93 [0.93, 0.93]  \u2502 AUROC 0.96 [0.94, 0.96]  \u2502 AUROC 0.98 [0.98, 0.98]  \u2502\n\u2502                       \u2502 F1: 0.84 [0.83, 0.85]    \u2502 F1: 0.88 [0.87, 0.9]     \u2502 F1: 0.92 [0.91, 0.92]    \u2502\n\u2502                       \u2502 AUPRC: 0.87 [0.86, 0.88] \u2502 AUPRC: 0.9 [0.89, 0.92]  \u2502 AUPRC: 0.93 [0.93, 0.94] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 NeuralNetFastAI       \u2502 AUROC 0.93 [0.92, 0.94]  \u2502 AUROC 0.96 [0.95, 0.96]  \u2502 AUROC 0.97 [0.97, 0.97]  \u2502\n\u2502                       \u2502 F1: 0.85 [0.83, 0.86]    \u2502 F1: 0.89 [0.88, 0.91]    \u2502 F1: 0.9 [0.9, 0.91]      \u2502\n\u2502                       \u2502 AUPRC: 0.87 [0.86, 0.88] \u2502 AUPRC: 0.9 [0.9, 0.92]   \u2502 AUPRC: 0.91 [0.91, 0.92] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 RandomForestEntr      \u2502 AUROC 0.92 [0.92, 0.93]  \u2502 AUROC 0.95 [0.93, 0.96]  \u2502 AUROC 1.0 [1.0, 1.0]     \u2502\n\u2502                       \u2502 F1: 0.84 [0.83, 0.85]    \u2502 F1: 0.86 [0.83, 0.88]    \u2502 F1: 1.0 [0.99, 1.0]      \u2502\n\u2502                       \u2502 AUPRC: 0.87 [0.86, 0.87] \u2502 AUPRC: 0.89 [0.86, 0.91] \u2502 AUPRC: 1.0 [1.0, 1.0]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 RandomForestGini      \u2502 AUROC 0.92 [0.92, 0.93]  \u2502 AUROC 0.95 [0.93, 0.96]  \u2502 AUROC 1.0 [1.0, 1.0]     \u2502\n\u2502                       \u2502 F1: 0.84 [0.83, 0.85]    \u2502 F1: 0.86 [0.83, 0.89]    \u2502 F1: 1.0 [0.99, 1.0]      \u2502\n\u2502                       \u2502 AUPRC: 0.87 [0.86, 0.87] \u2502 AUPRC: 0.89 [0.86, 0.92] \u2502 AUPRC: 1.0 [1.0, 1.0]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 LightGBM              \u2502 AUROC 0.92 [0.92, 0.93]  \u2502 AUROC 0.95 [0.94, 0.97]  \u2502 AUROC 0.99 [0.98, 0.99]  \u2502\n\u2502                       \u2502 F1: 0.84 [0.82, 0.85]    \u2502 F1: 0.88 [0.86, 0.9]     \u2502 F1: 0.93 [0.92, 0.94]    \u2502\n\u2502                       \u2502 AUPRC: 0.87 [0.85, 0.88] \u2502 AUPRC: 0.9 [0.88, 0.92]  \u2502 AUPRC: 0.94 [0.93, 0.95] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ExtraTreesEntr        \u2502 AUROC 0.92 [0.92, 0.93]  \u2502 AUROC 0.95 [0.93, 0.96]  \u2502 AUROC 1.0 [1.0, 1.0]     \u2502\n\u2502                       \u2502 F1: 0.83 [0.82, 0.84]    \u2502 F1: 0.87 [0.83, 0.9]     \u2502 F1: 1.0 [0.99, 1.0]      \u2502\n\u2502                       \u2502 AUPRC: 0.86 [0.85, 0.86] \u2502 AUPRC: 0.89 [0.86, 0.92] \u2502 AUPRC: 1.0 [1.0, 1.0]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ExtraTreesGini        \u2502 AUROC 0.92 [0.92, 0.93]  \u2502 AUROC 0.95 [0.93, 0.96]  \u2502 AUROC 1.0 [1.0, 1.0]     \u2502\n\u2502                       \u2502 F1: 0.83 [0.82, 0.83]    \u2502 F1: 0.87 [0.84, 0.89]    \u2502 F1: 1.0 [0.99, 1.0]      \u2502\n\u2502                       \u2502 AUPRC: 0.86 [0.85, 0.86] \u2502 AUPRC: 0.89 [0.87, 0.92] \u2502 AUPRC: 1.0 [1.0, 1.0]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 LightGBMLarge         \u2502 AUROC 0.91 [0.91, 0.92]  \u2502 AUROC 0.94 [0.93, 0.96]  \u2502 AUROC 1.0 [1.0, 1.0]     \u2502\n\u2502                       \u2502 F1: 0.81 [0.8, 0.82]     \u2502 F1: 0.86 [0.83, 0.88]    \u2502 F1: 0.98 [0.97, 0.98]    \u2502\n\u2502                       \u2502 AUPRC: 0.84 [0.84, 0.85] \u2502 AUPRC: 0.89 [0.86, 0.91] \u2502 AUPRC: 0.98 [0.97, 0.98] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SimpleRegressionModel \u2502 AUROC 0.9 [0.9, 0.91]    \u2502 AUROC 0.94 [0.93, 0.95]  \u2502 AUROC 0.94 [0.94, 0.94]  \u2502\n\u2502                       \u2502 F1: 0.81 [0.8, 0.81]     \u2502 F1: 0.86 [0.84, 0.89]    \u2502 F1: 0.87 [0.86, 0.87]    \u2502\n\u2502                       \u2502 AUPRC: 0.84 [0.84, 0.84] \u2502 AUPRC: 0.89 [0.86, 0.91] \u2502 AUPRC: 0.89 [0.89, 0.9]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 KNeighborsUnif        \u2502 AUROC 0.83 [0.83, 0.84]  \u2502 AUROC 0.86 [0.83, 0.88]  \u2502 AUROC 0.93 [0.92, 0.93]  \u2502\n\u2502                       \u2502 F1: 0.77 [0.75, 0.79]    \u2502 F1: 0.78 [0.73, 0.81]    \u2502 F1: 0.83 [0.82, 0.83]    \u2502\n\u2502                       \u2502 AUPRC: 0.81 [0.8, 0.82]  \u2502 AUPRC: 0.82 [0.78, 0.84] \u2502 AUPRC: 0.86 [0.85, 0.86] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 KNeighborsDist        \u2502 AUROC 0.81 [0.8, 0.83]   \u2502 AUROC 0.83 [0.8, 0.85]   \u2502 AUROC 0.95 [0.95, 0.96]  \u2502\n\u2502                       \u2502 F1: 0.69 [0.66, 0.72]    \u2502 F1: 0.72 [0.68, 0.75]    \u2502 F1: 0.84 [0.84, 0.85]    \u2502\n\u2502                       \u2502 AUPRC: 0.76 [0.73, 0.78] \u2502 AUPRC: 0.78 [0.74, 0.8]  \u2502 AUPRC: 0.88 [0.87, 0.88] \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</pre> In\u00a0[17]: Copied! <pre>trainer.X_test\n</pre> trainer.X_test Out[17]: age at dx Sex T Stage N Stage Stage Dose EGFRI HPV Combined Disease Site 430 89.6 Male T1b N0 I 51.0 0 Unknown larynx 488 43.6 Male T4a N0 IVA 70.0 0 1.0 oropharynx 1643 52.3 Male T1 N2a IVA 70.0 0 1.0 oropharynx 1059 54.1 Male T3 N2b IVA 70.0 0 Unknown lip &amp; oral cavity 1184 55.3 Male T2 N1 III 70.0 0 1.0 oropharynx ... ... ... ... ... ... ... ... ... ... 2408 51.1 Female T1 N0 I 70.0 0 Unknown nasopharynx 55 55.4 Male T1 N0 I 60.0 0 Unknown larynx 1651 38.5 Male T1b N0 I 70.0 0 Unknown larynx 2308 76.2 Male T1b N0 I 66.0 0 0.0 larynx 2005 65.9 Male T2 N2b IVA 64.0 0 Unknown hypopharynx <p>511 rows \u00d7 9 columns</p> In\u00a0[18]: Copied! <pre>from jarvais.explainer import Explainer\n\nsensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}\n\nexp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features)\nexp.run()\n</pre> from jarvais.explainer import Explainer  sensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}  exp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features) exp.run() <pre>Possible Bias in N Stage:\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.048\nModel:                            OLS   Adj. R-squared:                  0.033\nMethod:                 Least Squares   F-statistic:                     3.150\nDate:                Wed, 29 Jan 2025   Prob (F-statistic):            0.00173\nTime:                        13:57:17   Log-Likelihood:                -447.67\nNo. Observations:                 511   AIC:                             913.3\nDf Residuals:                     502   BIC:                             951.5\nDf Model:                           8                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst             0.2612      0.058      4.535      0.000       0.148       0.374\nN Stage_N0       -0.0992      0.069     -1.429      0.153      -0.236       0.037\nN Stage_N1        0.1099      0.088      1.243      0.215      -0.064       0.284\nN Stage_N2        0.0043      0.112      0.038      0.969      -0.215       0.224\nN Stage_N2a       0.1765      0.143      1.233      0.218      -0.105       0.458\nN Stage_N2b       0.2057      0.075      2.728      0.007       0.058       0.354\nN Stage_N2c       0.1161      0.081      1.439      0.151      -0.042       0.275\nN Stage_N3        0.2206      0.156      1.410      0.159      -0.087       0.528\nN Stage_N3b      -0.2286      0.268     -0.851      0.395      -0.756       0.299\nN Stage_Other    -0.2442      0.375     -0.651      0.515      -0.981       0.493\n==============================================================================\nOmnibus:                      303.295   Durbin-Watson:                   1.768\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1884.998\nSkew:                           2.681   Prob(JB):                         0.00\nKurtosis:                      10.732   Cond. No.                     4.69e+15\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 2.88e-29. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n</pre> <pre>Subgroup Analysis(N Stage)\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                              \u2502 N0                   \u2502 N1                  \u2502 N2                 \u2502 N2a                \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 mean_prediction              \u2502 0.1092896174863388   \u2502 0.45901639344262296 \u2502 0.9333333333333333 \u2502 0.4375             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 false_positive_rate          \u2502 0.031446540880503145 \u2502 0.21212121212121213 \u2502 0.5                \u2502 0.2222222222222222 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Relative mean_prediction     \u2502 1.000 \u2705             \u2502 4.200 \u2705            \u2502 8.540 \u2705           \u2502 4.003 \u2705           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Relative false_positive_rate \u2502 1.000 \u2705             \u2502 6.745 \u2705            \u2502 15.900 \u2705          \u2502 7.067 \u2705           \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\nPossible Bias in Disease Site:\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.062\nModel:                            OLS   Adj. R-squared:                  0.049\nMethod:                 Least Squares   F-statistic:                     4.786\nDate:                Wed, 29 Jan 2025   Prob (F-statistic):           3.15e-05\nTime:                        13:57:17   Log-Likelihood:                -443.70\nNo. Observations:                 511   AIC:                             903.4\nDf Residuals:                     503   BIC:                             937.3\nDf Model:                           7                                         \nCovariance Type:            nonrobust                                         \n==================================================================================================\n                                     coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------------------------\nconst                              0.3774      0.055      6.853      0.000       0.269       0.486\nDisease Site_Other                 0.0167      0.236      0.071      0.944      -0.446       0.480\nDisease Site_hypopharynx          -0.1231      0.109     -1.134      0.258      -0.336       0.090\nDisease Site_larynx               -0.2261      0.069     -3.300      0.001      -0.361      -0.092\nDisease Site_lip &amp; oral cavity     0.1389      0.201      0.690      0.491      -0.257       0.535\nDisease Site_nasal cavity          0.3830      0.189      2.022      0.044       0.011       0.755\nDisease Site_nasopharynx          -0.1892      0.084     -2.239      0.026      -0.355      -0.023\nDisease Site_oropharynx            0.0565      0.064      0.876      0.382      -0.070       0.183\nDisease Site_paranasal sinus       0.3208      0.236      1.361      0.174      -0.142       0.784\n==============================================================================\nOmnibus:                      307.483   Durbin-Watson:                   1.795\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             2049.479\nSkew:                           2.692   Prob(JB):                         0.00\nKurtosis:                      11.202   Cond. No.                     3.14e+15\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 6.99e-29. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n</pre> <pre>Subgroup Analysis(Disease Site)\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                              \u2502 Other    \u2502 hypopharynx         \u2502 larynx              \u2502 lip &amp; oral cavity   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 mean_prediction              \u2502 0.4      \u2502 0.4                 \u2502 0.11392405063291139 \u2502 0.42857142857142855 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 false_positive_rate          \u2502 0.25     \u2502 0.10526315789473684 \u2502 0.02962962962962963 \u2502 0.3333333333333333  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Relative mean_prediction     \u2502 0.664 \u2705 \u2502 0.664 \u2705            \u2502 0.189 \u2705            \u2502 0.711 \u2705            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Relative false_positive_rate \u2502 0.848 \u2705 \u2502 0.357 \u2705            \u2502 0.101 \u2705            \u2502 1.131 \u2705            \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\nSince target_class not specified, SHAP will explain predictions for each class\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [01:21&lt;00:00,  1.23it/s]\n</pre>"},{"location":"tutorials/regression/","title":"Regression","text":"In\u00a0[1]: Copied! <pre>import sys\n\nimport os\n\n# Get the absolute path of the project root directory\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Add the project root directory to the Python path\nsys.path.append(project_root)\n</pre> import sys  import os  # Get the absolute path of the project root directory project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Add the project root directory to the Python path sys.path.append(project_root) In\u00a0[2]: Copied! <pre>import pandas as pd\n\n\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Define the path to the data directory\ndata_dir = os.path.join(project_root, 'data')\n\n# Example: Access a specific data file in the data directory\ndata_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv')\ndf = pd.read_csv(data_file_path)\n</pre> import pandas as pd   project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Define the path to the data directory data_dir = os.path.join(project_root, 'data')  # Example: Access a specific data file in the data directory data_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv') df = pd.read_csv(data_file_path) In\u00a0[3]: Copied! <pre>from jarvais.analyzer import Analyzer\nfrom pprint import pprint\n\ndf.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)\n\nconfig = Analyzer.dry_run(df)\n\npprint(config)\n</pre> from jarvais.analyzer import Analyzer from pprint import pprint  df.drop(columns=[\"Study ID\", \"split\", \"survival_time\", \"death\"], inplace=True)  config = Analyzer.dry_run(df)  pprint(config) <pre>/home/joshua-siraj/Documents/CDI/jarvais/.pixi/envs/default/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> <pre>Config file not found. Creating custom...\nUsed a heuristic to define categorical and continuous columns. Please review!\n\n\nFeature Types:\n  - Categorical: ['N Stage', 'Disease Site', 'Stage', 'Sex', 'T Stage', 'HPV Combined', 'Chemotherapy', 'Dose', 'EGFRI']\n  - Continuous: ['age at dx']\n\n\nOutlier Analysis:\n  - Outliers found in N Stage: ['N3a: 14 out of 2552', 'NX: 1 out of 2552']\n  - Outliers found in Disease Site: ['esophagus: 22 out of 2552', 'salivary glands: 4 out of 2552']\n  - Outliers found in Stage: ['IV: 6 out of 2549', 'IIIC: 2 out of 2549', 'IIIA: 2 out of 2549', 'IIA: 1 out of 2549']\n  - No Outliers found in Sex\n  - Outliers found in T Stage: ['T2 (2): 1 out of 2552', 'TX: 1 out of 2552', 'T3 (2): 1 out of 2552']\n  - No Outliers found in HPV Combined\n  - No Outliers found in Chemotherapy\n  - Outliers found in Dose: ['50.0: 9 out of 2552', '69.96: 2 out of 2552', '50.8: 1 out of 2552', '55.0: 1 out of 2552', '53.55: 1 out of 2552', '59.4: 1 out of 2552']\n  - No Outliers found in EGFRI\n\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                      \u2502                   \u2502 Missing   \u2502 Overall     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 n                    \u2502                   \u2502           \u2502 2552        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 age at dx, mean (SD) \u2502                   \u2502 0         \u2502 62.0 (11.7) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 N Stage, n (%)       \u2502 N0                \u2502           \u2502 914 (35.8)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N1                \u2502           \u2502 260 (10.2)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2                \u2502           \u2502 161 (6.3)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2a               \u2502           \u2502 75 (2.9)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2b               \u2502           \u2502 585 (22.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2c               \u2502           \u2502 409 (16.0)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3                \u2502           \u2502 106 (4.2)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3a               \u2502           \u2502 14 (0.5)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3b               \u2502           \u2502 27 (1.1)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 NX                \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Disease Site, n (%)  \u2502 esophagus         \u2502           \u2502 22 (0.9)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 hypopharynx       \u2502           \u2502 143 (5.6)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 larynx            \u2502           \u2502 727 (28.5)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 lip &amp; oral cavity \u2502           \u2502 82 (3.2)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasal cavity      \u2502           \u2502 51 (2.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasopharynx       \u2502           \u2502 321 (12.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 oropharynx        \u2502           \u2502 1176 (46.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 paranasal sinus   \u2502           \u2502 26 (1.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 salivary glands   \u2502           \u2502 4 (0.2)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Stage, n (%)         \u2502 0                 \u2502           \u2502 37 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 I                 \u2502           \u2502 289 (11.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 II                \u2502           \u2502 323 (12.7)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IIA               \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 III               \u2502           \u2502 474 (18.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IIIA              \u2502           \u2502 2 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IIIC              \u2502           \u2502 2 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IV                \u2502           \u2502 6 (0.2)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVA               \u2502           \u2502 1187 (46.5) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVB               \u2502           \u2502 228 (8.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 None              \u2502           \u2502 3 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sex, n (%)           \u2502 Female            \u2502           \u2502 513 (20.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Male              \u2502           \u2502 2039 (79.9) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 T Stage, n (%)       \u2502 T1                \u2502           \u2502 361 (14.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1a               \u2502           \u2502 147 (5.8)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1b               \u2502           \u2502 68 (2.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T2                \u2502           \u2502 747 (29.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T2 (2)            \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T3                \u2502           \u2502 704 (27.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T3 (2)            \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4                \u2502           \u2502 96 (3.8)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4a               \u2502           \u2502 295 (11.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4b               \u2502           \u2502 95 (3.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 TX                \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Tis               \u2502           \u2502 36 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 HPV Combined, n (%)  \u2502 0.0               \u2502           \u2502 437 (17.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1.0               \u2502           \u2502 840 (32.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 None              \u2502           \u2502 1275 (50.0) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Chemotherapy, n (%)  \u2502 0                 \u2502           \u2502 1466 (57.4) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 1086 (42.6) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dose, n (%)          \u2502 50.0              \u2502           \u2502 9 (0.4)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 50.8              \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 51.0              \u2502           \u2502 177 (6.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 53.55             \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 55.0              \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 59.4              \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 60.0              \u2502           \u2502 288 (11.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 64.0              \u2502           \u2502 208 (8.2)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 66.0              \u2502           \u2502 68 (2.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 69.96             \u2502           \u2502 2 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 70.0              \u2502           \u2502 1796 (70.4) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 EGFRI, n (%)         \u2502 0                 \u2502           \u2502 2452 (96.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 100 (3.9)   \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n{'columns': {'categorical': ['N Stage',\n                             'Disease Site',\n                             'Stage',\n                             'Sex',\n                             'T Stage',\n                             'HPV Combined',\n                             'Chemotherapy',\n                             'Dose',\n                             'EGFRI'],\n             'continuous': ['age at dx'],\n             'date': [],\n             'other': []},\n 'mapping': {'Chemotherapy': {'0': '0', '1': '1'},\n             'Disease Site': {'esophagus': 'Other',\n                              'hypopharynx': 'hypopharynx',\n                              'larynx': 'larynx',\n                              'lip &amp; oral cavity': 'lip &amp; oral cavity',\n                              'nasal cavity': 'nasal cavity',\n                              'nasopharynx': 'nasopharynx',\n                              'oropharynx': 'oropharynx',\n                              'paranasal sinus': 'paranasal sinus',\n                              'salivary glands': 'Other'},\n             'Dose': {'50.0': 'Other',\n                      '50.8': 'Other',\n                      '51.0': '51.0',\n                      '53.55': 'Other',\n                      '55.0': 'Other',\n                      '59.4': 'Other',\n                      '60.0': '60.0',\n                      '64.0': '64.0',\n                      '66.0': '66.0',\n                      '69.96': 'Other',\n                      '70.0': '70.0'},\n             'EGFRI': {'0': '0', '1': '1'},\n             'HPV Combined': {'0.0': '0.0', '1.0': '1.0', 'nan': 'nan'},\n             'N Stage': {'N0': 'N0',\n                         'N1': 'N1',\n                         'N2': 'N2',\n                         'N2a': 'N2a',\n                         'N2b': 'N2b',\n                         'N2c': 'N2c',\n                         'N3': 'N3',\n                         'N3a': 'Other',\n                         'N3b': 'N3b',\n                         'NX': 'Other'},\n             'Sex': {'Female': 'Female', 'Male': 'Male'},\n             'Stage': {'0': '0',\n                       'I': 'I',\n                       'II': 'II',\n                       'IIA': 'Other',\n                       'III': 'III',\n                       'IIIA': 'Other',\n                       'IIIC': 'Other',\n                       'IV': 'Other',\n                       'IVA': 'IVA',\n                       'IVB': 'IVB',\n                       'nan': 'nan'},\n             'T Stage': {'T1': 'T1',\n                         'T1a': 'T1a',\n                         'T1b': 'T1b',\n                         'T2': 'T2',\n                         'T2 (2)': 'Other',\n                         'T3': 'T3',\n                         'T3 (2)': 'Other',\n                         'T4': 'T4',\n                         'T4a': 'T4a',\n                         'T4b': 'T4b',\n                         'TX': 'Other',\n                         'Tis': 'Tis'}},\n 'missingness_strategy': {'categorical': {'Chemotherapy': 'Unknown',\n                                          'Disease Site': 'Unknown',\n                                          'Dose': 'Unknown',\n                                          'EGFRI': 'Unknown',\n                                          'HPV Combined': 'Unknown',\n                                          'N Stage': 'Unknown',\n                                          'Sex': 'Unknown',\n                                          'Stage': 'Unknown',\n                                          'T Stage': 'Unknown'},\n                          'continuous': {'age at dx': 'median'}}}\n</pre> In\u00a0[4]: Copied! <pre>import yaml\nfrom pathlib import Path\n\nconfig['columns']['categorical'].remove('Dose')\nconfig['columns']['continuous'].append('Dose') \n\npprint(config)\n\nanalyzer_path = Path('outputs/analyzer')\nanalyzer_path.mkdir(parents=True, exist_ok=True)\n\nwith open(analyzer_path / 'config.yaml', 'w') as f:\n            yaml.dump(config, f)\n</pre> import yaml from pathlib import Path  config['columns']['categorical'].remove('Dose') config['columns']['continuous'].append('Dose')   pprint(config)  analyzer_path = Path('outputs/analyzer') analyzer_path.mkdir(parents=True, exist_ok=True)  with open(analyzer_path / 'config.yaml', 'w') as f:             yaml.dump(config, f) <pre>{'columns': {'categorical': ['N Stage',\n                             'Disease Site',\n                             'Stage',\n                             'Sex',\n                             'T Stage',\n                             'HPV Combined',\n                             'Chemotherapy',\n                             'EGFRI'],\n             'continuous': ['age at dx', 'Dose'],\n             'date': [],\n             'other': []},\n 'mapping': {'Chemotherapy': {'0': '0', '1': '1'},\n             'Disease Site': {'esophagus': 'Other',\n                              'hypopharynx': 'hypopharynx',\n                              'larynx': 'larynx',\n                              'lip &amp; oral cavity': 'lip &amp; oral cavity',\n                              'nasal cavity': 'nasal cavity',\n                              'nasopharynx': 'nasopharynx',\n                              'oropharynx': 'oropharynx',\n                              'paranasal sinus': 'paranasal sinus',\n                              'salivary glands': 'Other'},\n             'Dose': {'50.0': 'Other',\n                      '50.8': 'Other',\n                      '51.0': '51.0',\n                      '53.55': 'Other',\n                      '55.0': 'Other',\n                      '59.4': 'Other',\n                      '60.0': '60.0',\n                      '64.0': '64.0',\n                      '66.0': '66.0',\n                      '69.96': 'Other',\n                      '70.0': '70.0'},\n             'EGFRI': {'0': '0', '1': '1'},\n             'HPV Combined': {'0.0': '0.0', '1.0': '1.0', 'nan': 'nan'},\n             'N Stage': {'N0': 'N0',\n                         'N1': 'N1',\n                         'N2': 'N2',\n                         'N2a': 'N2a',\n                         'N2b': 'N2b',\n                         'N2c': 'N2c',\n                         'N3': 'N3',\n                         'N3a': 'Other',\n                         'N3b': 'N3b',\n                         'NX': 'Other'},\n             'Sex': {'Female': 'Female', 'Male': 'Male'},\n             'Stage': {'0': '0',\n                       'I': 'I',\n                       'II': 'II',\n                       'IIA': 'Other',\n                       'III': 'III',\n                       'IIIA': 'Other',\n                       'IIIC': 'Other',\n                       'IV': 'Other',\n                       'IVA': 'IVA',\n                       'IVB': 'IVB',\n                       'nan': 'nan'},\n             'T Stage': {'T1': 'T1',\n                         'T1a': 'T1a',\n                         'T1b': 'T1b',\n                         'T2': 'T2',\n                         'T2 (2)': 'Other',\n                         'T3': 'T3',\n                         'T3 (2)': 'Other',\n                         'T4': 'T4',\n                         'T4a': 'T4a',\n                         'T4b': 'T4b',\n                         'TX': 'Other',\n                         'Tis': 'Tis'}},\n 'missingness_strategy': {'categorical': {'Chemotherapy': 'Unknown',\n                                          'Disease Site': 'Unknown',\n                                          'Dose': 'Unknown',\n                                          'EGFRI': 'Unknown',\n                                          'HPV Combined': 'Unknown',\n                                          'N Stage': 'Unknown',\n                                          'Sex': 'Unknown',\n                                          'Stage': 'Unknown',\n                                          'T Stage': 'Unknown'},\n                          'continuous': {'age at dx': 'median'}}}\n</pre> In\u00a0[5]: Copied! <pre>from jarvais.analyzer import Analyzer\n\nanalyzer = Analyzer(df, target_variable='Dose', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')\n\nanalyzer.run()\n</pre> from jarvais.analyzer import Analyzer  analyzer = Analyzer(df, target_variable='Dose', output_dir='./outputs/analyzer', config='outputs/analyzer/config.yaml')  analyzer.run() <pre>Feature Types:\n  - Categorical: ['N Stage', 'Disease Site', 'Stage', 'Sex', 'T Stage', 'HPV Combined', 'Chemotherapy', 'EGFRI']\n  - Continuous: ['age at dx', 'Dose']\n\n\nOutlier Analysis:\n  - Outliers found in N Stage: ['N3a: 14 out of 2552', 'NX: 1 out of 2552']\n  - Outliers found in Disease Site: ['esophagus: 22 out of 2552', 'salivary glands: 4 out of 2552']\n  - Outliers found in Stage: ['IV: 6 out of 2549', 'IIIC: 2 out of 2549', 'IIIA: 2 out of 2549', 'IIA: 1 out of 2549']\n  - No Outliers found in Sex\n  - Outliers found in T Stage: ['T2 (2): 1 out of 2552', 'TX: 1 out of 2552', 'T3 (2): 1 out of 2552']\n  - No Outliers found in HPV Combined\n  - No Outliers found in Chemotherapy\n  - No Outliers found in EGFRI\n\nApplying changes from config...\n\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                      \u2502                   \u2502 Missing   \u2502 Overall     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 n                    \u2502                   \u2502           \u2502 2552        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 age at dx, mean (SD) \u2502                   \u2502 0         \u2502 62.0 (11.7) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dose, mean (SD)      \u2502                   \u2502 0         \u2502 66.9 (5.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 N Stage, n (%)       \u2502 N0                \u2502           \u2502 914 (35.8)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N1                \u2502           \u2502 260 (10.2)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2                \u2502           \u2502 161 (6.3)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2a               \u2502           \u2502 75 (2.9)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2b               \u2502           \u2502 585 (22.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2c               \u2502           \u2502 409 (16.0)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3                \u2502           \u2502 106 (4.2)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3b               \u2502           \u2502 27 (1.1)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Other             \u2502           \u2502 15 (0.6)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Disease Site, n (%)  \u2502 Other             \u2502           \u2502 26 (1.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 hypopharynx       \u2502           \u2502 143 (5.6)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 larynx            \u2502           \u2502 727 (28.5)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 lip &amp; oral cavity \u2502           \u2502 82 (3.2)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasal cavity      \u2502           \u2502 51 (2.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasopharynx       \u2502           \u2502 321 (12.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 oropharynx        \u2502           \u2502 1176 (46.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 paranasal sinus   \u2502           \u2502 26 (1.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Stage, n (%)         \u2502 0                 \u2502           \u2502 37 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 I                 \u2502           \u2502 289 (11.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 II                \u2502           \u2502 323 (12.7)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 III               \u2502           \u2502 474 (18.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVA               \u2502           \u2502 1187 (46.5) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVB               \u2502           \u2502 228 (8.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Other             \u2502           \u2502 11 (0.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Unknown           \u2502           \u2502 3 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sex, n (%)           \u2502 Female            \u2502           \u2502 513 (20.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Male              \u2502           \u2502 2039 (79.9) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 T Stage, n (%)       \u2502 Other             \u2502           \u2502 3 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1                \u2502           \u2502 361 (14.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1a               \u2502           \u2502 147 (5.8)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1b               \u2502           \u2502 68 (2.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T2                \u2502           \u2502 747 (29.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T3                \u2502           \u2502 704 (27.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4                \u2502           \u2502 96 (3.8)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4a               \u2502           \u2502 295 (11.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4b               \u2502           \u2502 95 (3.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Tis               \u2502           \u2502 36 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 HPV Combined, n (%)  \u2502 0.0               \u2502           \u2502 437 (17.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1.0               \u2502           \u2502 840 (32.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Unknown           \u2502           \u2502 1275 (50.0) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Chemotherapy, n (%)  \u2502 0                 \u2502           \u2502 1466 (57.4) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 1086 (42.6) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 EGFRI, n (%)         \u2502 0                 \u2502           \u2502 2452 (96.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 100 (3.9)   \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</pre> In\u00a0[6]: Copied! <pre>from jarvais.trainer import TrainerSupervised\n\ndf = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)\n\ntrainer = TrainerSupervised(task='regression', output_dir='./outputs/trainer')\ntrainer.run(df, 'Dose')\n</pre> from jarvais.trainer import TrainerSupervised  df = pd.read_csv('./outputs/analyzer/updated_data.csv', index_col=0)  trainer = TrainerSupervised(task='regression', output_dir='./outputs/trainer') trainer.run(df, 'Dose') <pre>Training fold 1/5...\nFold 1 score: 0.6415226629823407\nTraining fold 2/5...\nFold 2 score: 0.6354727494158782\nTraining fold 3/5...\nFold 3 score: 0.6784427999882303\nTraining fold 4/5...\nFold 4 score: 0.6340258425139446\nTraining fold 5/5...\nFold 5 score: 0.6137623216481571\n\nModel Leaderboard (Displays values in \"mean [min, max]\" format across training folds)\n------------------------------------------------------------------------------------\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 model                 \u2502 score_test                 \u2502 score_val                  \u2502 score_train                \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 WeightedEnsemble_L2   \u2502 R2 0.62 [0.62, 0.63]       \u2502 R2 0.64 [0.61, 0.68]       \u2502 R2 0.7 [0.69, 0.74]        \u2502\n\u2502                       \u2502 RMSE: -3.48 [-3.49, -3.46] \u2502 RMSE: -3.36 [-3.58, -3.19] \u2502 RMSE: -3.05 [-3.15, -2.87] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 CatBoost              \u2502 R2 0.62 [0.61, 0.64]       \u2502 R2 0.63 [0.6, 0.67]        \u2502 R2 0.67 [0.67, 0.68]       \u2502\n\u2502                       \u2502 RMSE: -3.48 [-3.54, -3.42] \u2502 RMSE: -3.43 [-3.63, -3.25] \u2502 RMSE: -3.2 [-3.23, -3.17]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 LightGBMXT            \u2502 R2 0.62 [0.61, 0.63]       \u2502 R2 0.63 [0.6, 0.66]        \u2502 R2 0.67 [0.65, 0.7]        \u2502\n\u2502                       \u2502 RMSE: -3.51 [-3.54, -3.46] \u2502 RMSE: -3.42 [-3.66, -3.26] \u2502 RMSE: -3.2 [-3.31, -3.08]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 NeuralNetFastAI       \u2502 R2 0.61 [0.6, 0.62]        \u2502 R2 0.63 [0.61, 0.67]       \u2502 R2 0.67 [0.64, 0.69]       \u2502\n\u2502                       \u2502 RMSE: -3.53 [-3.57, -3.5]  \u2502 RMSE: -3.41 [-3.61, -3.23] \u2502 RMSE: -3.21 [-3.37, -3.13] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 XGBoost               \u2502 R2 0.6 [0.59, 0.62]        \u2502 R2 0.6 [0.54, 0.65]        \u2502 R2 0.74 [0.7, 0.78]        \u2502\n\u2502                       \u2502 RMSE: -3.58 [-3.63, -3.51] \u2502 RMSE: -3.53 [-3.8, -3.33]  \u2502 RMSE: -2.84 [-3.04, -2.6]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 LightGBM              \u2502 R2 0.6 [0.59, 0.61]        \u2502 R2 0.61 [0.58, 0.66]       \u2502 R2 0.72 [0.69, 0.73]       \u2502\n\u2502                       \u2502 RMSE: -3.6 [-3.63, -3.53]  \u2502 RMSE: -3.5 [-3.7, -3.29]   \u2502 RMSE: -2.97 [-3.1, -2.91]  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ExtraTreesMSE         \u2502 R2 0.56 [0.54, 0.58]       \u2502 R2 0.55 [0.51, 0.61]       \u2502 R2 0.93 [0.93, 0.94]       \u2502\n\u2502                       \u2502 RMSE: -3.78 [-3.86, -3.7]  \u2502 RMSE: -3.75 [-3.96, -3.49] \u2502 RMSE: -1.45 [-1.49, -1.42] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 RandomForestMSE       \u2502 R2 0.56 [0.54, 0.57]       \u2502 R2 0.54 [0.48, 0.6]        \u2502 R2 0.93 [0.93, 0.94]       \u2502\n\u2502                       \u2502 RMSE: -3.75 [-3.86, -3.7]  \u2502 RMSE: -3.8 [-4.05, -3.58]  \u2502 RMSE: -1.46 [-1.51, -1.41] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 LightGBMLarge         \u2502 R2 0.55 [0.53, 0.56]       \u2502 R2 0.54 [0.51, 0.58]       \u2502 R2 0.84 [0.81, 0.86]       \u2502\n\u2502                       \u2502 RMSE: -3.82 [-3.87, -3.78] \u2502 RMSE: -3.78 [-3.87, -3.63] \u2502 RMSE: -2.22 [-2.41, -2.06] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 NeuralNetTorch        \u2502 R2 0.55 [0.52, 0.56]       \u2502 R2 0.55 [0.51, 0.59]       \u2502 R2 0.64 [0.62, 0.66]       \u2502\n\u2502                       \u2502 RMSE: -3.83 [-3.91, -3.75] \u2502 RMSE: -3.76 [-4.05, -3.6]  \u2502 RMSE: -3.35 [-3.42, -3.26] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SimpleRegressionModel \u2502 R2 0.45 [0.44, 0.45]       \u2502 R2 0.44 [0.43, 0.46]       \u2502 R2 0.45 [0.45, 0.45]       \u2502\n\u2502                       \u2502 RMSE: -4.22 [-4.24, -4.2]  \u2502 RMSE: -4.19 [-4.31, -4.13] \u2502 RMSE: -4.15 [-4.16, -4.12] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 KNeighborsDist        \u2502 R2 -0.27 [-0.34, -0.23]    \u2502 R2 -0.27 [-0.35, -0.21]    \u2502 R2 0.33 [0.3, 0.36]        \u2502\n\u2502                       \u2502 RMSE: -6.4 [-6.56, -6.29]  \u2502 RMSE: -6.31 [-6.66, -6.06] \u2502 RMSE: -4.59 [-4.68, -4.47] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 KNeighborsUnif        \u2502 R2 -0.15 [-0.16, -0.13]    \u2502 R2 -0.13 [-0.18, -0.06]    \u2502 R2 0.22 [0.21, 0.23]       \u2502\n\u2502                       \u2502 RMSE: -6.07 [-6.11, -6.02] \u2502 RMSE: -5.97 [-6.25, -5.76] \u2502 RMSE: -4.97 [-4.99, -4.89] \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</pre> In\u00a0[7]: Copied! <pre>from jarvais.explainer import Explainer\n\nsensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}\n\nexp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features)\nexp.run()\n</pre> from jarvais.explainer import Explainer  sensitive_features = {k: trainer.X_test[k] for k in ['N Stage', 'Disease Site', 'Sex']}  exp = Explainer.from_trainer(trainer, sensitive_features=sensitive_features) exp.run() <pre>Possible Bias in N Stage:\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.258\nModel:                            OLS   Adj. R-squared:                  0.246\nMethod:                 Least Squares   F-statistic:                     21.85\nDate:                Fri, 31 Jan 2025   Prob (F-statistic):           1.30e-28\nTime:                        13:25:56   Log-Likelihood:                -1146.7\nNo. Observations:                 511   AIC:                             2311.\nDf Residuals:                     502   BIC:                             2350.\nDf Model:                           8                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nconst             1.1967      0.257      4.648      0.000       0.691       1.703\nN Stage_N0        2.6057      0.296      8.814      0.000       2.025       3.187\nN Stage_N1        0.8848      0.385      2.301      0.022       0.129       1.640\nN Stage_N2       -0.9873      0.473     -2.089      0.037      -1.916      -0.059\nN Stage_N2a       1.5738      0.772      2.038      0.042       0.056       3.091\nN Stage_N2b      -0.0314      0.325     -0.096      0.923      -0.671       0.608\nN Stage_N2c      -0.0619      0.338     -0.183      0.854      -0.725       0.601\nN Stage_N3       -0.7237      0.501     -1.445      0.149      -1.707       0.260\nN Stage_N3b      -1.0758      1.479     -0.727      0.467      -3.981       1.830\nN Stage_Other    -0.9874      1.479     -0.668      0.505      -3.893       1.918\n==============================================================================\nOmnibus:                      215.697   Durbin-Watson:                   2.047\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1007.820\nSkew:                           1.853   Prob(JB):                    1.43e-219\nKurtosis:                       8.797   Cond. No.                     5.59e+15\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 2.06e-29. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n</pre> <pre>Subgroup Analysis(N Stage)\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                          \u2502 N0                \u2502 N1                \u2502 N2                \u2502 N2a               \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 mean_prediction          \u2502 63.06154393438083 \u2502 68.14472271845891 \u2502 69.90058333785446 \u2502 68.12633037567139 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Relative mean_prediction \u2502 1.000 \u2705          \u2502 1.081 \u2705          \u2502 1.108 \u2705          \u2502 1.080 \u2705          \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\nPossible Bias in Disease Site:\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.175\nModel:                            OLS   Adj. R-squared:                  0.163\nMethod:                 Least Squares   F-statistic:                     15.23\nDate:                Fri, 31 Jan 2025   Prob (F-statistic):           4.11e-18\nTime:                        13:25:56   Log-Likelihood:                -1173.9\nNo. Observations:                 511   AIC:                             2364.\nDf Residuals:                     503   BIC:                             2398.\nDf Model:                           7                                         \nCovariance Type:            nonrobust                                         \n==================================================================================================\n                                     coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------------------------\nconst                              2.4077      0.236     10.183      0.000       1.943       2.872\nDisease Site_Other                -0.8503      1.258     -0.676      0.499      -3.321       1.621\nDisease Site_hypopharynx          -0.7767      0.457     -1.701      0.090      -1.674       0.120\nDisease Site_larynx                0.9168      0.290      3.160      0.002       0.347       1.487\nDisease Site_lip &amp; oral cavity     2.0480      0.545      3.759      0.000       0.978       3.118\nDisease Site_nasal cavity          0.2696      0.619      0.436      0.663      -0.946       1.485\nDisease Site_nasopharynx          -2.1063      0.371     -5.677      0.000      -2.835      -1.377\nDisease Site_oropharynx           -0.6931      0.276     -2.507      0.012      -1.236      -0.150\nDisease Site_paranasal sinus       3.5996      1.096      3.285      0.001       1.447       5.752\n==============================================================================\nOmnibus:                      176.191   Durbin-Watson:                   2.106\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              598.255\nSkew:                           1.597   Prob(JB):                    1.23e-130\nKurtosis:                       7.231   Cond. No.                     3.10e+15\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 7.04e-29. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n</pre> <pre>Subgroup Analysis(Disease Site)\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                          \u2502 Other             \u2502 hypopharynx      \u2502 larynx             \u2502 lip &amp; oral cavity   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 mean_prediction          \u2502 68.44259134928386 \u2502 67.9584831237793 \u2502 62.553679077713575 \u2502 66.02217885067589   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Relative mean_prediction \u2502 0.998 \u2705          \u2502 0.991 \u2705         \u2502 0.912 \u2705           \u2502 0.963 \u2705            \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n\n</pre>"},{"location":"tutorials/survival/","title":"Survival","text":"In\u00a0[1]: Copied! <pre>import sys\n\nimport os\n\n# Get the absolute path of the project root directory\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Add the project root directory to the Python path\nsys.path.append(project_root)\n</pre> import sys  import os  # Get the absolute path of the project root directory project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Add the project root directory to the Python path sys.path.append(project_root) In\u00a0[2]: Copied! <pre>import pandas as pd\n\n\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n\n# Define the path to the data directory\ndata_dir = os.path.join(project_root, 'data')\n\n# Example: Access a specific data file in the data directory\ndata_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv')\ndf = pd.read_csv(data_file_path)\n</pre> import pandas as pd   project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # Define the path to the data directory data_dir = os.path.join(project_root, 'data')  # Example: Access a specific data file in the data directory data_file_path = os.path.join(data_dir, 'RADCURE_challenge_clinical.csv') df = pd.read_csv(data_file_path) In\u00a0[\u00a0]: Copied! <pre>from jarvais.analyzer import Analyzer\nfrom pprint import pprint\n\ndf.drop(columns=[\"Study ID\", \"split\"], inplace=True)\ndf.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)\n\nconfig = Analyzer.dry_run(df)\n\npprint(config)\n</pre> from jarvais.analyzer import Analyzer from pprint import pprint  df.drop(columns=[\"Study ID\", \"split\"], inplace=True) df.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)  config = Analyzer.dry_run(df)  pprint(config) <pre>Config file not found. Creating custom...\nUsed a heuristic to define categorical and continuous columns. Please review!\n\n\nFeature Types:\n  - Categorical: ['T Stage', 'Stage', 'Disease Site', 'Sex', 'N Stage', 'Dose', 'EGFRI', 'event', 'Chemotherapy', 'HPV Combined']\n  - Continuous: ['time', 'age at dx']\n\n\nOutlier Analysis:\n  - Outliers found in T Stage: ['T2 (2): 1 out of 2552', 'TX: 1 out of 2552', 'T3 (2): 1 out of 2552']\n  - Outliers found in Stage: ['IV: 6 out of 2549', 'IIIC: 2 out of 2549', 'IIIA: 2 out of 2549', 'IIA: 1 out of 2549']\n  - Outliers found in Disease Site: ['esophagus: 22 out of 2552', 'salivary glands: 4 out of 2552']\n  - No Outliers found in Sex\n  - Outliers found in N Stage: ['N3a: 14 out of 2552', 'NX: 1 out of 2552']\n  - Outliers found in Dose: ['50.0: 9 out of 2552', '69.96: 2 out of 2552', '50.8: 1 out of 2552', '55.0: 1 out of 2552', '53.55: 1 out of 2552', '59.4: 1 out of 2552']\n  - No Outliers found in EGFRI\n  - No Outliers found in event\n  - No Outliers found in Chemotherapy\n  - No Outliers found in HPV Combined\n\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                      \u2502                   \u2502 Missing   \u2502 Overall     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 n                    \u2502                   \u2502           \u2502 2552        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 time, mean (SD)      \u2502                   \u2502 0         \u2502 4.8 (2.8)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 age at dx, mean (SD) \u2502                   \u2502 0         \u2502 62.0 (11.7) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 T Stage, n (%)       \u2502 T1                \u2502           \u2502 361 (14.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1a               \u2502           \u2502 147 (5.8)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1b               \u2502           \u2502 68 (2.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T2                \u2502           \u2502 747 (29.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T2 (2)            \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T3                \u2502           \u2502 704 (27.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T3 (2)            \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4                \u2502           \u2502 96 (3.8)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4a               \u2502           \u2502 295 (11.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4b               \u2502           \u2502 95 (3.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 TX                \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Tis               \u2502           \u2502 36 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Stage, n (%)         \u2502 0                 \u2502           \u2502 37 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 I                 \u2502           \u2502 289 (11.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 II                \u2502           \u2502 323 (12.7)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IIA               \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 III               \u2502           \u2502 474 (18.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IIIA              \u2502           \u2502 2 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IIIC              \u2502           \u2502 2 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IV                \u2502           \u2502 6 (0.2)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVA               \u2502           \u2502 1187 (46.5) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVB               \u2502           \u2502 228 (8.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 None              \u2502           \u2502 3 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Disease Site, n (%)  \u2502 esophagus         \u2502           \u2502 22 (0.9)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 hypopharynx       \u2502           \u2502 143 (5.6)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 larynx            \u2502           \u2502 727 (28.5)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 lip &amp; oral cavity \u2502           \u2502 82 (3.2)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasal cavity      \u2502           \u2502 51 (2.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasopharynx       \u2502           \u2502 321 (12.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 oropharynx        \u2502           \u2502 1176 (46.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 paranasal sinus   \u2502           \u2502 26 (1.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 salivary glands   \u2502           \u2502 4 (0.2)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sex, n (%)           \u2502 Female            \u2502           \u2502 513 (20.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Male              \u2502           \u2502 2039 (79.9) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 N Stage, n (%)       \u2502 N0                \u2502           \u2502 914 (35.8)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N1                \u2502           \u2502 260 (10.2)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2                \u2502           \u2502 161 (6.3)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2a               \u2502           \u2502 75 (2.9)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2b               \u2502           \u2502 585 (22.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2c               \u2502           \u2502 409 (16.0)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3                \u2502           \u2502 106 (4.2)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3a               \u2502           \u2502 14 (0.5)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3b               \u2502           \u2502 27 (1.1)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 NX                \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dose, n (%)          \u2502 50.0              \u2502           \u2502 9 (0.4)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 50.8              \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 51.0              \u2502           \u2502 177 (6.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 53.55             \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 55.0              \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 59.4              \u2502           \u2502 1 (0.0)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 60.0              \u2502           \u2502 288 (11.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 64.0              \u2502           \u2502 208 (8.2)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 66.0              \u2502           \u2502 68 (2.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 69.96             \u2502           \u2502 2 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 70.0              \u2502           \u2502 1796 (70.4) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 EGFRI, n (%)         \u2502 0                 \u2502           \u2502 2452 (96.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 100 (3.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 event, n (%)         \u2502 0                 \u2502           \u2502 1674 (65.6) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 878 (34.4)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Chemotherapy, n (%)  \u2502 0                 \u2502           \u2502 1466 (57.4) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 1086 (42.6) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 HPV Combined, n (%)  \u2502 0.0               \u2502           \u2502 437 (17.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1.0               \u2502           \u2502 840 (32.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 None              \u2502           \u2502 1275 (50.0) \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n{'columns': {'categorical': ['T Stage',\n                             'Stage',\n                             'Disease Site',\n                             'Sex',\n                             'N Stage',\n                             'Dose',\n                             'EGFRI',\n                             'event',\n                             'Chemotherapy',\n                             'HPV Combined'],\n             'continuous': ['time', 'age at dx'],\n             'date': [],\n             'other': []},\n 'mapping': {'Chemotherapy': {'0': '0', '1': '1'},\n             'Disease Site': {'esophagus': 'Other',\n                              'hypopharynx': 'hypopharynx',\n                              'larynx': 'larynx',\n                              'lip &amp; oral cavity': 'lip &amp; oral cavity',\n                              'nasal cavity': 'nasal cavity',\n                              'nasopharynx': 'nasopharynx',\n                              'oropharynx': 'oropharynx',\n                              'paranasal sinus': 'paranasal sinus',\n                              'salivary glands': 'Other'},\n             'Dose': {'50.0': 'Other',\n                      '50.8': 'Other',\n                      '51.0': '51.0',\n                      '53.55': 'Other',\n                      '55.0': 'Other',\n                      '59.4': 'Other',\n                      '60.0': '60.0',\n                      '64.0': '64.0',\n                      '66.0': '66.0',\n                      '69.96': 'Other',\n                      '70.0': '70.0'},\n             'EGFRI': {'0': '0', '1': '1'},\n             'HPV Combined': {'0.0': '0.0', '1.0': '1.0', 'nan': 'nan'},\n             'N Stage': {'N0': 'N0',\n                         'N1': 'N1',\n                         'N2': 'N2',\n                         'N2a': 'N2a',\n                         'N2b': 'N2b',\n                         'N2c': 'N2c',\n                         'N3': 'N3',\n                         'N3a': 'Other',\n                         'N3b': 'N3b',\n                         'NX': 'Other'},\n             'Sex': {'Female': 'Female', 'Male': 'Male'},\n             'Stage': {'0': '0',\n                       'I': 'I',\n                       'II': 'II',\n                       'IIA': 'Other',\n                       'III': 'III',\n                       'IIIA': 'Other',\n                       'IIIC': 'Other',\n                       'IV': 'Other',\n                       'IVA': 'IVA',\n                       'IVB': 'IVB',\n                       'nan': 'nan'},\n             'T Stage': {'T1': 'T1',\n                         'T1a': 'T1a',\n                         'T1b': 'T1b',\n                         'T2': 'T2',\n                         'T2 (2)': 'Other',\n                         'T3': 'T3',\n                         'T3 (2)': 'Other',\n                         'T4': 'T4',\n                         'T4a': 'T4a',\n                         'T4b': 'T4b',\n                         'TX': 'Other',\n                         'Tis': 'Tis'},\n             'event': {'0': '0', '1': '1'}},\n 'missingness_strategy': {'categorical': {'Chemotherapy': 'Unknown',\n                                          'Disease Site': 'Unknown',\n                                          'Dose': 'Unknown',\n                                          'EGFRI': 'Unknown',\n                                          'HPV Combined': 'Unknown',\n                                          'N Stage': 'Unknown',\n                                          'Sex': 'Unknown',\n                                          'Stage': 'Unknown',\n                                          'T Stage': 'Unknown',\n                                          'event': 'Unknown'},\n                          'continuous': {'age at dx': 'median',\n                                         'time': 'median'}}}\n</pre> In\u00a0[4]: Copied! <pre>import yaml\nfrom pathlib import Path\n\nconfig['columns']['categorical'].remove('Dose')\nconfig['columns']['continuous'].append('Dose') \n\npprint(config)\n\nanalyzer_path = Path('radcure_outputs/analyzer')\nanalyzer_path.mkdir(parents=True, exist_ok=True)\n\nwith open(analyzer_path / 'config.yaml', 'w') as f:\n            yaml.dump(config, f)\n</pre> import yaml from pathlib import Path  config['columns']['categorical'].remove('Dose') config['columns']['continuous'].append('Dose')   pprint(config)  analyzer_path = Path('radcure_outputs/analyzer') analyzer_path.mkdir(parents=True, exist_ok=True)  with open(analyzer_path / 'config.yaml', 'w') as f:             yaml.dump(config, f) <pre>{'columns': {'categorical': ['T Stage',\n                             'Stage',\n                             'Disease Site',\n                             'Sex',\n                             'N Stage',\n                             'EGFRI',\n                             'event',\n                             'Chemotherapy',\n                             'HPV Combined'],\n             'continuous': ['time', 'age at dx', 'Dose'],\n             'date': [],\n             'other': []},\n 'mapping': {'Chemotherapy': {'0': '0', '1': '1'},\n             'Disease Site': {'esophagus': 'Other',\n                              'hypopharynx': 'hypopharynx',\n                              'larynx': 'larynx',\n                              'lip &amp; oral cavity': 'lip &amp; oral cavity',\n                              'nasal cavity': 'nasal cavity',\n                              'nasopharynx': 'nasopharynx',\n                              'oropharynx': 'oropharynx',\n                              'paranasal sinus': 'paranasal sinus',\n                              'salivary glands': 'Other'},\n             'Dose': {'50.0': 'Other',\n                      '50.8': 'Other',\n                      '51.0': '51.0',\n                      '53.55': 'Other',\n                      '55.0': 'Other',\n                      '59.4': 'Other',\n                      '60.0': '60.0',\n                      '64.0': '64.0',\n                      '66.0': '66.0',\n                      '69.96': 'Other',\n                      '70.0': '70.0'},\n             'EGFRI': {'0': '0', '1': '1'},\n             'HPV Combined': {'0.0': '0.0', '1.0': '1.0', 'nan': 'nan'},\n             'N Stage': {'N0': 'N0',\n                         'N1': 'N1',\n                         'N2': 'N2',\n                         'N2a': 'N2a',\n                         'N2b': 'N2b',\n                         'N2c': 'N2c',\n                         'N3': 'N3',\n                         'N3a': 'Other',\n                         'N3b': 'N3b',\n                         'NX': 'Other'},\n             'Sex': {'Female': 'Female', 'Male': 'Male'},\n             'Stage': {'0': '0',\n                       'I': 'I',\n                       'II': 'II',\n                       'IIA': 'Other',\n                       'III': 'III',\n                       'IIIA': 'Other',\n                       'IIIC': 'Other',\n                       'IV': 'Other',\n                       'IVA': 'IVA',\n                       'IVB': 'IVB',\n                       'nan': 'nan'},\n             'T Stage': {'T1': 'T1',\n                         'T1a': 'T1a',\n                         'T1b': 'T1b',\n                         'T2': 'T2',\n                         'T2 (2)': 'Other',\n                         'T3': 'T3',\n                         'T3 (2)': 'Other',\n                         'T4': 'T4',\n                         'T4a': 'T4a',\n                         'T4b': 'T4b',\n                         'TX': 'Other',\n                         'Tis': 'Tis'},\n             'event': {'0': '0', '1': '1'}},\n 'missingness_strategy': {'categorical': {'Chemotherapy': 'Unknown',\n                                          'Disease Site': 'Unknown',\n                                          'Dose': 'Unknown',\n                                          'EGFRI': 'Unknown',\n                                          'HPV Combined': 'Unknown',\n                                          'N Stage': 'Unknown',\n                                          'Sex': 'Unknown',\n                                          'Stage': 'Unknown',\n                                          'T Stage': 'Unknown',\n                                          'event': 'Unknown'},\n                          'continuous': {'age at dx': 'median',\n                                         'time': 'median'}}}\n</pre> In\u00a0[\u00a0]: Copied! <pre>from jarvais.analyzer import Analyzer\n\nanalyzer = Analyzer(df, task='survival', target_variable='event', output_dir='./radcure_outputs/analyzer', one_hot_encode=True, config='radcure_outputs/analyzer/config.yaml')\n\nanalyzer.run()\n</pre> from jarvais.analyzer import Analyzer  analyzer = Analyzer(df, task='survival', target_variable='event', output_dir='./radcure_outputs/analyzer', one_hot_encode=True, config='radcure_outputs/analyzer/config.yaml')  analyzer.run() <pre>Feature Types:\n  - Categorical: ['T Stage', 'Stage', 'Disease Site', 'Sex', 'N Stage', 'EGFRI', 'event', 'Chemotherapy', 'HPV Combined']\n  - Continuous: ['time', 'age at dx', 'Dose']\n\n\nOutlier Analysis:\n  - Outliers found in T Stage: ['T2 (2): 1 out of 2552', 'TX: 1 out of 2552', 'T3 (2): 1 out of 2552']\n  - Outliers found in Stage: ['IV: 6 out of 2549', 'IIIC: 2 out of 2549', 'IIIA: 2 out of 2549', 'IIA: 1 out of 2549']\n  - Outliers found in Disease Site: ['esophagus: 22 out of 2552', 'salivary glands: 4 out of 2552']\n  - No Outliers found in Sex\n  - Outliers found in N Stage: ['N3a: 14 out of 2552', 'NX: 1 out of 2552']\n  - No Outliers found in EGFRI\n  - No Outliers found in event\n  - No Outliers found in Chemotherapy\n  - No Outliers found in HPV Combined\n\nApplying changes from config...\n\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502                      \u2502                   \u2502 Missing   \u2502 Overall     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 n                    \u2502                   \u2502           \u2502 2552        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 time, mean (SD)      \u2502                   \u2502 0         \u2502 4.8 (2.8)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 age at dx, mean (SD) \u2502                   \u2502 0         \u2502 62.0 (11.7) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dose, mean (SD)      \u2502                   \u2502 0         \u2502 66.9 (5.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 T Stage, n (%)       \u2502 Other             \u2502           \u2502 3 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1                \u2502           \u2502 361 (14.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1a               \u2502           \u2502 147 (5.8)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T1b               \u2502           \u2502 68 (2.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T2                \u2502           \u2502 747 (29.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T3                \u2502           \u2502 704 (27.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4                \u2502           \u2502 96 (3.8)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4a               \u2502           \u2502 295 (11.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 T4b               \u2502           \u2502 95 (3.7)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Tis               \u2502           \u2502 36 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Stage, n (%)         \u2502 0                 \u2502           \u2502 37 (1.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 I                 \u2502           \u2502 289 (11.3)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 II                \u2502           \u2502 323 (12.7)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 III               \u2502           \u2502 474 (18.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVA               \u2502           \u2502 1187 (46.5) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 IVB               \u2502           \u2502 228 (8.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Other             \u2502           \u2502 11 (0.4)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Unknown           \u2502           \u2502 3 (0.1)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Disease Site, n (%)  \u2502 Other             \u2502           \u2502 26 (1.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 hypopharynx       \u2502           \u2502 143 (5.6)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 larynx            \u2502           \u2502 727 (28.5)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 lip &amp; oral cavity \u2502           \u2502 82 (3.2)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasal cavity      \u2502           \u2502 51 (2.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 nasopharynx       \u2502           \u2502 321 (12.6)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 oropharynx        \u2502           \u2502 1176 (46.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 paranasal sinus   \u2502           \u2502 26 (1.0)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Sex, n (%)           \u2502 Female            \u2502           \u2502 513 (20.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Male              \u2502           \u2502 2039 (79.9) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 N Stage, n (%)       \u2502 N0                \u2502           \u2502 914 (35.8)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N1                \u2502           \u2502 260 (10.2)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2                \u2502           \u2502 161 (6.3)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2a               \u2502           \u2502 75 (2.9)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2b               \u2502           \u2502 585 (22.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N2c               \u2502           \u2502 409 (16.0)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3                \u2502           \u2502 106 (4.2)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 N3b               \u2502           \u2502 27 (1.1)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Other             \u2502           \u2502 15 (0.6)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 EGFRI, n (%)         \u2502 0                 \u2502           \u2502 2452 (96.1) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 100 (3.9)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 event, n (%)         \u2502 0                 \u2502           \u2502 1674 (65.6) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 878 (34.4)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Chemotherapy, n (%)  \u2502 0                 \u2502           \u2502 1466 (57.4) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1                 \u2502           \u2502 1086 (42.6) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 HPV Combined, n (%)  \u2502 0.0               \u2502           \u2502 437 (17.1)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 1.0               \u2502           \u2502 840 (32.9)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      \u2502 Unknown           \u2502           \u2502 1275 (50.0) \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</pre> In\u00a0[3]: Copied! <pre>from jarvais.trainer import TrainerSupervised\n\ndf = pd.read_csv('./radcure_outputs/analyzer/updated_data.csv', index_col=0)\ndf.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)\n\ntrainer = TrainerSupervised(task='survival', output_dir='./radcure_outputs/ED_trainer_explainer',)\ntrainer.run(df, ['event','time'])\n</pre> from jarvais.trainer import TrainerSupervised  df = pd.read_csv('./radcure_outputs/analyzer/updated_data.csv', index_col=0) df.rename(columns={'survival_time': 'time', 'death':'event'}, inplace=True)  trainer = TrainerSupervised(task='survival', output_dir='./radcure_outputs/ED_trainer_explainer',) trainer.run(df, ['event','time']) <pre>/home/joshua-siraj/Documents/CDI/jarvais/.pixi/envs/default/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> <pre>Training MTLR...\n  Best trial:\n    Params: \n      C1: 0.01\n      dropout: 0.48010344307101943\n      dims: [16, 16]\nTraining DeepSurv...\n  Best trial:\n    Params: \n      l2_reg: 0.0067966243797537955\n      dropout: 0.4685764374782581\n      dims: [256, 256, 256]\nTraining CoxPH...\nTraining GradientBoosting...\nTraining RandomForest...\nTraining SVM...\n\nConsolidated C-index Scores:\nMTLR: 0.6201\nDeepSurv: 0.6046\nCoxPH: 0.7785\nGradientBoosting: 0.7793\nRandomForest: 0.7684\nSVM: 0.7745\n</pre> In\u00a0[4]: Copied! <pre>from jarvais.explainer import Explainer\n\nexp = Explainer.from_trainer(trainer)\nexp.run()\n</pre> from jarvais.explainer import Explainer  exp = Explainer.from_trainer(trainer) exp.run()"}]}